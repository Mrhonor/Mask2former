Fontconfig error: Cannot load default config file
Loading config configs/7_datasets/Base-Cityscapes-SemanticSegmentation_hrnet.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Command Line Args: Namespace(config_file='configs/7_datasets/hrnet_bs16_90k.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/model_0019999.pth'], resume=True)
[03/05 14:17:33 detectron2]: Rank of current process: 0. World size: 1
[03/05 14:17:34 detectron2]: Environment info:
-------------------------------  ----------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.10 (default, Nov 22 2023, 10:22:35) [GCC 9.4.0]
numpy                            1.24.4
detectron2                       0.6 @/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2
Compiler                         GCC 11.4
CUDA compiler                    CUDA 11.7
detectron2 arch flags            8.0
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.0.1+cu117 @/usr/local/lib/python3.8/dist-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            NVIDIA A100-SXM4-80GB (arch=8.0)
Driver version                   470.199.02
CUDA_HOME                        /usr/local/cuda-11.7
Pillow                           10.2.0
torchvision                      0.15.2+cu117 @/usr/local/lib/python3.8/dist-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  ----------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/05 14:17:34 detectron2]: Command line arguments: Namespace(config_file='configs/7_datasets/hrnet_bs16_90k.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/model_0019999.pth'], resume=True)
[03/05 14:17:34 detectron2]: Contents of args.config_file=configs/7_datasets/hrnet_bs16_90k.yaml:
[38;5;197m_BASE_[39m[38;5;15m:[39m[38;5;15m [39mBase-Cityscapes-SemanticSegmentation_hrnet.yaml
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mHRNet_W48_ARCH[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mHRNet_W48[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mOUTPUT_FEAT_DIM[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mWITH_DATASETS_AUX[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m    [39m[38;5;197mBN_TYPE[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mtorchbn[39m[38;5;186m"[39m
[38;5;15m  [39m[38;5;197mGNN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mNFEAT[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNFEAT_OUT[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mnfeat_adj[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197madj_feat_dim[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mdropout_rate[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mthreshold_value[39m[38;5;15m:[39m[38;5;15m [39m0.95
[38;5;15m    [39m[38;5;197mcalc_bipartite[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m    [39m[38;5;197moutput_max_adj[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197moutput_softmax_adj[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197muot_ratio[39m[38;5;15m:[39m[38;5;15m [39m1.01
[38;5;15m    [39m[38;5;197mmse_or_adv[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mNone[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mGNN_type[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mGSAGE[39m[38;5;186m"[39m
[38;5;15m    [39m[38;5;197mwith_datasets_aux[39m[38;5;15m:[39m[38;5;15m [39mTrue
[38;5;15m    [39m[38;5;197minit_stage_iters[39m[38;5;15m:[39m[38;5;15m [39m10000
[38;5;15m    [39m[38;5;197misGumbelSoftmax[39m[38;5;15m:[39m[38;5;15m [39mFalse
[38;5;15m    [39m[38;5;197mGNN_ITERS[39m[38;5;15m:[39m[38;5;15m [39m20000
[38;5;15m    [39m[38;5;197mSEG_ITERS[39m[38;5;15m:[39m[38;5;15m [39m20000
[38;5;15m    [39m[38;5;197mFIRST_STAGE_GNN_ITERS[39m[38;5;15m:[39m[38;5;15m [39m15000
[38;5;15m    [39m[38;5;197mINIT_ADJ_PATH[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186moutput/init_adj_7_datasets.pt[39m[38;5;186m"[39m

[03/05 14:17:34 detectron2]: Running with full config:
[38;5;197mCUDNN_BENCHMARK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mDATALOADER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mASPECT_RATIO_GROUPING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mFILTER_EMPTY_ANNOTATIONS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mNUM_WORKERS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mREPEAT_THRESHOLD[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSAMPLER_TRAIN[39m[38;5;15m:[39m[38;5;15m [39mTrainingSampler
[38;5;197mDATASETS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCONFIGER[39m[38;5;15m:[39m[38;5;15m [39mconfigs/ltbgnn_7_datasets_snp.json
[38;5;15m  [39m[38;5;197mDATASETS_CATS[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m19
[38;5;15m  [39m-[38;5;15m [39m64
[38;5;15m  [39m-[38;5;15m [39m37
[38;5;15m  [39m-[38;5;15m [39m19
[38;5;15m  [39m-[38;5;15m [39m26
[38;5;15m  [39m-[38;5;15m [39m150
[38;5;15m  [39m-[38;5;15m [39m133
[38;5;15m  [39m[38;5;197mIGNORE_LB[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m  [39m[38;5;197mNUM_UNIFY_CLASS[39m[38;5;15m:[39m[38;5;15m [39m448
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mPRECOMPUTED_PROPOSAL_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TEST[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPROPOSAL_FILES_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39mcs_sem_seg_val
[38;5;15m  [39m-[38;5;15m [39msunrgbd_sem_seg_val
[38;5;15m  [39m-[38;5;15m [39mbdd_sem_seg_val
[38;5;15m  [39m-[38;5;15m [39midd_sem_seg_val
[38;5;15m  [39m-[38;5;15m [39made_sem_seg_val
[38;5;15m  [39m-[38;5;15m [39mcoco_sem_seg_val
[38;5;15m  [39m[38;5;197mTRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39mcs_sem_seg_train
[38;5;15m  [39m-[38;5;15m [39mmapi_sem_seg_train
[38;5;15m  [39m-[38;5;15m [39msunrgbd_sem_seg_train
[38;5;15m  [39m-[38;5;15m [39mbdd_sem_seg_train
[38;5;15m  [39m-[38;5;15m [39midd_sem_seg_train
[38;5;15m  [39m-[38;5;15m [39made_sem_seg_train
[38;5;15m  [39m-[38;5;15m [39mcoco_sem_seg_train
[38;5;197mGLOBAL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mHACK[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;197mINPUT[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mCOLOR_AUG_SSD[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mCROP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSINGLE_CATEGORY_MAX_AREA[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mSIZE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m[38;5;197mTYPE[39m[38;5;15m:[39m[38;5;15m [39mabsolute
[38;5;15m  [39m[38;5;197mDATASET_MAPPER_NAME[39m[38;5;15m:[39m[38;5;15m [39mDALI
[38;5;15m  [39m[38;5;197mFORMAT[39m[38;5;15m:[39m[38;5;15m [39mRGB
[38;5;15m  [39m[38;5;197mIMAGE_SIZE[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m  [39m[38;5;197mMASK_FORMAT[39m[38;5;15m:[39m[38;5;15m [39mpolygon
[38;5;15m  [39m[38;5;197mMAX_SCALE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mMAX_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m  [39m[38;5;197mMAX_SIZE_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m  [39m[38;5;197mMIN_SCALE[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mMIN_SIZE_TEST[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m256
[38;5;15m  [39m-[38;5;15m [39m307
[38;5;15m  [39m-[38;5;15m [39m358
[38;5;15m  [39m-[38;5;15m [39m409
[38;5;15m  [39m-[38;5;15m [39m460
[38;5;15m  [39m-[38;5;15m [39m512
[38;5;15m  [39m-[38;5;15m [39m563
[38;5;15m  [39m-[38;5;15m [39m614
[38;5;15m  [39m-[38;5;15m [39m665
[38;5;15m  [39m-[38;5;15m [39m716
[38;5;15m  [39m-[38;5;15m [39m768
[38;5;15m  [39m-[38;5;15m [39m819
[38;5;15m  [39m-[38;5;15m [39m870
[38;5;15m  [39m-[38;5;15m [39m921
[38;5;15m  [39m-[38;5;15m [39m972
[38;5;15m  [39m-[38;5;15m [39m1024
[38;5;15m  [39m-[38;5;15m [39m1075
[38;5;15m  [39m-[38;5;15m [39m1126
[38;5;15m  [39m-[38;5;15m [39m1177
[38;5;15m  [39m-[38;5;15m [39m1228
[38;5;15m  [39m-[38;5;15m [39m1280
[38;5;15m  [39m-[38;5;15m [39m1331
[38;5;15m  [39m-[38;5;15m [39m1382
[38;5;15m  [39m-[38;5;15m [39m1433
[38;5;15m  [39m-[38;5;15m [39m1484
[38;5;15m  [39m-[38;5;15m [39m1536
[38;5;15m  [39m-[38;5;15m [39m1587
[38;5;15m  [39m-[38;5;15m [39m1638
[38;5;15m  [39m-[38;5;15m [39m1689
[38;5;15m  [39m-[38;5;15m [39m1740
[38;5;15m  [39m-[38;5;15m [39m1792
[38;5;15m  [39m-[38;5;15m [39m1843
[38;5;15m  [39m-[38;5;15m [39m1894
[38;5;15m  [39m-[38;5;15m [39m1945
[38;5;15m  [39m-[38;5;15m [39m1996
[38;5;15m  [39m-[38;5;15m [39m2048
[38;5;15m  [39m[38;5;197mMIN_SIZE_TRAIN_SAMPLING[39m[38;5;15m:[39m[38;5;15m [39mchoice
[38;5;15m  [39m[38;5;197mRANDOM_FLIP[39m[38;5;15m:[39m[38;5;15m [39mhorizontal
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mLOSS[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mOHEM_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;197mMODEL[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mANCHOR_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mANGLES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m-90
[38;5;15m      [39m-[38;5;15m [39m0
[38;5;15m      [39m-[38;5;15m [39m90
[38;5;15m    [39m[38;5;197mASPECT_RATIOS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m0.5
[38;5;15m      [39m-[38;5;15m [39m1.0
[38;5;15m      [39m-[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mDefaultAnchorGenerator
[38;5;15m    [39m[38;5;197mOFFSET[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mSIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m32
[38;5;15m      [39m-[38;5;15m [39m64
[38;5;15m      [39m-[38;5;15m [39m128
[38;5;15m      [39m-[38;5;15m [39m256
[38;5;15m      [39m-[38;5;15m [39m512
[38;5;15m  [39m[38;5;197mAUX_MODE[39m[38;5;15m:[39m[38;5;15m [39mtrain
[38;5;15m  [39m[38;5;197mBACKBONE[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFREEZE_AT[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mHighResolutionNet
[38;5;15m  [39m[38;5;197mDEVICE[39m[38;5;15m:[39m[38;5;15m [39mcuda
[38;5;15m  [39m[38;5;197mFPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFUSE_TYPE[39m[38;5;15m:[39m[38;5;15m [39msum
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mOUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m  [39m[38;5;197mGNN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mFIRST_STAGE_GNN_ITERS[39m[38;5;15m:[39m[38;5;15m [39m15000
[38;5;15m    [39m[38;5;197mGNN_ITERS[39m[38;5;15m:[39m[38;5;15m [39m20000
[38;5;15m    [39m[38;5;197mGNN_type[39m[38;5;15m:[39m[38;5;15m [39mGSAGE
[38;5;15m    [39m[38;5;197mINIT_ADJ_PATH[39m[38;5;15m:[39m[38;5;15m [39moutput/init_adj_7_datasets.pt
[38;5;15m    [39m[38;5;197mNFEAT[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mNFEAT_OUT[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mSEG_ITERS[39m[38;5;15m:[39m[38;5;15m [39m20000
[38;5;15m    [39m[38;5;197madj_feat_dim[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mcalc_bipartite[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mdropout_rate[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197minit_stage_iters[39m[38;5;15m:[39m[38;5;15m [39m10000
[38;5;15m    [39m[38;5;197misGumbelSoftmax[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mmse_or_adv[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m    [39m[38;5;197mnfeat_adj[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197moutput_max_adj[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197moutput_softmax_adj[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mthreshold_value[39m[38;5;15m:[39m[38;5;15m [39m0.95
[38;5;15m    [39m[38;5;197muot_ratio[39m[38;5;15m:[39m[38;5;15m [39m1.01
[38;5;15m    [39m[38;5;197mwith_datasets_aux[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mHRNET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBN_TYPE[39m[38;5;15m:[39m[38;5;15m [39mtorchbn
[38;5;15m    [39m[38;5;197mDROP_STAGE4[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFULL_RES_STEM[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mHRNET_CFG[39m[38;5;15m:[39m[38;5;15m [39mhrnet48
[38;5;15m    [39m[38;5;197mKEEP_IMAGENET_HEAD[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mKEYPOINT_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mLOAD_PROPOSALS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMASK_ON[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mMETA_ARCHITECTURE[39m[38;5;15m:[39m[38;5;15m [39mHRNet_W48_ARCH
[38;5;15m  [39m[38;5;197mPANOPTIC_FPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCOMBINE[39m[38;5;15m:[39m
[38;5;15m      [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m      [39m[38;5;197mINSTANCES_CONFIDENCE_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mOVERLAP_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m      [39m[38;5;197mSTUFF_AREA_LIMIT[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mINSTANCE_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mPIXEL_MEAN[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m123.675
[38;5;15m  [39m-[38;5;15m [39m116.28
[38;5;15m  [39m-[38;5;15m [39m103.53
[38;5;15m  [39m[38;5;197mPIXEL_STD[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m58.395
[38;5;15m  [39m-[38;5;15m [39m57.12
[38;5;15m  [39m-[38;5;15m [39m57.375
[38;5;15m  [39m[38;5;197mPRETRAINING[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mPROPOSAL_GENERATOR[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mMIN_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRPN
[38;5;15m  [39m[38;5;197mRESNETS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mDEFORM_MODULATED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEFORM_NUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mDEFORM_ON_PER_STAGE[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m-[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mDEPTH[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mFrozenBN
[38;5;15m    [39m[38;5;197mNUM_GROUPS[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mOUT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mRES2_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mRES4_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_DILATION[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mRES5_MULTI_GRID[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m-[38;5;15m [39m2
[38;5;15m    [39m-[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mSTEM_OUT_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m    [39m[38;5;197mSTEM_TYPE[39m[38;5;15m:[39m[38;5;15m [39mdeeplab
[38;5;15m    [39m[38;5;197mSTRIDE_IN_1X1[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mWIDTH_PER_GROUP[39m[38;5;15m:[39m[38;5;15m [39m64
[38;5;15m  [39m[38;5;197mRETINANET[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m&id002[39m
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m-[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_ALPHA[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mFOCAL_LOSS_GAMMA[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m-[38;5;15m [39mp6
[38;5;15m    [39m-[38;5;15m [39mp7
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.4
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mNUM_CONVS[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mPRIOR_PROB[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m    [39m[38;5;197mSMOOTH_L1_LOSS_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mTOPK_CANDIDATES_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m  [39m[38;5;197mROI_BOX_CASCADE_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m[38;5;15m&id001[39m
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m      [39m-[38;5;15m [39m5.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m20.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m      [39m-[38;5;15m [39m10.0
[38;5;15m    [39m-[38;5;15m [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m30.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m      [39m-[38;5;15m [39m15.0
[38;5;15m    [39m[38;5;197mIOUS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m-[38;5;15m [39m0.6
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m  [39m[38;5;197mROI_BOX_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id001[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_BBOX_REG[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mFC_DIM[39m[38;5;15m:[39m[38;5;15m [39m1024
[38;5;15m    [39m[38;5;197mFED_LOSS_FREQ_WEIGHT_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mFED_LOSS_NUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m50
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mNUM_FC[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m    [39m[38;5;197mTRAIN_ON_PRED_BOXES[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mUSE_FED_LOSS[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mUSE_SIGMOID_CE[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mROI_HEADS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mRes5ROIHeads
[38;5;15m    [39m[38;5;197mNMS_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m80
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.25
[38;5;15m    [39m[38;5;197mPROPOSAL_APPEND_GT[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mSCORE_THRESH_TEST[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mROI_KEYPOINT_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mMIN_KEYPOINTS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mKRCNNConvDeconvUpsampleHead
[38;5;15m    [39m[38;5;197mNORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNUM_KEYPOINTS[39m[38;5;15m:[39m[38;5;15m [39m17
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mROI_MASK_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLS_AGNOSTIC_MASK[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mCONV_DIM[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mMaskRCNNConvUpsampleHead
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39m[38;5;186m'[39m[38;5;186m'[39m
[38;5;15m    [39m[38;5;197mNUM_CONV[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_RESOLUTION[39m[38;5;15m:[39m[38;5;15m [39m14
[38;5;15m    [39m[38;5;197mPOOLER_SAMPLING_RATIO[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m    [39m[38;5;197mPOOLER_TYPE[39m[38;5;15m:[39m[38;5;15m [39mROIAlignV2
[38;5;15m  [39m[38;5;197mRPN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mBATCH_SIZE_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39msmooth_l1
[38;5;15m    [39m[38;5;197mBBOX_REG_LOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mBBOX_REG_WEIGHTS[39m[38;5;15m:[39m[38;5;15m [39m[38;5;15m*id002[39m
[38;5;15m    [39m[38;5;197mBOUNDARY_THRESH[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mCONV_DIMS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m[38;5;197mHEAD_NAME[39m[38;5;15m:[39m[38;5;15m [39mStandardRPNHead
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres4
[38;5;15m    [39m[38;5;197mIOU_LABELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0
[38;5;15m    [39m-[38;5;15m [39m-1
[38;5;15m    [39m-[38;5;15m [39m1
[38;5;15m    [39m[38;5;197mIOU_THRESHOLDS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m0.3
[38;5;15m    [39m-[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNMS_THRESH[39m[38;5;15m:[39m[38;5;15m [39m0.7
[38;5;15m    [39m[38;5;197mPOSITIVE_FRACTION[39m[38;5;15m:[39m[38;5;15m [39m0.5
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m1000
[38;5;15m    [39m[38;5;197mPOST_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m2000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TEST[39m[38;5;15m:[39m[38;5;15m [39m6000
[38;5;15m    [39m[38;5;197mPRE_NMS_TOPK_TRAIN[39m[38;5;15m:[39m[38;5;15m [39m12000
[38;5;15m    [39m[38;5;197mSMOOTH_L1_BETA[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mSEM_SEG_HEAD[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mASPP_CHANNELS[39m[38;5;15m:[39m[38;5;15m [39m256
[38;5;15m    [39m[38;5;197mASPP_DILATIONS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m6
[38;5;15m    [39m-[38;5;15m [39m12
[38;5;15m    [39m-[38;5;15m [39m18
[38;5;15m    [39m[38;5;197mASPP_DROPOUT[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m    [39m[38;5;197mBN_TYPE[39m[38;5;15m:[39m[38;5;15m [39mtorchbn
[38;5;15m    [39m[38;5;197mCOMMON_STRIDE[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m    [39m[38;5;197mCONVS_DIM[39m[38;5;15m:[39m[38;5;15m [39m128
[38;5;15m    [39m[38;5;197mIGNORE_VALUE[39m[38;5;15m:[39m[38;5;15m [39m255
[38;5;15m    [39m[38;5;197mIN_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mp2
[38;5;15m    [39m-[38;5;15m [39mp3
[38;5;15m    [39m-[38;5;15m [39mp4
[38;5;15m    [39m-[38;5;15m [39mp5
[38;5;15m    [39m[38;5;197mLOSS_TYPE[39m[38;5;15m:[39m[38;5;15m [39mhard_pixel_mining
[38;5;15m    [39m[38;5;197mLOSS_WEIGHT[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m    [39m[38;5;197mNAME[39m[38;5;15m:[39m[38;5;15m [39mHRNet_W48
[38;5;15m    [39m[38;5;197mNORM[39m[38;5;15m:[39m[38;5;15m [39mGN
[38;5;15m    [39m[38;5;197mNUM_CLASSES[39m[38;5;15m:[39m[38;5;15m [39m54
[38;5;15m    [39m[38;5;197mOUTPUT_FEAT_DIM[39m[38;5;15m:[39m[38;5;15m [39m512
[38;5;15m    [39m[38;5;197mPROJECT_CHANNELS[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m48
[38;5;15m    [39m[38;5;197mPROJECT_FEATURES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39mres2
[38;5;15m    [39m[38;5;197mUSE_DEPTHWISE_SEPARABLE_CONV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mWITH_DATASETS_AUX[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSIZE_DIVISIBILITY[39m[38;5;15m:[39m[38;5;15m [39m32
[38;5;15m  [39m[38;5;197mWEIGHTS[39m[38;5;15m:[39m[38;5;15m [39moutput/model_0019999.pth
[38;5;15m  [39m[38;5;197mWITH_DATASETS_AUX[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;197mOUTPUT_DIR[39m[38;5;15m:[39m[38;5;15m [39m./output
[38;5;197mSEED[39m[38;5;15m:[39m[38;5;15m [39m-1
[38;5;197mSOLVER[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAMP[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m  [39m[38;5;197mBACKBONE_MULTIPLIER[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mBASE_LR[39m[38;5;15m:[39m[38;5;15m [39m0.0001
[38;5;15m  [39m[38;5;197mBASE_LR_END[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mBIAS_LR_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mCHECKPOINT_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m5000
[38;5;15m  [39m[38;5;197mCLIP_GRADIENTS[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mCLIP_TYPE[39m[38;5;15m:[39m[38;5;15m [39mfull_model
[38;5;15m    [39m[38;5;197mCLIP_VALUE[39m[38;5;15m:[39m[38;5;15m [39m0.01
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mNORM_TYPE[39m[38;5;15m:[39m[38;5;15m [39m2.0
[38;5;15m  [39m[38;5;197mGAMMA[39m[38;5;15m:[39m[38;5;15m [39m0.1
[38;5;15m  [39m[38;5;197mIMS_PER_BATCH[39m[38;5;15m:[39m[38;5;15m [39m4
[38;5;15m  [39m[38;5;197mLR_SCHEDULER_NAME[39m[38;5;15m:[39m[38;5;15m [39mWarmupPolyLR
[38;5;15m  [39m[38;5;197mMAX_ITER[39m[38;5;15m:[39m[38;5;15m [39m100000
[38;5;15m  [39m[38;5;197mMOMENTUM[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mNESTEROV[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mNUM_DECAYS[39m[38;5;15m:[39m[38;5;15m [39m3
[38;5;15m  [39m[38;5;197mOPTIMIZER[39m[38;5;15m:[39m[38;5;15m [39mADAMW
[38;5;15m  [39m[38;5;197mPOLY_LR_CONSTANT_ENDING[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mPOLY_LR_POWER[39m[38;5;15m:[39m[38;5;15m [39m0.9
[38;5;15m  [39m[38;5;197mREFERENCE_WORLD_SIZE[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mRESCALE_INTERVAL[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m  [39m[38;5;197mSTEPS[39m[38;5;15m:[39m
[38;5;15m  [39m-[38;5;15m [39m30000
[38;5;15m  [39m[38;5;197mWARMUP_FACTOR[39m[38;5;15m:[39m[38;5;15m [39m1.0
[38;5;15m  [39m[38;5;197mWARMUP_ITERS[39m[38;5;15m:[39m[38;5;15m [39m0
[38;5;15m  [39m[38;5;197mWARMUP_METHOD[39m[38;5;15m:[39m[38;5;15m [39mlinear
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY[39m[38;5;15m:[39m[38;5;15m [39m0.05
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_BIAS[39m[38;5;15m:[39m[38;5;15m [39mnull
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_EMBED[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;15m  [39m[38;5;197mWEIGHT_DECAY_NORM[39m[38;5;15m:[39m[38;5;15m [39m0.0
[38;5;197mTEST[39m[38;5;15m:[39m
[38;5;15m  [39m[38;5;197mAUG[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mFLIP[39m[38;5;15m:[39m[38;5;15m [39mtrue
[38;5;15m    [39m[38;5;197mMAX_SIZE[39m[38;5;15m:[39m[38;5;15m [39m4096
[38;5;15m    [39m[38;5;197mMIN_SIZES[39m[38;5;15m:[39m
[38;5;15m    [39m-[38;5;15m [39m256
[38;5;15m    [39m-[38;5;15m [39m384
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m640
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m896
[38;5;15m    [39m-[38;5;15m [39m512
[38;5;15m    [39m-[38;5;15m [39m768
[38;5;15m    [39m-[38;5;15m [39m1024
[38;5;15m    [39m-[38;5;15m [39m1280
[38;5;15m    [39m-[38;5;15m [39m1536
[38;5;15m    [39m-[38;5;15m [39m1792
[38;5;15m  [39m[38;5;197mDETECTIONS_PER_IMAGE[39m[38;5;15m:[39m[38;5;15m [39m100
[38;5;15m  [39m[38;5;197mEVAL_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m10000
[38;5;15m  [39m[38;5;197mEXPECTED_RESULTS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mKEYPOINT_OKS_SIGMAS[39m[38;5;15m:[39m[38;5;15m [39m[]
[38;5;15m  [39m[38;5;197mPRECISE_BN[39m[38;5;15m:[39m
[38;5;15m    [39m[38;5;197mENABLED[39m[38;5;15m:[39m[38;5;15m [39mfalse
[38;5;15m    [39m[38;5;197mNUM_ITER[39m[38;5;15m:[39m[38;5;15m [39m200
[38;5;197mVERSION[39m[38;5;15m:[39m[38;5;15m [39m2
[38;5;197mVIS_PERIOD[39m[38;5;15m:[39m[38;5;15m [39m0

[03/05 14:17:34 detectron2]: Full config saved to ./output/config.yaml
[03/05 14:17:34 d2.utils.env]: Using a generated random seed 34273627
torch.Size([19, 1024])
[03/05 14:17:43 d2.engine.defaults]: Model:
HRNet_W48_ARCH(
  (backbone): HighResolutionNet(
    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU()
    (layer1): Sequential(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (relu_in): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (relu_in): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (relu_in): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU()
        (relu_in): ReLU(inplace=True)
      )
    )
    (transition1): ModuleList(
      (0): Sequential(
        (0): Conv2d(256, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU()
      )
      (1): Sequential(
        (0): Sequential(
          (0): Conv2d(256, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
    )
    (stage2): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition2): ModuleList(
      (0-1): 2 x None
      (2): Sequential(
        (0): Sequential(
          (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
    )
    (stage3): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (1): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (2): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
      (3): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
          )
        )
        (relu): ReLU()
      )
    )
    (transition3): ModuleList(
      (0-2): 3 x None
      (3): Sequential(
        (0): Sequential(
          (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU()
        )
      )
    )
    (stage4): Sequential(
      (0): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (1): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
      (2): HighResolutionModule(
        (branches): ModuleList(
          (0): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): Sequential(
            (0): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (1): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): BasicBlock(
              (conv1): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (relu): ReLU()
              (relu_in): ReLU(inplace=True)
              (conv2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (bn2): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
        )
        (fuse_layers): ModuleList(
          (0): ModuleList(
            (0): None
            (1): Sequential(
              (0): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (2): Sequential(
              (0): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (1): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): None
            (2): Sequential(
              (0): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
            (3): Sequential(
              (0): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (2): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): None
            (3): Sequential(
              (0): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (3): ModuleList(
            (0): Sequential(
              (0): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (2): Sequential(
                (0): Conv2d(48, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (1): Sequential(
              (0): Sequential(
                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): ReLU()
              )
              (1): Sequential(
                (0): Conv2d(96, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (2): Sequential(
              (0): Sequential(
                (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
                (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              )
            )
            (3): None
          )
        )
        (relu): ReLU()
      )
    )
  )
  (proj_head): HRNet_W48(
    (proj_head): ProjectionHead(
      (proj): Sequential(
        (0): Conv2d(720, 720, kernel_size=(1, 1), stride=(1, 1))
        (1): Sequential(
          (0): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (1): ReLU()
        )
        (2): Conv2d(720, 512, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (bipartite_graphs): ParameterList(
        (0): Parameter containing: [torch.float32 of size 19x448 (GPU 0)]
        (1): Parameter containing: [torch.float32 of size 64x448 (GPU 0)]
        (2): Parameter containing: [torch.float32 of size 37x448 (GPU 0)]
        (3): Parameter containing: [torch.float32 of size 19x448 (GPU 0)]
        (4): Parameter containing: [torch.float32 of size 26x448 (GPU 0)]
        (5): Parameter containing: [torch.float32 of size 150x448 (GPU 0)]
        (6): Parameter containing: [torch.float32 of size 133x448 (GPU 0)]
    )
  )
  (criterion): OhemCELoss(
    (criteria): CrossEntropyLoss()
  )
)
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f54850>, RandomFlip()]
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f54730>, RandomFlip()]
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f54460>, RandomFlip()]
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f541c0>, RandomFlip()]
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f86fd0>, RandomFlip()]
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f86d60>, RandomFlip()]
[03/05 14:17:44 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9b17f86af0>, RandomFlip()]
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 0.94 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 18000 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 4.48 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 5285 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 1.14 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 7000 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 1.74 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 6993 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 1.69 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 20210 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 5.45 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.data.build]: Using training sampler TrainingSampler
[03/05 14:17:44 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 14:17:44 d2.data.common]: Serializing 118287 elements to byte tensors and concatenating them all ...
[03/05 14:17:44 d2.data.common]: Serialized dataset takes 27.98 MiB
[03/05 14:17:44 d2.data.build]: Making batched data loader with batch_size=4
[03/05 14:17:44 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from ./output/model_0019999.pth ...
[03/05 14:17:44 fvcore.common.checkpoint]: [Checkpointer] Loading from ./output/model_0019999.pth ...
[03/05 14:17:51 fvcore.common.checkpoint]: Loading trainer from ./output/model_0019999.pth ...
[03/05 14:17:51 d2.engine.hooks]: Loading scheduler from state_dict ...
[03/05 14:17:52 d2.engine.train_loop]: Starting training from iteration 20000
[03/05 14:18:31 d2.utils.events]:  eta: 1 day, 13:12:54  iter: 20019  total_loss: 12.24  loss_ce0: 0.711  loss_ce1: 1.112  loss_ce2: 1.162  loss_ce3: 0.8046  loss_ce4: 1.016  loss_ce5: 4.959  loss_ce6: 2.479    time: 1.6712  last_time: 1.6734  data_time: 0.2572  last_data_time: 0.0413   lr: 8.1788e-06  max_mem: 49046M
[03/05 14:19:04 d2.utils.events]:  eta: 1 day, 13:06:55  iter: 20039  total_loss: 10.94  loss_ce0: 0.7188  loss_ce1: 1.194  loss_ce2: 1.209  loss_ce3: 0.8269  loss_ce4: 0.9578  loss_ce5: 3.622  loss_ce6: 2.371    time: 1.6657  last_time: 1.6421  data_time: 0.0449  last_data_time: 0.0448   lr: 8.1769e-06  max_mem: 49046M
[03/05 14:19:38 d2.utils.events]:  eta: 1 day, 13:06:22  iter: 20059  total_loss: 10.95  loss_ce0: 0.6738  loss_ce1: 1.246  loss_ce2: 1.253  loss_ce3: 0.8185  loss_ce4: 1.029  loss_ce5: 3.078  loss_ce6: 2.64    time: 1.6708  last_time: 1.7249  data_time: 0.0465  last_data_time: 0.0502   lr: 8.1751e-06  max_mem: 49046M
[03/05 14:20:11 d2.utils.events]:  eta: 1 day, 13:00:46  iter: 20079  total_loss: 10.5  loss_ce0: 0.7151  loss_ce1: 1.198  loss_ce2: 1.262  loss_ce3: 0.7889  loss_ce4: 1.04  loss_ce5: 2.748  loss_ce6: 2.655    time: 1.6682  last_time: 1.6173  data_time: 0.0473  last_data_time: 0.0447   lr: 8.1733e-06  max_mem: 49046M
[03/05 14:20:45 d2.utils.events]:  eta: 1 day, 13:05:15  iter: 20099  total_loss: 10.17  loss_ce0: 0.6979  loss_ce1: 1.227  loss_ce2: 1.157  loss_ce3: 0.7669  loss_ce4: 1.043  loss_ce5: 2.673  loss_ce6: 2.455    time: 1.6702  last_time: 1.6231  data_time: 0.0490  last_data_time: 0.0464   lr: 8.1714e-06  max_mem: 49046M
[03/05 14:21:18 d2.utils.events]:  eta: 1 day, 13:04:33  iter: 20119  total_loss: 10.57  loss_ce0: 0.6687  loss_ce1: 1.244  loss_ce2: 1.232  loss_ce3: 0.7735  loss_ce4: 0.9979  loss_ce5: 3.016  loss_ce6: 2.299    time: 1.6727  last_time: 1.6482  data_time: 0.0473  last_data_time: 0.0467   lr: 8.1696e-06  max_mem: 49046M
[03/05 14:21:52 d2.utils.events]:  eta: 1 day, 13:04:19  iter: 20139  total_loss: 10.79  loss_ce0: 0.6741  loss_ce1: 1.153  loss_ce2: 1.355  loss_ce3: 0.8544  loss_ce4: 0.9879  loss_ce5: 2.691  loss_ce6: 2.881    time: 1.6739  last_time: 1.6590  data_time: 0.0463  last_data_time: 0.0431   lr: 8.1677e-06  max_mem: 49046M
[03/05 14:22:26 d2.utils.events]:  eta: 1 day, 13:05:32  iter: 20159  total_loss: 10.37  loss_ce0: 0.6492  loss_ce1: 1.182  loss_ce2: 1.267  loss_ce3: 0.8207  loss_ce4: 1.021  loss_ce5: 2.609  loss_ce6: 2.549    time: 1.6768  last_time: 1.9066  data_time: 0.0461  last_data_time: 0.0437   lr: 8.1659e-06  max_mem: 49046M
[03/05 14:23:00 d2.utils.events]:  eta: 1 day, 13:05:44  iter: 20179  total_loss: 10.66  loss_ce0: 0.6786  loss_ce1: 1.197  loss_ce2: 1.167  loss_ce3: 0.745  loss_ce4: 0.9751  loss_ce5: 2.449  loss_ce6: 2.993    time: 1.6781  last_time: 1.6204  data_time: 0.0472  last_data_time: 0.0490   lr: 8.164e-06  max_mem: 49046M
[03/05 14:23:33 d2.utils.events]:  eta: 1 day, 13:05:11  iter: 20199  total_loss: 10.47  loss_ce0: 0.685  loss_ce1: 1.199  loss_ce2: 1.33  loss_ce3: 0.8074  loss_ce4: 1.001  loss_ce5: 2.569  loss_ce6: 2.577    time: 1.6783  last_time: 1.6655  data_time: 0.0467  last_data_time: 0.0478   lr: 8.1622e-06  max_mem: 49046M
[03/05 14:24:07 d2.utils.events]:  eta: 1 day, 13:04:13  iter: 20219  total_loss: 10.17  loss_ce0: 0.6683  loss_ce1: 1.326  loss_ce2: 1.211  loss_ce3: 0.8066  loss_ce4: 1.015  loss_ce5: 2.376  loss_ce6: 2.613    time: 1.6777  last_time: 1.6222  data_time: 0.0466  last_data_time: 0.0485   lr: 8.1604e-06  max_mem: 49046M
[03/05 14:24:41 d2.utils.events]:  eta: 1 day, 13:04:46  iter: 20239  total_loss: 9.963  loss_ce0: 0.6776  loss_ce1: 1.172  loss_ce2: 1.131  loss_ce3: 0.767  loss_ce4: 0.9744  loss_ce5: 2.391  loss_ce6: 2.607    time: 1.6794  last_time: 1.7032  data_time: 0.0498  last_data_time: 0.0492   lr: 8.1585e-06  max_mem: 49046M
[03/05 14:25:15 d2.utils.events]:  eta: 1 day, 13:04:53  iter: 20259  total_loss: 10.33  loss_ce0: 0.6729  loss_ce1: 1.211  loss_ce2: 1.098  loss_ce3: 0.7241  loss_ce4: 1.047  loss_ce5: 2.386  loss_ce6: 2.678    time: 1.6797  last_time: 1.6194  data_time: 0.0470  last_data_time: 0.0464   lr: 8.1567e-06  max_mem: 49046M
[03/05 14:25:48 d2.utils.events]:  eta: 1 day, 13:06:37  iter: 20279  total_loss: 10.57  loss_ce0: 0.6726  loss_ce1: 1.327  loss_ce2: 1.503  loss_ce3: 0.7489  loss_ce4: 1.007  loss_ce5: 2.542  loss_ce6: 2.773    time: 1.6803  last_time: 1.6770  data_time: 0.0477  last_data_time: 0.0394   lr: 8.1548e-06  max_mem: 49046M
[03/05 14:26:22 d2.utils.events]:  eta: 1 day, 13:06:59  iter: 20299  total_loss: 10.64  loss_ce0: 0.6708  loss_ce1: 1.214  loss_ce2: 1.399  loss_ce3: 0.7742  loss_ce4: 0.9557  loss_ce5: 2.564  loss_ce6: 2.63    time: 1.6814  last_time: 1.7998  data_time: 0.0485  last_data_time: 0.0536   lr: 8.153e-06  max_mem: 49046M
[03/05 14:26:56 d2.utils.events]:  eta: 1 day, 13:07:42  iter: 20319  total_loss: 10.53  loss_ce0: 0.6551  loss_ce1: 1.231  loss_ce2: 1.152  loss_ce3: 0.8711  loss_ce4: 0.9797  loss_ce5: 2.333  loss_ce6: 2.605    time: 1.6832  last_time: 1.7043  data_time: 0.0470  last_data_time: 0.0468   lr: 8.1512e-06  max_mem: 49046M
[03/05 14:27:30 d2.utils.events]:  eta: 1 day, 13:08:15  iter: 20339  total_loss: 10.11  loss_ce0: 0.6888  loss_ce1: 1.231  loss_ce2: 1.256  loss_ce3: 0.7514  loss_ce4: 1.009  loss_ce5: 2.563  loss_ce6: 2.577    time: 1.6835  last_time: 1.7512  data_time: 0.0467  last_data_time: 0.0485   lr: 8.1493e-06  max_mem: 49046M
[03/05 14:28:04 d2.utils.events]:  eta: 1 day, 13:07:42  iter: 20359  total_loss: 9.832  loss_ce0: 0.6807  loss_ce1: 1.119  loss_ce2: 1.161  loss_ce3: 0.7845  loss_ce4: 0.9832  loss_ce5: 2.623  loss_ce6: 2.52    time: 1.6845  last_time: 1.6449  data_time: 0.0464  last_data_time: 0.0422   lr: 8.1475e-06  max_mem: 49046M
[03/05 14:28:38 d2.utils.events]:  eta: 1 day, 13:08:12  iter: 20379  total_loss: 10.16  loss_ce0: 0.6981  loss_ce1: 1.2  loss_ce2: 1.159  loss_ce3: 0.8627  loss_ce4: 0.999  loss_ce5: 2.405  loss_ce6: 2.565    time: 1.6855  last_time: 1.6393  data_time: 0.0492  last_data_time: 0.0501   lr: 8.1456e-06  max_mem: 49046M
[03/05 14:29:13 d2.utils.events]:  eta: 1 day, 13:10:43  iter: 20399  total_loss: 10.22  loss_ce0: 0.6575  loss_ce1: 1.139  loss_ce2: 1.073  loss_ce3: 0.8117  loss_ce4: 1.012  loss_ce5: 2.585  loss_ce6: 2.746    time: 1.6871  last_time: 1.6930  data_time: 0.0485  last_data_time: 0.0434   lr: 8.1438e-06  max_mem: 49046M
[03/05 14:29:47 d2.utils.events]:  eta: 1 day, 13:11:04  iter: 20419  total_loss: 10.38  loss_ce0: 0.6916  loss_ce1: 1.273  loss_ce2: 1.375  loss_ce3: 0.8113  loss_ce4: 0.9645  loss_ce5: 2.394  loss_ce6: 2.591    time: 1.6878  last_time: 1.7062  data_time: 0.0477  last_data_time: 0.0515   lr: 8.142e-06  max_mem: 49046M
[03/05 14:30:21 d2.utils.events]:  eta: 1 day, 13:12:07  iter: 20439  total_loss: 10.15  loss_ce0: 0.6756  loss_ce1: 1.185  loss_ce2: 1.28  loss_ce3: 0.8056  loss_ce4: 0.9605  loss_ce5: 2.518  loss_ce6: 2.504    time: 1.6886  last_time: 1.7866  data_time: 0.0479  last_data_time: 0.0495   lr: 8.1401e-06  max_mem: 49046M
[03/05 14:30:55 d2.utils.events]:  eta: 1 day, 13:11:48  iter: 20459  total_loss: 10.03  loss_ce0: 0.6938  loss_ce1: 1.286  loss_ce2: 1.104  loss_ce3: 0.8582  loss_ce4: 1.057  loss_ce5: 2.575  loss_ce6: 2.556    time: 1.6886  last_time: 1.6687  data_time: 0.0463  last_data_time: 0.0439   lr: 8.1383e-06  max_mem: 49046M
[03/05 14:31:29 d2.utils.events]:  eta: 1 day, 13:11:21  iter: 20479  total_loss: 9.887  loss_ce0: 0.6655  loss_ce1: 1.192  loss_ce2: 1.171  loss_ce3: 0.7962  loss_ce4: 0.9635  loss_ce5: 2.367  loss_ce6: 2.42    time: 1.6889  last_time: 1.6296  data_time: 0.0465  last_data_time: 0.0432   lr: 8.1364e-06  max_mem: 49046M
[03/05 14:32:02 d2.utils.events]:  eta: 1 day, 13:11:07  iter: 20499  total_loss: 10.02  loss_ce0: 0.685  loss_ce1: 1.197  loss_ce2: 1.125  loss_ce3: 0.8553  loss_ce4: 1.003  loss_ce5: 2.458  loss_ce6: 2.62    time: 1.6886  last_time: 1.6844  data_time: 0.0461  last_data_time: 0.0432   lr: 8.1346e-06  max_mem: 49046M
[03/05 14:32:36 d2.utils.events]:  eta: 1 day, 13:11:03  iter: 20519  total_loss: 10.24  loss_ce0: 0.6996  loss_ce1: 1.189  loss_ce2: 1.077  loss_ce3: 0.7822  loss_ce4: 0.9824  loss_ce5: 2.265  loss_ce6: 2.537    time: 1.6889  last_time: 1.6327  data_time: 0.0477  last_data_time: 0.0458   lr: 8.1327e-06  max_mem: 49046M
[03/05 14:33:10 d2.utils.events]:  eta: 1 day, 13:11:15  iter: 20539  total_loss: 9.77  loss_ce0: 0.702  loss_ce1: 1.225  loss_ce2: 0.9679  loss_ce3: 0.7308  loss_ce4: 0.9904  loss_ce5: 2.303  loss_ce6: 2.532    time: 1.6892  last_time: 1.6357  data_time: 0.0482  last_data_time: 0.0470   lr: 8.1309e-06  max_mem: 49046M
[03/05 14:33:45 d2.utils.events]:  eta: 1 day, 13:11:10  iter: 20559  total_loss: 9.994  loss_ce0: 0.7023  loss_ce1: 1.139  loss_ce2: 1.244  loss_ce3: 0.794  loss_ce4: 0.9626  loss_ce5: 2.535  loss_ce6: 2.38    time: 1.6902  last_time: 1.6735  data_time: 0.0467  last_data_time: 0.0435   lr: 8.1291e-06  max_mem: 49046M
[03/05 14:34:19 d2.utils.events]:  eta: 1 day, 13:11:01  iter: 20579  total_loss: 10.46  loss_ce0: 0.6939  loss_ce1: 1.206  loss_ce2: 1.254  loss_ce3: 0.7823  loss_ce4: 0.9996  loss_ce5: 2.661  loss_ce6: 2.612    time: 1.6910  last_time: 1.7646  data_time: 0.0482  last_data_time: 0.0476   lr: 8.1272e-06  max_mem: 49046M
[03/05 14:34:53 d2.utils.events]:  eta: 1 day, 13:10:27  iter: 20599  total_loss: 10.6  loss_ce0: 0.7038  loss_ce1: 1.25  loss_ce2: 1.268  loss_ce3: 0.7933  loss_ce4: 1.013  loss_ce5: 2.458  loss_ce6: 2.897    time: 1.6911  last_time: 1.6818  data_time: 0.0480  last_data_time: 0.0470   lr: 8.1254e-06  max_mem: 49046M
[03/05 14:35:27 d2.utils.events]:  eta: 1 day, 13:10:13  iter: 20619  total_loss: 10.08  loss_ce0: 0.7147  loss_ce1: 1.234  loss_ce2: 1.09  loss_ce3: 0.889  loss_ce4: 1.015  loss_ce5: 2.503  loss_ce6: 2.433    time: 1.6910  last_time: 1.6943  data_time: 0.0484  last_data_time: 0.0429   lr: 8.1235e-06  max_mem: 49046M
[03/05 14:36:01 d2.utils.events]:  eta: 1 day, 13:09:52  iter: 20639  total_loss: 10.01  loss_ce0: 0.6837  loss_ce1: 1.129  loss_ce2: 1.204  loss_ce3: 0.7914  loss_ce4: 1.066  loss_ce5: 2.564  loss_ce6: 2.463    time: 1.6914  last_time: 1.7636  data_time: 0.0482  last_data_time: 0.0560   lr: 8.1217e-06  max_mem: 49046M
[03/05 14:36:35 d2.utils.events]:  eta: 1 day, 13:10:23  iter: 20659  total_loss: 10.33  loss_ce0: 0.7283  loss_ce1: 1.219  loss_ce2: 1.235  loss_ce3: 0.7835  loss_ce4: 1.051  loss_ce5: 2.456  loss_ce6: 2.6    time: 1.6916  last_time: 1.7285  data_time: 0.0488  last_data_time: 0.0556   lr: 8.1198e-06  max_mem: 49046M
[03/05 14:37:09 d2.utils.events]:  eta: 1 day, 13:09:59  iter: 20679  total_loss: 9.985  loss_ce0: 0.6877  loss_ce1: 1.194  loss_ce2: 1.301  loss_ce3: 0.8311  loss_ce4: 1.026  loss_ce5: 2.633  loss_ce6: 2.215    time: 1.6919  last_time: 1.6419  data_time: 0.0486  last_data_time: 0.0479   lr: 8.118e-06  max_mem: 49046M
[03/05 14:37:43 d2.utils.events]:  eta: 1 day, 13:09:52  iter: 20699  total_loss: 10.5  loss_ce0: 0.7193  loss_ce1: 1.193  loss_ce2: 1.342  loss_ce3: 0.814  loss_ce4: 0.9878  loss_ce5: 2.391  loss_ce6: 2.608    time: 1.6926  last_time: 1.8136  data_time: 0.0483  last_data_time: 0.0523   lr: 8.1162e-06  max_mem: 49046M
[03/05 14:38:17 d2.utils.events]:  eta: 1 day, 13:09:18  iter: 20719  total_loss: 10.12  loss_ce0: 0.686  loss_ce1: 1.257  loss_ce2: 1.155  loss_ce3: 0.8405  loss_ce4: 0.9819  loss_ce5: 2.454  loss_ce6: 2.549    time: 1.6925  last_time: 1.6281  data_time: 0.0488  last_data_time: 0.0512   lr: 8.1143e-06  max_mem: 49046M
[03/05 14:38:51 d2.utils.events]:  eta: 1 day, 13:09:13  iter: 20739  total_loss: 10.27  loss_ce0: 0.6919  loss_ce1: 1.28  loss_ce2: 1.062  loss_ce3: 0.8698  loss_ce4: 0.9837  loss_ce5: 2.307  loss_ce6: 2.568    time: 1.6929  last_time: 1.6736  data_time: 0.0497  last_data_time: 0.0442   lr: 8.1125e-06  max_mem: 49046M
[03/05 14:39:25 d2.utils.events]:  eta: 1 day, 13:08:39  iter: 20759  total_loss: 10.19  loss_ce0: 0.692  loss_ce1: 1.16  loss_ce2: 1.37  loss_ce3: 0.8363  loss_ce4: 1.005  loss_ce5: 2.395  loss_ce6: 2.708    time: 1.6929  last_time: 1.6859  data_time: 0.0505  last_data_time: 0.0449   lr: 8.1106e-06  max_mem: 49046M
[03/05 14:39:59 d2.utils.events]:  eta: 1 day, 13:08:46  iter: 20779  total_loss: 10.06  loss_ce0: 0.6919  loss_ce1: 1.269  loss_ce2: 1.276  loss_ce3: 0.8386  loss_ce4: 0.9466  loss_ce5: 2.339  loss_ce6: 2.656    time: 1.6931  last_time: 1.7162  data_time: 0.0480  last_data_time: 0.0456   lr: 8.1088e-06  max_mem: 49046M
[03/05 14:40:33 d2.utils.events]:  eta: 1 day, 13:08:31  iter: 20799  total_loss: 10.31  loss_ce0: 0.6933  loss_ce1: 1.287  loss_ce2: 1.286  loss_ce3: 0.7684  loss_ce4: 0.9788  loss_ce5: 2.367  loss_ce6: 2.533    time: 1.6930  last_time: 1.6484  data_time: 0.0471  last_data_time: 0.0532   lr: 8.107e-06  max_mem: 49046M
[03/05 14:41:07 d2.utils.events]:  eta: 1 day, 13:08:12  iter: 20819  total_loss: 9.852  loss_ce0: 0.7324  loss_ce1: 1.195  loss_ce2: 1.17  loss_ce3: 0.8162  loss_ce4: 1.024  loss_ce5: 2.347  loss_ce6: 2.467    time: 1.6933  last_time: 1.7013  data_time: 0.0500  last_data_time: 0.0502   lr: 8.1051e-06  max_mem: 49046M
[03/05 14:41:41 d2.utils.events]:  eta: 1 day, 13:07:40  iter: 20839  total_loss: 10.47  loss_ce0: 0.6962  loss_ce1: 1.291  loss_ce2: 1.351  loss_ce3: 0.8569  loss_ce4: 0.9842  loss_ce5: 2.417  loss_ce6: 2.956    time: 1.6935  last_time: 1.6929  data_time: 0.0496  last_data_time: 0.0501   lr: 8.1033e-06  max_mem: 49046M
[03/05 14:42:15 d2.utils.events]:  eta: 1 day, 13:07:59  iter: 20859  total_loss: 9.867  loss_ce0: 0.7187  loss_ce1: 1.164  loss_ce2: 1.282  loss_ce3: 0.7222  loss_ce4: 0.9592  loss_ce5: 2.32  loss_ce6: 2.479    time: 1.6938  last_time: 1.6901  data_time: 0.0495  last_data_time: 0.0461   lr: 8.1014e-06  max_mem: 49046M
[03/05 14:42:49 d2.utils.events]:  eta: 1 day, 13:07:42  iter: 20879  total_loss: 10.22  loss_ce0: 0.6942  loss_ce1: 1.113  loss_ce2: 1.257  loss_ce3: 0.851  loss_ce4: 1.005  loss_ce5: 2.476  loss_ce6: 2.545    time: 1.6939  last_time: 1.7076  data_time: 0.0489  last_data_time: 0.0539   lr: 8.0996e-06  max_mem: 49046M
[03/05 14:43:24 d2.utils.events]:  eta: 1 day, 13:07:26  iter: 20899  total_loss: 10.14  loss_ce0: 0.7012  loss_ce1: 1.166  loss_ce2: 1.094  loss_ce3: 0.7434  loss_ce4: 0.9886  loss_ce5: 2.341  loss_ce6: 2.558    time: 1.6943  last_time: 1.6825  data_time: 0.0514  last_data_time: 0.0532   lr: 8.0977e-06  max_mem: 49046M
[03/05 14:43:58 d2.utils.events]:  eta: 1 day, 13:07:32  iter: 20919  total_loss: 10.05  loss_ce0: 0.7179  loss_ce1: 1.16  loss_ce2: 1.24  loss_ce3: 0.7754  loss_ce4: 0.9866  loss_ce5: 2.832  loss_ce6: 2.466    time: 1.6952  last_time: 1.6527  data_time: 0.0521  last_data_time: 0.0465   lr: 8.0959e-06  max_mem: 49046M
[03/05 14:44:33 d2.utils.events]:  eta: 1 day, 13:07:39  iter: 20939  total_loss: 9.993  loss_ce0: 0.6721  loss_ce1: 1.223  loss_ce2: 1.228  loss_ce3: 0.7802  loss_ce4: 1.013  loss_ce5: 2.417  loss_ce6: 2.458    time: 1.6956  last_time: 1.6838  data_time: 0.0508  last_data_time: 0.0617   lr: 8.0941e-06  max_mem: 49046M
[03/05 14:45:07 d2.utils.events]:  eta: 1 day, 13:07:08  iter: 20959  total_loss: 10.19  loss_ce0: 0.7135  loss_ce1: 1.206  loss_ce2: 1.102  loss_ce3: 0.883  loss_ce4: 0.9912  loss_ce5: 2.302  loss_ce6: 2.701    time: 1.6957  last_time: 1.7439  data_time: 0.0549  last_data_time: 0.0550   lr: 8.0922e-06  max_mem: 49046M
[03/05 14:45:41 d2.utils.events]:  eta: 1 day, 13:06:47  iter: 20979  total_loss: 10.31  loss_ce0: 0.7505  loss_ce1: 1.172  loss_ce2: 1.294  loss_ce3: 0.8433  loss_ce4: 0.9798  loss_ce5: 2.465  loss_ce6: 2.347    time: 1.6959  last_time: 1.8547  data_time: 0.0512  last_data_time: 0.0512   lr: 8.0904e-06  max_mem: 49046M
[03/05 14:46:15 d2.utils.events]:  eta: 1 day, 13:06:08  iter: 20999  total_loss: 9.964  loss_ce0: 0.7025  loss_ce1: 1.149  loss_ce2: 1.38  loss_ce3: 0.7691  loss_ce4: 0.9815  loss_ce5: 2.42  loss_ce6: 2.664    time: 1.6958  last_time: 1.6792  data_time: 0.0521  last_data_time: 0.0488   lr: 8.0885e-06  max_mem: 49046M
[03/05 14:46:49 d2.utils.events]:  eta: 1 day, 13:06:08  iter: 21019  total_loss: 10.23  loss_ce0: 0.7057  loss_ce1: 1.14  loss_ce2: 1.238  loss_ce3: 0.7804  loss_ce4: 0.9612  loss_ce5: 2.348  loss_ce6: 2.611    time: 1.6959  last_time: 1.7346  data_time: 0.0527  last_data_time: 0.0529   lr: 8.0867e-06  max_mem: 49046M
[03/05 14:47:22 d2.utils.events]:  eta: 1 day, 13:06:07  iter: 21039  total_loss: 10.13  loss_ce0: 0.7135  loss_ce1: 1.269  loss_ce2: 1.294  loss_ce3: 0.7632  loss_ce4: 0.9826  loss_ce5: 2.287  loss_ce6: 2.733    time: 1.6956  last_time: 1.6321  data_time: 0.0506  last_data_time: 0.0461   lr: 8.0848e-06  max_mem: 49046M
[03/05 14:47:56 d2.utils.events]:  eta: 1 day, 13:05:42  iter: 21059  total_loss: 10  loss_ce0: 0.7252  loss_ce1: 1.21  loss_ce2: 1.229  loss_ce3: 0.8497  loss_ce4: 1.048  loss_ce5: 2.584  loss_ce6: 2.373    time: 1.6953  last_time: 1.6298  data_time: 0.0514  last_data_time: 0.0418   lr: 8.083e-06  max_mem: 49046M
[03/05 14:48:30 d2.utils.events]:  eta: 1 day, 13:05:47  iter: 21079  total_loss: 10.09  loss_ce0: 0.7377  loss_ce1: 1.2  loss_ce2: 1.266  loss_ce3: 0.8887  loss_ce4: 1.04  loss_ce5: 2.406  loss_ce6: 2.498    time: 1.6951  last_time: 1.6241  data_time: 0.0488  last_data_time: 0.0476   lr: 8.0812e-06  max_mem: 49046M
[03/05 14:49:04 d2.utils.events]:  eta: 1 day, 13:05:13  iter: 21099  total_loss: 10.02  loss_ce0: 0.6984  loss_ce1: 1.227  loss_ce2: 1.168  loss_ce3: 0.7676  loss_ce4: 0.9753  loss_ce5: 2.413  loss_ce6: 2.721    time: 1.6953  last_time: 1.6966  data_time: 0.0505  last_data_time: 0.0455   lr: 8.0793e-06  max_mem: 49046M
[03/05 14:49:38 d2.utils.events]:  eta: 1 day, 13:05:16  iter: 21119  total_loss: 9.9  loss_ce0: 0.7051  loss_ce1: 1.125  loss_ce2: 1.217  loss_ce3: 0.9068  loss_ce4: 0.963  loss_ce5: 2.337  loss_ce6: 2.479    time: 1.6956  last_time: 1.7428  data_time: 0.0538  last_data_time: 0.0528   lr: 8.0775e-06  max_mem: 49046M
[03/05 14:50:13 d2.utils.events]:  eta: 1 day, 13:05:19  iter: 21139  total_loss: 9.794  loss_ce0: 0.7121  loss_ce1: 1.187  loss_ce2: 1.1  loss_ce3: 0.804  loss_ce4: 0.9642  loss_ce5: 2.455  loss_ce6: 2.374    time: 1.6963  last_time: 1.7107  data_time: 0.0546  last_data_time: 0.0500   lr: 8.0756e-06  max_mem: 49046M
[03/05 14:50:47 d2.utils.events]:  eta: 1 day, 13:05:36  iter: 21159  total_loss: 10.08  loss_ce0: 0.7375  loss_ce1: 1.242  loss_ce2: 1.329  loss_ce3: 0.8027  loss_ce4: 1.019  loss_ce5: 2.333  loss_ce6: 2.569    time: 1.6968  last_time: 1.6839  data_time: 0.0549  last_data_time: 0.0492   lr: 8.0738e-06  max_mem: 49046M
[03/05 14:51:22 d2.utils.events]:  eta: 1 day, 13:05:11  iter: 21179  total_loss: 10.22  loss_ce0: 0.6911  loss_ce1: 1.171  loss_ce2: 1.291  loss_ce3: 0.8941  loss_ce4: 1.007  loss_ce5: 2.546  loss_ce6: 2.596    time: 1.6971  last_time: 1.6820  data_time: 0.0522  last_data_time: 0.0488   lr: 8.0719e-06  max_mem: 49046M
[03/05 14:51:56 d2.utils.events]:  eta: 1 day, 13:06:10  iter: 21199  total_loss: 10.63  loss_ce0: 0.6948  loss_ce1: 1.268  loss_ce2: 1.339  loss_ce3: 0.8583  loss_ce4: 0.9897  loss_ce5: 2.285  loss_ce6: 2.472    time: 1.6973  last_time: 1.7088  data_time: 0.0521  last_data_time: 0.0540   lr: 8.0701e-06  max_mem: 49046M
[03/05 14:52:30 d2.utils.events]:  eta: 1 day, 13:06:08  iter: 21219  total_loss: 10.26  loss_ce0: 0.7163  loss_ce1: 1.165  loss_ce2: 1.302  loss_ce3: 0.7837  loss_ce4: 1.058  loss_ce5: 2.296  loss_ce6: 2.454    time: 1.6972  last_time: 1.6604  data_time: 0.0552  last_data_time: 0.0496   lr: 8.0682e-06  max_mem: 49046M
[03/05 14:53:03 d2.utils.events]:  eta: 1 day, 13:04:54  iter: 21239  total_loss: 10.28  loss_ce0: 0.7164  loss_ce1: 1.251  loss_ce2: 1.441  loss_ce3: 0.7227  loss_ce4: 0.9512  loss_ce5: 2.397  loss_ce6: 2.767    time: 1.6965  last_time: 1.6547  data_time: 0.0484  last_data_time: 0.0467   lr: 8.0664e-06  max_mem: 49046M
[03/05 14:53:36 d2.utils.events]:  eta: 1 day, 13:03:19  iter: 21259  total_loss: 10.15  loss_ce0: 0.6972  loss_ce1: 1.185  loss_ce2: 1.293  loss_ce3: 0.8052  loss_ce4: 0.9782  loss_ce5: 2.247  loss_ce6: 2.505    time: 1.6959  last_time: 1.6171  data_time: 0.0488  last_data_time: 0.0466   lr: 8.0646e-06  max_mem: 49046M
[03/05 14:54:09 d2.utils.events]:  eta: 1 day, 13:02:22  iter: 21279  total_loss: 10.52  loss_ce0: 0.7056  loss_ce1: 1.21  loss_ce2: 1.131  loss_ce3: 0.8198  loss_ce4: 1.069  loss_ce5: 2.479  loss_ce6: 2.564    time: 1.6954  last_time: 1.6959  data_time: 0.0477  last_data_time: 0.0490   lr: 8.0627e-06  max_mem: 49046M
[03/05 14:54:43 d2.utils.events]:  eta: 1 day, 13:01:22  iter: 21299  total_loss: 10.39  loss_ce0: 0.7032  loss_ce1: 1.202  loss_ce2: 1.194  loss_ce3: 0.7802  loss_ce4: 1.047  loss_ce5: 2.092  loss_ce6: 2.811    time: 1.6952  last_time: 1.6512  data_time: 0.0480  last_data_time: 0.0460   lr: 8.0609e-06  max_mem: 49046M
[03/05 14:55:16 d2.utils.events]:  eta: 1 day, 12:59:40  iter: 21319  total_loss: 10.45  loss_ce0: 0.6993  loss_ce1: 1.176  loss_ce2: 1.212  loss_ce3: 0.8645  loss_ce4: 1.041  loss_ce5: 2.317  loss_ce6: 2.402    time: 1.6946  last_time: 1.7036  data_time: 0.0490  last_data_time: 0.0475   lr: 8.059e-06  max_mem: 49046M
[03/05 14:55:50 d2.utils.events]:  eta: 1 day, 12:59:11  iter: 21339  total_loss: 10.3  loss_ce0: 0.6931  loss_ce1: 1.193  loss_ce2: 1.339  loss_ce3: 0.878  loss_ce4: 0.9938  loss_ce5: 2.283  loss_ce6: 2.735    time: 1.6944  last_time: 1.7010  data_time: 0.0490  last_data_time: 0.0491   lr: 8.0572e-06  max_mem: 49046M
[03/05 14:56:23 d2.utils.events]:  eta: 1 day, 12:58:37  iter: 21359  total_loss: 9.884  loss_ce0: 0.701  loss_ce1: 1.165  loss_ce2: 1.335  loss_ce3: 0.7934  loss_ce4: 0.9402  loss_ce5: 2.24  loss_ce6: 2.469    time: 1.6940  last_time: 1.6534  data_time: 0.0483  last_data_time: 0.0516   lr: 8.0553e-06  max_mem: 49046M
[03/05 14:56:56 d2.utils.events]:  eta: 1 day, 12:57:04  iter: 21379  total_loss: 10.03  loss_ce0: 0.7233  loss_ce1: 1.168  loss_ce2: 1.124  loss_ce3: 0.8081  loss_ce4: 0.9566  loss_ce5: 2.496  loss_ce6: 2.316    time: 1.6935  last_time: 1.6643  data_time: 0.0479  last_data_time: 0.0495   lr: 8.0535e-06  max_mem: 49046M
[03/05 14:57:29 d2.utils.events]:  eta: 1 day, 12:55:17  iter: 21399  total_loss: 10.22  loss_ce0: 0.7096  loss_ce1: 1.254  loss_ce2: 1.266  loss_ce3: 0.785  loss_ce4: 1.022  loss_ce5: 2.368  loss_ce6: 2.58    time: 1.6929  last_time: 1.6617  data_time: 0.0486  last_data_time: 0.0503   lr: 8.0517e-06  max_mem: 49046M
[03/05 14:58:03 d2.utils.events]:  eta: 1 day, 12:53:59  iter: 21419  total_loss: 9.956  loss_ce0: 0.7095  loss_ce1: 1.225  loss_ce2: 1.182  loss_ce3: 0.7797  loss_ce4: 1.011  loss_ce5: 2.217  loss_ce6: 2.471    time: 1.6924  last_time: 1.6060  data_time: 0.0469  last_data_time: 0.0446   lr: 8.0498e-06  max_mem: 49046M
[03/05 14:58:35 d2.utils.events]:  eta: 1 day, 12:52:17  iter: 21439  total_loss: 10.25  loss_ce0: 0.7189  loss_ce1: 1.224  loss_ce2: 1.193  loss_ce3: 0.7815  loss_ce4: 0.9789  loss_ce5: 2.366  loss_ce6: 2.459    time: 1.6917  last_time: 1.6052  data_time: 0.0482  last_data_time: 0.0457   lr: 8.048e-06  max_mem: 49046M
[03/05 14:59:09 d2.utils.events]:  eta: 1 day, 12:50:56  iter: 21459  total_loss: 10.56  loss_ce0: 0.7312  loss_ce1: 1.165  loss_ce2: 1.149  loss_ce3: 0.8732  loss_ce4: 1.001  loss_ce5: 2.343  loss_ce6: 2.787    time: 1.6911  last_time: 1.6167  data_time: 0.0500  last_data_time: 0.0498   lr: 8.0461e-06  max_mem: 49046M
[03/05 14:59:42 d2.utils.events]:  eta: 1 day, 12:49:47  iter: 21479  total_loss: 9.595  loss_ce0: 0.7399  loss_ce1: 1.2  loss_ce2: 1.177  loss_ce3: 0.7858  loss_ce4: 0.9996  loss_ce5: 2.324  loss_ce6: 2.375    time: 1.6907  last_time: 1.6117  data_time: 0.0470  last_data_time: 0.0488   lr: 8.0443e-06  max_mem: 49046M
[03/05 15:00:15 d2.utils.events]:  eta: 1 day, 12:48:37  iter: 21499  total_loss: 9.904  loss_ce0: 0.7058  loss_ce1: 1.147  loss_ce2: 1.211  loss_ce3: 0.8881  loss_ce4: 1.038  loss_ce5: 2.376  loss_ce6: 2.256    time: 1.6902  last_time: 1.6166  data_time: 0.0466  last_data_time: 0.0413   lr: 8.0424e-06  max_mem: 49046M
[03/05 15:00:47 d2.utils.events]:  eta: 1 day, 12:46:17  iter: 21519  total_loss: 11.09  loss_ce0: 0.7057  loss_ce1: 1.252  loss_ce2: 1.229  loss_ce3: 0.8467  loss_ce4: 0.9893  loss_ce5: 2.452  loss_ce6: 2.888    time: 1.6894  last_time: 1.6978  data_time: 0.0474  last_data_time: 0.0500   lr: 8.0406e-06  max_mem: 49046M
[03/05 15:01:21 d2.utils.events]:  eta: 1 day, 12:44:35  iter: 21539  total_loss: 9.963  loss_ce0: 0.7031  loss_ce1: 1.309  loss_ce2: 1.17  loss_ce3: 0.7884  loss_ce4: 1.013  loss_ce5: 2.385  loss_ce6: 2.402    time: 1.6890  last_time: 1.6041  data_time: 0.0468  last_data_time: 0.0393   lr: 8.0387e-06  max_mem: 49046M
[03/05 15:01:54 d2.utils.events]:  eta: 1 day, 12:42:52  iter: 21559  total_loss: 9.896  loss_ce0: 0.7213  loss_ce1: 1.194  loss_ce2: 1.361  loss_ce3: 0.8262  loss_ce4: 1.046  loss_ce5: 2.411  loss_ce6: 2.272    time: 1.6887  last_time: 1.6587  data_time: 0.0459  last_data_time: 0.0466   lr: 8.0369e-06  max_mem: 49046M
[03/05 15:02:27 d2.utils.events]:  eta: 1 day, 12:41:30  iter: 21579  total_loss: 10.14  loss_ce0: 0.7223  loss_ce1: 1.203  loss_ce2: 1.164  loss_ce3: 0.8659  loss_ce4: 1.026  loss_ce5: 2.337  loss_ce6: 2.499    time: 1.6883  last_time: 1.6458  data_time: 0.0478  last_data_time: 0.0479   lr: 8.0351e-06  max_mem: 49046M
[03/05 15:03:00 d2.utils.events]:  eta: 1 day, 12:40:21  iter: 21599  total_loss: 10.14  loss_ce0: 0.697  loss_ce1: 1.226  loss_ce2: 1.175  loss_ce3: 0.8223  loss_ce4: 1.034  loss_ce5: 2.173  loss_ce6: 2.578    time: 1.6878  last_time: 1.6069  data_time: 0.0452  last_data_time: 0.0494   lr: 8.0332e-06  max_mem: 49046M
[03/05 15:03:34 d2.utils.events]:  eta: 1 day, 12:39:12  iter: 21619  total_loss: 9.979  loss_ce0: 0.7344  loss_ce1: 1.118  loss_ce2: 1.151  loss_ce3: 0.8259  loss_ce4: 0.9714  loss_ce5: 2.368  loss_ce6: 2.625    time: 1.6876  last_time: 1.6288  data_time: 0.0472  last_data_time: 0.0456   lr: 8.0314e-06  max_mem: 49046M
[03/05 15:04:07 d2.utils.events]:  eta: 1 day, 12:37:45  iter: 21639  total_loss: 9.895  loss_ce0: 0.687  loss_ce1: 1.166  loss_ce2: 1.05  loss_ce3: 0.7478  loss_ce4: 1.004  loss_ce5: 2.313  loss_ce6: 2.512    time: 1.6873  last_time: 1.5981  data_time: 0.0453  last_data_time: 0.0436   lr: 8.0295e-06  max_mem: 49046M
[03/05 15:04:40 d2.utils.events]:  eta: 1 day, 12:35:16  iter: 21659  total_loss: 10.04  loss_ce0: 0.7205  loss_ce1: 1.162  loss_ce2: 1.217  loss_ce3: 0.7937  loss_ce4: 0.9827  loss_ce5: 2.526  loss_ce6: 2.233    time: 1.6870  last_time: 1.6779  data_time: 0.0455  last_data_time: 0.0462   lr: 8.0277e-06  max_mem: 49046M
[03/05 15:05:13 d2.utils.events]:  eta: 1 day, 12:32:30  iter: 21679  total_loss: 10.06  loss_ce0: 0.73  loss_ce1: 1.222  loss_ce2: 1.24  loss_ce3: 0.7987  loss_ce4: 0.9788  loss_ce5: 2.252  loss_ce6: 2.465    time: 1.6864  last_time: 1.6703  data_time: 0.0460  last_data_time: 0.0478   lr: 8.0258e-06  max_mem: 49046M
[03/05 15:05:46 d2.utils.events]:  eta: 1 day, 12:30:11  iter: 21699  total_loss: 9.833  loss_ce0: 0.7161  loss_ce1: 1.201  loss_ce2: 1.159  loss_ce3: 0.8742  loss_ce4: 0.976  loss_ce5: 2.219  loss_ce6: 2.622    time: 1.6861  last_time: 1.6546  data_time: 0.0460  last_data_time: 0.0490   lr: 8.024e-06  max_mem: 49046M
[03/05 15:06:19 d2.utils.events]:  eta: 1 day, 12:29:04  iter: 21719  total_loss: 9.788  loss_ce0: 0.7127  loss_ce1: 1.169  loss_ce2: 1.42  loss_ce3: 0.8262  loss_ce4: 0.997  loss_ce5: 2.341  loss_ce6: 2.238    time: 1.6857  last_time: 1.6034  data_time: 0.0466  last_data_time: 0.0483   lr: 8.0221e-06  max_mem: 49046M
[03/05 15:06:52 d2.utils.events]:  eta: 1 day, 12:26:45  iter: 21739  total_loss: 10.07  loss_ce0: 0.7038  loss_ce1: 1.251  loss_ce2: 1.143  loss_ce3: 0.8492  loss_ce4: 1.009  loss_ce5: 2.343  loss_ce6: 2.535    time: 1.6853  last_time: 1.6988  data_time: 0.0456  last_data_time: 0.0474   lr: 8.0203e-06  max_mem: 49046M
[03/05 15:07:25 d2.utils.events]:  eta: 1 day, 12:25:06  iter: 21759  total_loss: 10.02  loss_ce0: 0.7131  loss_ce1: 1.213  loss_ce2: 1.294  loss_ce3: 0.7956  loss_ce4: 0.9845  loss_ce5: 2.26  loss_ce6: 2.436    time: 1.6849  last_time: 1.6476  data_time: 0.0447  last_data_time: 0.0488   lr: 8.0185e-06  max_mem: 49046M
[03/05 15:07:59 d2.utils.events]:  eta: 1 day, 12:23:51  iter: 21779  total_loss: 9.902  loss_ce0: 0.689  loss_ce1: 1.181  loss_ce2: 1.261  loss_ce3: 0.8021  loss_ce4: 1.048  loss_ce5: 2.269  loss_ce6: 2.494    time: 1.6849  last_time: 1.7317  data_time: 0.0490  last_data_time: 0.0514   lr: 8.0166e-06  max_mem: 49046M
[03/05 15:08:33 d2.utils.events]:  eta: 1 day, 12:22:25  iter: 21799  total_loss: 10.24  loss_ce0: 0.7352  loss_ce1: 1.207  loss_ce2: 1.231  loss_ce3: 0.8253  loss_ce4: 0.9966  loss_ce5: 2.339  loss_ce6: 2.787    time: 1.6849  last_time: 1.6204  data_time: 0.0476  last_data_time: 0.0461   lr: 8.0148e-06  max_mem: 49046M
[03/05 15:09:06 d2.utils.events]:  eta: 1 day, 12:19:43  iter: 21819  total_loss: 9.894  loss_ce0: 0.6792  loss_ce1: 1.159  loss_ce2: 1.163  loss_ce3: 0.8004  loss_ce4: 1.034  loss_ce5: 2.425  loss_ce6: 2.483    time: 1.6846  last_time: 1.6072  data_time: 0.0508  last_data_time: 0.0465   lr: 8.0129e-06  max_mem: 49046M
[03/05 15:09:40 d2.utils.events]:  eta: 1 day, 12:18:49  iter: 21839  total_loss: 9.631  loss_ce0: 0.7416  loss_ce1: 1.212  loss_ce2: 1.116  loss_ce3: 0.7833  loss_ce4: 1.017  loss_ce5: 2.236  loss_ce6: 2.421    time: 1.6847  last_time: 1.6081  data_time: 0.0473  last_data_time: 0.0463   lr: 8.0111e-06  max_mem: 49046M
[03/05 15:10:13 d2.utils.events]:  eta: 1 day, 12:17:07  iter: 21859  total_loss: 10.06  loss_ce0: 0.7082  loss_ce1: 1.223  loss_ce2: 1.286  loss_ce3: 0.7998  loss_ce4: 1.017  loss_ce5: 2.497  loss_ce6: 2.447    time: 1.6843  last_time: 1.6666  data_time: 0.0457  last_data_time: 0.0438   lr: 8.0092e-06  max_mem: 49046M
[03/05 15:10:46 d2.utils.events]:  eta: 1 day, 12:15:30  iter: 21879  total_loss: 10.36  loss_ce0: 0.7157  loss_ce1: 1.179  loss_ce2: 1.156  loss_ce3: 0.8261  loss_ce4: 1.012  loss_ce5: 2.364  loss_ce6: 2.449    time: 1.6843  last_time: 1.5992  data_time: 0.0459  last_data_time: 0.0444   lr: 8.0074e-06  max_mem: 49046M
[03/05 15:11:19 d2.utils.events]:  eta: 1 day, 12:13:12  iter: 21899  total_loss: 9.907  loss_ce0: 0.6801  loss_ce1: 1.237  loss_ce2: 1.135  loss_ce3: 0.7192  loss_ce4: 1.002  loss_ce5: 2.26  loss_ce6: 2.479    time: 1.6839  last_time: 1.6224  data_time: 0.0453  last_data_time: 0.0448   lr: 8.0055e-06  max_mem: 49046M
[03/05 15:11:53 d2.utils.events]:  eta: 1 day, 12:11:38  iter: 21919  total_loss: 9.966  loss_ce0: 0.6903  loss_ce1: 1.093  loss_ce2: 1.216  loss_ce3: 0.7786  loss_ce4: 0.9663  loss_ce5: 2.335  loss_ce6: 2.597    time: 1.6836  last_time: 1.6031  data_time: 0.0454  last_data_time: 0.0410   lr: 8.0037e-06  max_mem: 49046M
[03/05 15:12:26 d2.utils.events]:  eta: 1 day, 12:09:46  iter: 21939  total_loss: 10.15  loss_ce0: 0.6855  loss_ce1: 1.132  loss_ce2: 1.189  loss_ce3: 0.9086  loss_ce4: 0.9854  loss_ce5: 2.506  loss_ce6: 2.6    time: 1.6833  last_time: 1.6260  data_time: 0.0484  last_data_time: 0.0471   lr: 8.0019e-06  max_mem: 49046M
[03/05 15:12:59 d2.utils.events]:  eta: 1 day, 12:08:09  iter: 21959  total_loss: 9.53  loss_ce0: 0.7277  loss_ce1: 1.158  loss_ce2: 1.046  loss_ce3: 0.8248  loss_ce4: 0.9843  loss_ce5: 2.266  loss_ce6: 2.353    time: 1.6831  last_time: 1.6211  data_time: 0.0469  last_data_time: 0.0455   lr: 8e-06  max_mem: 49046M
[03/05 15:13:32 d2.utils.events]:  eta: 1 day, 12:06:12  iter: 21979  total_loss: 9.941  loss_ce0: 0.7053  loss_ce1: 1.118  loss_ce2: 1.179  loss_ce3: 0.7616  loss_ce4: 1.055  loss_ce5: 2.505  loss_ce6: 2.744    time: 1.6827  last_time: 1.6746  data_time: 0.0456  last_data_time: 0.0449   lr: 7.9982e-06  max_mem: 49046M
[03/05 15:14:05 d2.utils.events]:  eta: 1 day, 12:04:36  iter: 21999  total_loss: 9.697  loss_ce0: 0.7315  loss_ce1: 1.186  loss_ce2: 1.19  loss_ce3: 0.8481  loss_ce4: 0.9683  loss_ce5: 2.361  loss_ce6: 2.513    time: 1.6825  last_time: 1.6842  data_time: 0.0489  last_data_time: 0.0539   lr: 7.9963e-06  max_mem: 49046M
[03/05 15:14:38 d2.utils.events]:  eta: 1 day, 12:02:15  iter: 22019  total_loss: 9.859  loss_ce0: 0.7132  loss_ce1: 1.182  loss_ce2: 1.213  loss_ce3: 0.9134  loss_ce4: 1.003  loss_ce5: 2.329  loss_ce6: 2.314    time: 1.6821  last_time: 1.6204  data_time: 0.0455  last_data_time: 0.0482   lr: 7.9945e-06  max_mem: 49046M
[03/05 15:15:11 d2.utils.events]:  eta: 1 day, 12:00:59  iter: 22039  total_loss: 10.15  loss_ce0: 0.6902  loss_ce1: 1.198  loss_ce2: 1.271  loss_ce3: 0.8819  loss_ce4: 1.081  loss_ce5: 2.391  loss_ce6: 2.406    time: 1.6817  last_time: 1.6932  data_time: 0.0466  last_data_time: 0.0495   lr: 7.9926e-06  max_mem: 49046M
[03/05 15:15:44 d2.utils.events]:  eta: 1 day, 11:59:36  iter: 22059  total_loss: 9.895  loss_ce0: 0.6931  loss_ce1: 1.187  loss_ce2: 1.171  loss_ce3: 0.7693  loss_ce4: 1.007  loss_ce5: 2.306  loss_ce6: 2.483    time: 1.6815  last_time: 1.6625  data_time: 0.0476  last_data_time: 0.0494   lr: 7.9908e-06  max_mem: 49046M
[03/05 15:16:17 d2.utils.events]:  eta: 1 day, 11:58:34  iter: 22079  total_loss: 9.762  loss_ce0: 0.7186  loss_ce1: 1.181  loss_ce2: 1.183  loss_ce3: 0.7883  loss_ce4: 0.9683  loss_ce5: 2.253  loss_ce6: 2.285    time: 1.6813  last_time: 1.6646  data_time: 0.0471  last_data_time: 0.0459   lr: 7.9889e-06  max_mem: 49046M
[03/05 15:16:51 d2.utils.events]:  eta: 1 day, 11:57:17  iter: 22099  total_loss: 9.476  loss_ce0: 0.694  loss_ce1: 1.235  loss_ce2: 1.181  loss_ce3: 0.7511  loss_ce4: 0.9707  loss_ce5: 2.119  loss_ce6: 2.413    time: 1.6811  last_time: 1.6060  data_time: 0.0459  last_data_time: 0.0424   lr: 7.9871e-06  max_mem: 49046M
[03/05 15:17:24 d2.utils.events]:  eta: 1 day, 11:56:03  iter: 22119  total_loss: 9.985  loss_ce0: 0.7193  loss_ce1: 1.137  loss_ce2: 1.059  loss_ce3: 0.804  loss_ce4: 1.004  loss_ce5: 2.333  loss_ce6: 2.567    time: 1.6809  last_time: 1.6255  data_time: 0.0458  last_data_time: 0.0396   lr: 7.9852e-06  max_mem: 49046M
[03/05 15:17:57 d2.utils.events]:  eta: 1 day, 11:53:42  iter: 22139  total_loss: 9.809  loss_ce0: 0.7018  loss_ce1: 1.201  loss_ce2: 1.218  loss_ce3: 0.8472  loss_ce4: 0.9721  loss_ce5: 2.38  loss_ce6: 2.499    time: 1.6806  last_time: 1.5963  data_time: 0.0446  last_data_time: 0.0457   lr: 7.9834e-06  max_mem: 49046M
[03/05 15:18:30 d2.utils.events]:  eta: 1 day, 11:52:20  iter: 22159  total_loss: 10.12  loss_ce0: 0.6997  loss_ce1: 1.209  loss_ce2: 1.247  loss_ce3: 0.7943  loss_ce4: 1.029  loss_ce5: 2.463  loss_ce6: 2.633    time: 1.6805  last_time: 1.7509  data_time: 0.0459  last_data_time: 0.0435   lr: 7.9816e-06  max_mem: 49046M
[03/05 15:19:04 d2.utils.events]:  eta: 1 day, 11:50:33  iter: 22179  total_loss: 10.35  loss_ce0: 0.7082  loss_ce1: 1.196  loss_ce2: 1.357  loss_ce3: 0.7612  loss_ce4: 0.9552  loss_ce5: 2.389  loss_ce6: 2.615    time: 1.6804  last_time: 1.7863  data_time: 0.0440  last_data_time: 0.0446   lr: 7.9797e-06  max_mem: 49046M
[03/05 15:19:37 d2.utils.events]:  eta: 1 day, 11:48:53  iter: 22199  total_loss: 10.03  loss_ce0: 0.7241  loss_ce1: 1.141  loss_ce2: 1.171  loss_ce3: 0.8866  loss_ce4: 0.9849  loss_ce5: 2.385  loss_ce6: 2.391    time: 1.6802  last_time: 1.7821  data_time: 0.0453  last_data_time: 0.0460   lr: 7.9779e-06  max_mem: 49046M
[03/05 15:20:10 d2.utils.events]:  eta: 1 day, 11:45:09  iter: 22219  total_loss: 9.666  loss_ce0: 0.7041  loss_ce1: 1.178  loss_ce2: 1.147  loss_ce3: 0.7598  loss_ce4: 1.019  loss_ce5: 2.141  loss_ce6: 2.335    time: 1.6799  last_time: 1.5881  data_time: 0.0465  last_data_time: 0.0397   lr: 7.976e-06  max_mem: 49046M
[03/05 15:20:43 d2.utils.events]:  eta: 1 day, 11:44:32  iter: 22239  total_loss: 9.991  loss_ce0: 0.7188  loss_ce1: 1.175  loss_ce2: 1.036  loss_ce3: 0.8646  loss_ce4: 1.088  loss_ce5: 2.497  loss_ce6: 2.336    time: 1.6796  last_time: 1.6416  data_time: 0.0475  last_data_time: 0.0472   lr: 7.9742e-06  max_mem: 49046M
[03/05 15:21:16 d2.utils.events]:  eta: 1 day, 11:44:13  iter: 22259  total_loss: 10.3  loss_ce0: 0.7132  loss_ce1: 1.19  loss_ce2: 1.118  loss_ce3: 0.9337  loss_ce4: 1.002  loss_ce5: 2.318  loss_ce6: 2.935    time: 1.6794  last_time: 1.6763  data_time: 0.0472  last_data_time: 0.0464   lr: 7.9723e-06  max_mem: 49046M
[03/05 15:21:49 d2.utils.events]:  eta: 1 day, 11:43:44  iter: 22279  total_loss: 9.925  loss_ce0: 0.693  loss_ce1: 1.172  loss_ce2: 1.199  loss_ce3: 0.7954  loss_ce4: 0.9943  loss_ce5: 2.468  loss_ce6: 2.382    time: 1.6793  last_time: 1.5981  data_time: 0.0455  last_data_time: 0.0428   lr: 7.9705e-06  max_mem: 49046M
[03/05 15:22:22 d2.utils.events]:  eta: 1 day, 11:42:52  iter: 22299  total_loss: 10.23  loss_ce0: 0.691  loss_ce1: 1.187  loss_ce2: 1.193  loss_ce3: 0.9505  loss_ce4: 1.056  loss_ce5: 2.347  loss_ce6: 2.433    time: 1.6791  last_time: 1.7036  data_time: 0.0461  last_data_time: 0.0571   lr: 7.9686e-06  max_mem: 49046M
[03/05 15:22:56 d2.utils.events]:  eta: 1 day, 11:42:32  iter: 22319  total_loss: 9.975  loss_ce0: 0.6808  loss_ce1: 1.18  loss_ce2: 1.201  loss_ce3: 0.7971  loss_ce4: 1.027  loss_ce5: 2.47  loss_ce6: 2.512    time: 1.6791  last_time: 1.6693  data_time: 0.0470  last_data_time: 0.0510   lr: 7.9668e-06  max_mem: 49046M
[03/05 15:23:29 d2.utils.events]:  eta: 1 day, 11:41:18  iter: 22339  total_loss: 9.595  loss_ce0: 0.6902  loss_ce1: 1.111  loss_ce2: 1.245  loss_ce3: 0.835  loss_ce4: 1.01  loss_ce5: 2.049  loss_ce6: 2.501    time: 1.6789  last_time: 1.7057  data_time: 0.0438  last_data_time: 0.0436   lr: 7.9649e-06  max_mem: 49046M
[03/05 15:24:02 d2.utils.events]:  eta: 1 day, 11:38:41  iter: 22359  total_loss: 9.934  loss_ce0: 0.7147  loss_ce1: 1.201  loss_ce2: 1.119  loss_ce3: 0.7975  loss_ce4: 0.9564  loss_ce5: 2.305  loss_ce6: 2.504    time: 1.6787  last_time: 1.6033  data_time: 0.0448  last_data_time: 0.0436   lr: 7.9631e-06  max_mem: 49046M
[03/05 15:24:36 d2.utils.events]:  eta: 1 day, 11:37:41  iter: 22379  total_loss: 9.907  loss_ce0: 0.6958  loss_ce1: 1.247  loss_ce2: 1.342  loss_ce3: 0.8  loss_ce4: 0.9396  loss_ce5: 2.284  loss_ce6: 2.524    time: 1.6785  last_time: 1.7160  data_time: 0.0435  last_data_time: 0.0415   lr: 7.9613e-06  max_mem: 49046M
[03/05 15:25:09 d2.utils.events]:  eta: 1 day, 11:38:12  iter: 22399  total_loss: 10.05  loss_ce0: 0.7027  loss_ce1: 1.187  loss_ce2: 1.393  loss_ce3: 0.8635  loss_ce4: 0.9895  loss_ce5: 2.437  loss_ce6: 2.408    time: 1.6784  last_time: 1.6545  data_time: 0.0466  last_data_time: 0.0369   lr: 7.9594e-06  max_mem: 49046M
[03/05 15:25:42 d2.utils.events]:  eta: 1 day, 11:37:39  iter: 22419  total_loss: 10.16  loss_ce0: 0.7079  loss_ce1: 1.228  loss_ce2: 1.152  loss_ce3: 0.8498  loss_ce4: 1.012  loss_ce5: 2.574  loss_ce6: 2.615    time: 1.6782  last_time: 1.6930  data_time: 0.0441  last_data_time: 0.0478   lr: 7.9576e-06  max_mem: 49046M
[03/05 15:26:15 d2.utils.events]:  eta: 1 day, 11:37:54  iter: 22439  total_loss: 10.03  loss_ce0: 0.713  loss_ce1: 1.109  loss_ce2: 1.182  loss_ce3: 0.8043  loss_ce4: 1.001  loss_ce5: 2.36  loss_ce6: 2.452    time: 1.6781  last_time: 1.6042  data_time: 0.0480  last_data_time: 0.0474   lr: 7.9557e-06  max_mem: 49046M
[03/05 15:26:48 d2.utils.events]:  eta: 1 day, 11:37:21  iter: 22459  total_loss: 10.28  loss_ce0: 0.7257  loss_ce1: 1.259  loss_ce2: 1.18  loss_ce3: 0.8178  loss_ce4: 1.004  loss_ce5: 2.356  loss_ce6: 2.573    time: 1.6778  last_time: 1.7087  data_time: 0.0438  last_data_time: 0.0463   lr: 7.9539e-06  max_mem: 49046M
[03/05 15:27:21 d2.utils.events]:  eta: 1 day, 11:35:26  iter: 22479  total_loss: 10.1  loss_ce0: 0.6936  loss_ce1: 1.186  loss_ce2: 1.15  loss_ce3: 0.7761  loss_ce4: 0.9388  loss_ce5: 2.503  loss_ce6: 2.678    time: 1.6775  last_time: 1.7062  data_time: 0.0454  last_data_time: 0.0551   lr: 7.952e-06  max_mem: 49046M
[03/05 15:27:54 d2.utils.events]:  eta: 1 day, 11:35:48  iter: 22499  total_loss: 9.962  loss_ce0: 0.7191  loss_ce1: 1.207  loss_ce2: 1.187  loss_ce3: 0.8487  loss_ce4: 1.034  loss_ce5: 2.296  loss_ce6: 2.42    time: 1.6773  last_time: 1.7982  data_time: 0.0447  last_data_time: 0.0669   lr: 7.9502e-06  max_mem: 49046M
[03/05 15:28:27 d2.utils.events]:  eta: 1 day, 11:35:57  iter: 22519  total_loss: 9.872  loss_ce0: 0.717  loss_ce1: 1.156  loss_ce2: 1.13  loss_ce3: 0.8022  loss_ce4: 1.034  loss_ce5: 2.314  loss_ce6: 2.396    time: 1.6771  last_time: 1.6187  data_time: 0.0448  last_data_time: 0.0431   lr: 7.9483e-06  max_mem: 49046M
[03/05 15:29:00 d2.utils.events]:  eta: 1 day, 11:34:20  iter: 22539  total_loss: 9.923  loss_ce0: 0.7258  loss_ce1: 1.181  loss_ce2: 1.186  loss_ce3: 0.8628  loss_ce4: 1.033  loss_ce5: 2.597  loss_ce6: 2.411    time: 1.6768  last_time: 1.6570  data_time: 0.0440  last_data_time: 0.0465   lr: 7.9465e-06  max_mem: 49046M
[03/05 15:29:33 d2.utils.events]:  eta: 1 day, 11:34:20  iter: 22559  total_loss: 10.07  loss_ce0: 0.7246  loss_ce1: 1.186  loss_ce2: 1.357  loss_ce3: 0.7716  loss_ce4: 1.019  loss_ce5: 2.407  loss_ce6: 2.508    time: 1.6767  last_time: 1.6163  data_time: 0.0474  last_data_time: 0.0435   lr: 7.9446e-06  max_mem: 49046M
[03/05 15:30:07 d2.utils.events]:  eta: 1 day, 11:33:11  iter: 22579  total_loss: 9.992  loss_ce0: 0.7546  loss_ce1: 1.208  loss_ce2: 1.283  loss_ce3: 0.8123  loss_ce4: 0.9889  loss_ce5: 2.227  loss_ce6: 2.675    time: 1.6766  last_time: 1.6034  data_time: 0.0486  last_data_time: 0.0443   lr: 7.9428e-06  max_mem: 49046M
[03/05 15:30:40 d2.utils.events]:  eta: 1 day, 11:33:29  iter: 22599  total_loss: 9.83  loss_ce0: 0.7085  loss_ce1: 1.142  loss_ce2: 1.186  loss_ce3: 0.8634  loss_ce4: 1.038  loss_ce5: 2.276  loss_ce6: 2.444    time: 1.6766  last_time: 1.6160  data_time: 0.0454  last_data_time: 0.0384   lr: 7.9409e-06  max_mem: 49046M
[03/05 15:31:14 d2.utils.events]:  eta: 1 day, 11:32:56  iter: 22619  total_loss: 9.792  loss_ce0: 0.6828  loss_ce1: 1.27  loss_ce2: 1.048  loss_ce3: 0.8712  loss_ce4: 0.9741  loss_ce5: 2.082  loss_ce6: 2.466    time: 1.6767  last_time: 1.6290  data_time: 0.0494  last_data_time: 0.0476   lr: 7.9391e-06  max_mem: 49046M
[03/05 15:31:47 d2.utils.events]:  eta: 1 day, 11:32:23  iter: 22639  total_loss: 10.06  loss_ce0: 0.7072  loss_ce1: 1.223  loss_ce2: 1.25  loss_ce3: 0.7807  loss_ce4: 1.05  loss_ce5: 2.393  loss_ce6: 2.683    time: 1.6766  last_time: 1.6980  data_time: 0.0445  last_data_time: 0.0451   lr: 7.9372e-06  max_mem: 49046M
[03/05 15:32:21 d2.utils.events]:  eta: 1 day, 11:32:23  iter: 22659  total_loss: 9.822  loss_ce0: 0.6928  loss_ce1: 1.182  loss_ce2: 1.08  loss_ce3: 0.8537  loss_ce4: 0.9905  loss_ce5: 2.147  loss_ce6: 2.523    time: 1.6766  last_time: 1.6178  data_time: 0.0451  last_data_time: 0.0462   lr: 7.9354e-06  max_mem: 49046M
[03/05 15:32:54 d2.utils.events]:  eta: 1 day, 11:32:27  iter: 22679  total_loss: 9.917  loss_ce0: 0.7093  loss_ce1: 1.162  loss_ce2: 1.2  loss_ce3: 0.7639  loss_ce4: 0.9922  loss_ce5: 2.197  loss_ce6: 2.388    time: 1.6765  last_time: 1.6420  data_time: 0.0470  last_data_time: 0.0474   lr: 7.9336e-06  max_mem: 49046M
[03/05 15:33:28 d2.utils.events]:  eta: 1 day, 11:31:59  iter: 22699  total_loss: 10.32  loss_ce0: 0.6896  loss_ce1: 1.129  loss_ce2: 1.187  loss_ce3: 0.7524  loss_ce4: 1.015  loss_ce5: 2.519  loss_ce6: 2.852    time: 1.6765  last_time: 1.6459  data_time: 0.0495  last_data_time: 0.0386   lr: 7.9317e-06  max_mem: 49046M
[03/05 15:34:01 d2.utils.events]:  eta: 1 day, 11:31:33  iter: 22719  total_loss: 9.746  loss_ce0: 0.7072  loss_ce1: 1.197  loss_ce2: 1.223  loss_ce3: 0.8555  loss_ce4: 0.9586  loss_ce5: 2.384  loss_ce6: 2.454    time: 1.6765  last_time: 1.6106  data_time: 0.0471  last_data_time: 0.0465   lr: 7.9299e-06  max_mem: 49046M
[03/05 15:34:35 d2.utils.events]:  eta: 1 day, 11:32:20  iter: 22739  total_loss: 9.544  loss_ce0: 0.7258  loss_ce1: 1.199  loss_ce2: 1.152  loss_ce3: 0.793  loss_ce4: 0.9568  loss_ce5: 2.255  loss_ce6: 2.452    time: 1.6765  last_time: 1.6014  data_time: 0.0495  last_data_time: 0.0454   lr: 7.928e-06  max_mem: 49046M
[03/05 15:35:08 d2.utils.events]:  eta: 1 day, 11:31:15  iter: 22759  total_loss: 9.701  loss_ce0: 0.7045  loss_ce1: 1.236  loss_ce2: 1.166  loss_ce3: 0.8261  loss_ce4: 0.9718  loss_ce5: 2.255  loss_ce6: 2.603    time: 1.6763  last_time: 1.6600  data_time: 0.0467  last_data_time: 0.0447   lr: 7.9262e-06  max_mem: 49046M
[03/05 15:35:41 d2.utils.events]:  eta: 1 day, 11:29:56  iter: 22779  total_loss: 9.809  loss_ce0: 0.7242  loss_ce1: 1.207  loss_ce2: 1.191  loss_ce3: 0.8628  loss_ce4: 1.019  loss_ce5: 2.125  loss_ce6: 2.292    time: 1.6762  last_time: 1.6429  data_time: 0.0471  last_data_time: 0.0474   lr: 7.9243e-06  max_mem: 49046M
[03/05 15:36:14 d2.utils.events]:  eta: 1 day, 11:29:16  iter: 22799  total_loss: 10.06  loss_ce0: 0.707  loss_ce1: 1.226  loss_ce2: 1.189  loss_ce3: 0.8339  loss_ce4: 1.012  loss_ce5: 2.153  loss_ce6: 2.522    time: 1.6760  last_time: 1.6802  data_time: 0.0445  last_data_time: 0.0466   lr: 7.9225e-06  max_mem: 49046M
[03/05 15:36:47 d2.utils.events]:  eta: 1 day, 11:28:36  iter: 22819  total_loss: 10.33  loss_ce0: 0.7133  loss_ce1: 1.201  loss_ce2: 1.291  loss_ce3: 0.7871  loss_ce4: 1.084  loss_ce5: 2.362  loss_ce6: 2.553    time: 1.6758  last_time: 1.6083  data_time: 0.0451  last_data_time: 0.0435   lr: 7.9206e-06  max_mem: 49046M
[03/05 15:37:20 d2.utils.events]:  eta: 1 day, 11:27:13  iter: 22839  total_loss: 10.32  loss_ce0: 0.7343  loss_ce1: 1.144  loss_ce2: 1.166  loss_ce3: 0.8238  loss_ce4: 1.011  loss_ce5: 2.15  loss_ce6: 2.711    time: 1.6757  last_time: 1.6646  data_time: 0.0474  last_data_time: 0.0448   lr: 7.9188e-06  max_mem: 49046M
[03/05 15:37:53 d2.utils.events]:  eta: 1 day, 11:26:21  iter: 22859  total_loss: 10.2  loss_ce0: 0.6943  loss_ce1: 1.148  loss_ce2: 1.269  loss_ce3: 0.9061  loss_ce4: 1.014  loss_ce5: 2.36  loss_ce6: 2.495    time: 1.6755  last_time: 1.6590  data_time: 0.0478  last_data_time: 0.0496   lr: 7.9169e-06  max_mem: 49046M
[03/05 15:38:26 d2.utils.events]:  eta: 1 day, 11:25:09  iter: 22879  total_loss: 9.629  loss_ce0: 0.7084  loss_ce1: 1.181  loss_ce2: 1.32  loss_ce3: 0.7896  loss_ce4: 0.9962  loss_ce5: 2.157  loss_ce6: 2.183    time: 1.6754  last_time: 1.6107  data_time: 0.0453  last_data_time: 0.0489   lr: 7.9151e-06  max_mem: 49046M
[03/05 15:39:00 d2.utils.events]:  eta: 1 day, 11:25:15  iter: 22899  total_loss: 9.733  loss_ce0: 0.7124  loss_ce1: 1.129  loss_ce2: 1.095  loss_ce3: 0.7722  loss_ce4: 1.042  loss_ce5: 2.127  loss_ce6: 2.746    time: 1.6754  last_time: 1.7090  data_time: 0.0477  last_data_time: 0.0426   lr: 7.9132e-06  max_mem: 49046M
[03/05 15:39:33 d2.utils.events]:  eta: 1 day, 11:24:56  iter: 22919  total_loss: 9.758  loss_ce0: 0.7447  loss_ce1: 1.135  loss_ce2: 1.169  loss_ce3: 0.8932  loss_ce4: 0.996  loss_ce5: 2.202  loss_ce6: 2.561    time: 1.6753  last_time: 1.6785  data_time: 0.0465  last_data_time: 0.0439   lr: 7.9114e-06  max_mem: 49046M
[03/05 15:40:07 d2.utils.events]:  eta: 1 day, 11:24:45  iter: 22939  total_loss: 9.918  loss_ce0: 0.7154  loss_ce1: 1.236  loss_ce2: 1.204  loss_ce3: 0.8501  loss_ce4: 0.9799  loss_ce5: 2.136  loss_ce6: 2.751    time: 1.6752  last_time: 1.6467  data_time: 0.0469  last_data_time: 0.0473   lr: 7.9095e-06  max_mem: 49046M
[03/05 15:40:39 d2.utils.events]:  eta: 1 day, 11:23:36  iter: 22959  total_loss: 9.976  loss_ce0: 0.6973  loss_ce1: 1.205  loss_ce2: 1.154  loss_ce3: 0.7799  loss_ce4: 1.015  loss_ce5: 2.283  loss_ce6: 2.268    time: 1.6750  last_time: 1.5906  data_time: 0.0453  last_data_time: 0.0430   lr: 7.9077e-06  max_mem: 49046M
[03/05 15:41:12 d2.utils.events]:  eta: 1 day, 11:23:03  iter: 22979  total_loss: 9.639  loss_ce0: 0.7197  loss_ce1: 1.193  loss_ce2: 1.05  loss_ce3: 0.8487  loss_ce4: 0.9869  loss_ce5: 2.146  loss_ce6: 2.296    time: 1.6748  last_time: 1.6991  data_time: 0.0460  last_data_time: 0.0529   lr: 7.9058e-06  max_mem: 49046M
[03/05 15:41:46 d2.utils.events]:  eta: 1 day, 11:22:44  iter: 22999  total_loss: 9.85  loss_ce0: 0.6997  loss_ce1: 1.283  loss_ce2: 1.168  loss_ce3: 0.8127  loss_ce4: 1.009  loss_ce5: 2.198  loss_ce6: 2.521    time: 1.6748  last_time: 1.6234  data_time: 0.0461  last_data_time: 0.0404   lr: 7.904e-06  max_mem: 49046M
[03/05 15:42:19 d2.utils.events]:  eta: 1 day, 11:23:12  iter: 23019  total_loss: 10.01  loss_ce0: 0.7246  loss_ce1: 1.16  loss_ce2: 1.268  loss_ce3: 0.8535  loss_ce4: 0.992  loss_ce5: 2.235  loss_ce6: 2.463    time: 1.6748  last_time: 1.7000  data_time: 0.0449  last_data_time: 0.0454   lr: 7.9021e-06  max_mem: 49046M
[03/05 15:42:53 d2.utils.events]:  eta: 1 day, 11:22:41  iter: 23039  total_loss: 9.899  loss_ce0: 0.7185  loss_ce1: 1.193  loss_ce2: 1.317  loss_ce3: 0.7939  loss_ce4: 1.015  loss_ce5: 2.3  loss_ce6: 2.607    time: 1.6747  last_time: 1.7694  data_time: 0.0466  last_data_time: 0.0463   lr: 7.9003e-06  max_mem: 49046M
[03/05 15:43:26 d2.utils.events]:  eta: 1 day, 11:22:11  iter: 23059  total_loss: 10.28  loss_ce0: 0.7339  loss_ce1: 1.205  loss_ce2: 1.147  loss_ce3: 0.7836  loss_ce4: 1.043  loss_ce5: 2.208  loss_ce6: 2.75    time: 1.6746  last_time: 1.6947  data_time: 0.0450  last_data_time: 0.0527   lr: 7.8985e-06  max_mem: 49046M
[03/05 15:43:59 d2.utils.events]:  eta: 1 day, 11:21:32  iter: 23079  total_loss: 10.1  loss_ce0: 0.6911  loss_ce1: 1.117  loss_ce2: 1.244  loss_ce3: 0.8337  loss_ce4: 0.9589  loss_ce5: 2.356  loss_ce6: 2.664    time: 1.6745  last_time: 1.6267  data_time: 0.0442  last_data_time: 0.0476   lr: 7.8966e-06  max_mem: 49046M
[03/05 15:44:32 d2.utils.events]:  eta: 1 day, 11:20:20  iter: 23099  total_loss: 10.1  loss_ce0: 0.697  loss_ce1: 1.243  loss_ce2: 1.057  loss_ce3: 0.8131  loss_ce4: 1.041  loss_ce5: 2.542  loss_ce6: 2.333    time: 1.6742  last_time: 1.7006  data_time: 0.0442  last_data_time: 0.0435   lr: 7.8948e-06  max_mem: 49046M
[03/05 15:45:05 d2.utils.events]:  eta: 1 day, 11:19:47  iter: 23119  total_loss: 9.773  loss_ce0: 0.6801  loss_ce1: 1.169  loss_ce2: 1.381  loss_ce3: 0.7947  loss_ce4: 1.045  loss_ce5: 2.204  loss_ce6: 2.386    time: 1.6741  last_time: 1.6628  data_time: 0.0439  last_data_time: 0.0448   lr: 7.8929e-06  max_mem: 49046M
[03/05 15:45:38 d2.utils.events]:  eta: 1 day, 11:19:01  iter: 23139  total_loss: 9.992  loss_ce0: 0.7109  loss_ce1: 1.187  loss_ce2: 1.219  loss_ce3: 0.7742  loss_ce4: 1.009  loss_ce5: 2.429  loss_ce6: 2.341    time: 1.6739  last_time: 1.6701  data_time: 0.0433  last_data_time: 0.0443   lr: 7.8911e-06  max_mem: 49046M
[03/05 15:46:11 d2.utils.events]:  eta: 1 day, 11:18:28  iter: 23159  total_loss: 9.894  loss_ce0: 0.7212  loss_ce1: 1.156  loss_ce2: 1.135  loss_ce3: 0.7882  loss_ce4: 1.023  loss_ce5: 2.248  loss_ce6: 2.324    time: 1.6738  last_time: 1.6931  data_time: 0.0445  last_data_time: 0.0451   lr: 7.8892e-06  max_mem: 49046M
[03/05 15:46:44 d2.utils.events]:  eta: 1 day, 11:17:55  iter: 23179  total_loss: 10.42  loss_ce0: 0.7071  loss_ce1: 1.252  loss_ce2: 1.107  loss_ce3: 0.8038  loss_ce4: 0.9798  loss_ce5: 2.264  loss_ce6: 2.812    time: 1.6737  last_time: 1.8214  data_time: 0.0452  last_data_time: 0.0404   lr: 7.8874e-06  max_mem: 49046M
[03/05 15:47:17 d2.utils.events]:  eta: 1 day, 11:17:06  iter: 23199  total_loss: 9.96  loss_ce0: 0.7164  loss_ce1: 1.208  loss_ce2: 1.162  loss_ce3: 0.8103  loss_ce4: 0.9847  loss_ce5: 2.312  loss_ce6: 2.402    time: 1.6736  last_time: 1.6692  data_time: 0.0444  last_data_time: 0.0470   lr: 7.8855e-06  max_mem: 49046M
[03/05 15:47:51 d2.utils.events]:  eta: 1 day, 11:16:49  iter: 23219  total_loss: 10.17  loss_ce0: 0.6955  loss_ce1: 1.275  loss_ce2: 1.162  loss_ce3: 0.8175  loss_ce4: 0.9399  loss_ce5: 2.397  loss_ce6: 2.565    time: 1.6735  last_time: 1.6876  data_time: 0.0453  last_data_time: 0.0420   lr: 7.8837e-06  max_mem: 49046M
[03/05 15:48:24 d2.utils.events]:  eta: 1 day, 11:17:07  iter: 23239  total_loss: 10.09  loss_ce0: 0.7181  loss_ce1: 1.216  loss_ce2: 1.349  loss_ce3: 0.8216  loss_ce4: 1.024  loss_ce5: 2.4  loss_ce6: 2.362    time: 1.6735  last_time: 1.6312  data_time: 0.0477  last_data_time: 0.0474   lr: 7.8818e-06  max_mem: 49046M
[03/05 15:48:57 d2.utils.events]:  eta: 1 day, 11:15:55  iter: 23259  total_loss: 9.779  loss_ce0: 0.6946  loss_ce1: 1.172  loss_ce2: 1.229  loss_ce3: 0.8507  loss_ce4: 1.012  loss_ce5: 2.235  loss_ce6: 2.569    time: 1.6733  last_time: 1.6041  data_time: 0.0461  last_data_time: 0.0433   lr: 7.88e-06  max_mem: 49046M
[03/05 15:49:31 d2.utils.events]:  eta: 1 day, 11:15:22  iter: 23279  total_loss: 9.575  loss_ce0: 0.7236  loss_ce1: 1.26  loss_ce2: 1.126  loss_ce3: 0.8119  loss_ce4: 1.037  loss_ce5: 2.144  loss_ce6: 2.576    time: 1.6734  last_time: 1.6084  data_time: 0.0459  last_data_time: 0.0417   lr: 7.8781e-06  max_mem: 49046M
[03/05 15:50:04 d2.utils.events]:  eta: 1 day, 11:14:07  iter: 23299  total_loss: 10.05  loss_ce0: 0.7233  loss_ce1: 1.204  loss_ce2: 1.145  loss_ce3: 0.8671  loss_ce4: 0.982  loss_ce5: 2.316  loss_ce6: 2.649    time: 1.6732  last_time: 1.7684  data_time: 0.0451  last_data_time: 0.0478   lr: 7.8763e-06  max_mem: 49046M
[03/05 15:50:36 d2.utils.events]:  eta: 1 day, 11:11:33  iter: 23319  total_loss: 9.87  loss_ce0: 0.7143  loss_ce1: 1.14  loss_ce2: 1.235  loss_ce3: 0.8037  loss_ce4: 0.9792  loss_ce5: 2.423  loss_ce6: 2.419    time: 1.6729  last_time: 1.5993  data_time: 0.0436  last_data_time: 0.0438   lr: 7.8744e-06  max_mem: 49046M
[03/05 15:51:09 d2.utils.events]:  eta: 1 day, 11:09:31  iter: 23339  total_loss: 10.21  loss_ce0: 0.7265  loss_ce1: 1.222  loss_ce2: 1.248  loss_ce3: 0.8678  loss_ce4: 1.013  loss_ce5: 2.294  loss_ce6: 2.327    time: 1.6728  last_time: 1.6002  data_time: 0.0447  last_data_time: 0.0412   lr: 7.8726e-06  max_mem: 49046M
[03/05 15:51:42 d2.utils.events]:  eta: 1 day, 11:08:23  iter: 23359  total_loss: 10.36  loss_ce0: 0.7232  loss_ce1: 1.196  loss_ce2: 1.279  loss_ce3: 0.8332  loss_ce4: 1.009  loss_ce5: 2.458  loss_ce6: 2.507    time: 1.6726  last_time: 1.6569  data_time: 0.0439  last_data_time: 0.0407   lr: 7.8707e-06  max_mem: 49046M
[03/05 15:52:15 d2.utils.events]:  eta: 1 day, 11:07:28  iter: 23379  total_loss: 9.513  loss_ce0: 0.6959  loss_ce1: 1.141  loss_ce2: 1.314  loss_ce3: 0.8469  loss_ce4: 1.013  loss_ce5: 2.111  loss_ce6: 2.329    time: 1.6724  last_time: 1.5972  data_time: 0.0443  last_data_time: 0.0408   lr: 7.8689e-06  max_mem: 49046M
[03/05 15:52:48 d2.utils.events]:  eta: 1 day, 11:06:14  iter: 23399  total_loss: 9.895  loss_ce0: 0.6984  loss_ce1: 1.17  loss_ce2: 1.217  loss_ce3: 0.7311  loss_ce4: 1.027  loss_ce5: 2.113  loss_ce6: 2.619    time: 1.6723  last_time: 1.6408  data_time: 0.0445  last_data_time: 0.0439   lr: 7.867e-06  max_mem: 49046M
[03/05 15:53:21 d2.utils.events]:  eta: 1 day, 11:05:41  iter: 23419  total_loss: 9.389  loss_ce0: 0.7135  loss_ce1: 1.125  loss_ce2: 1.031  loss_ce3: 0.7949  loss_ce4: 0.9345  loss_ce5: 2.372  loss_ce6: 2.432    time: 1.6722  last_time: 1.6373  data_time: 0.0461  last_data_time: 0.0437   lr: 7.8652e-06  max_mem: 49046M
[03/05 15:53:54 d2.utils.events]:  eta: 1 day, 11:04:14  iter: 23439  total_loss: 9.707  loss_ce0: 0.7306  loss_ce1: 1.212  loss_ce2: 1.163  loss_ce3: 0.7825  loss_ce4: 0.9691  loss_ce5: 2.34  loss_ce6: 2.17    time: 1.6720  last_time: 1.6705  data_time: 0.0458  last_data_time: 0.0505   lr: 7.8633e-06  max_mem: 49046M
[03/05 15:54:27 d2.utils.events]:  eta: 1 day, 11:04:27  iter: 23459  total_loss: 9.989  loss_ce0: 0.6939  loss_ce1: 1.16  loss_ce2: 1.151  loss_ce3: 0.7874  loss_ce4: 0.99  loss_ce5: 2.072  loss_ce6: 2.732    time: 1.6720  last_time: 1.7881  data_time: 0.0476  last_data_time: 0.0518   lr: 7.8615e-06  max_mem: 49046M
[03/05 15:55:01 d2.utils.events]:  eta: 1 day, 11:04:34  iter: 23479  total_loss: 10.18  loss_ce0: 0.7105  loss_ce1: 1.169  loss_ce2: 1.335  loss_ce3: 0.8242  loss_ce4: 0.9481  loss_ce5: 2.337  loss_ce6: 2.711    time: 1.6720  last_time: 1.7363  data_time: 0.0459  last_data_time: 0.0497   lr: 7.8596e-06  max_mem: 49046M
[03/05 15:55:34 d2.utils.events]:  eta: 1 day, 11:03:29  iter: 23499  total_loss: 9.528  loss_ce0: 0.7109  loss_ce1: 1.151  loss_ce2: 1.307  loss_ce3: 0.7817  loss_ce4: 1.029  loss_ce5: 2.437  loss_ce6: 2.607    time: 1.6718  last_time: 1.6571  data_time: 0.0457  last_data_time: 0.0433   lr: 7.8578e-06  max_mem: 49046M
[03/05 15:56:06 d2.utils.events]:  eta: 1 day, 11:02:02  iter: 23519  total_loss: 9.984  loss_ce0: 0.728  loss_ce1: 1.209  loss_ce2: 1.17  loss_ce3: 0.8528  loss_ce4: 0.9869  loss_ce5: 2.314  loss_ce6: 2.297    time: 1.6716  last_time: 1.6547  data_time: 0.0438  last_data_time: 0.0490   lr: 7.8559e-06  max_mem: 49046M
[03/05 15:56:39 d2.utils.events]:  eta: 1 day, 11:02:08  iter: 23539  total_loss: 9.627  loss_ce0: 0.7179  loss_ce1: 1.162  loss_ce2: 1.221  loss_ce3: 0.7868  loss_ce4: 0.9541  loss_ce5: 2.331  loss_ce6: 2.247    time: 1.6715  last_time: 1.6265  data_time: 0.0456  last_data_time: 0.0446   lr: 7.8541e-06  max_mem: 49046M
[03/05 15:57:13 d2.utils.events]:  eta: 1 day, 11:01:50  iter: 23559  total_loss: 9.907  loss_ce0: 0.679  loss_ce1: 1.15  loss_ce2: 1.221  loss_ce3: 0.8695  loss_ce4: 1.027  loss_ce5: 2.144  loss_ce6: 2.616    time: 1.6715  last_time: 1.6599  data_time: 0.0469  last_data_time: 0.0444   lr: 7.8522e-06  max_mem: 49046M
[03/05 15:57:46 d2.utils.events]:  eta: 1 day, 11:01:58  iter: 23579  total_loss: 9.872  loss_ce0: 0.7274  loss_ce1: 1.216  loss_ce2: 1.257  loss_ce3: 0.8451  loss_ce4: 0.9639  loss_ce5: 2.448  loss_ce6: 2.664    time: 1.6715  last_time: 1.6985  data_time: 0.0515  last_data_time: 0.0500   lr: 7.8504e-06  max_mem: 49046M
[03/05 15:58:19 d2.utils.events]:  eta: 1 day, 11:00:29  iter: 23599  total_loss: 9.856  loss_ce0: 0.7042  loss_ce1: 1.168  loss_ce2: 1.167  loss_ce3: 0.808  loss_ce4: 0.9869  loss_ce5: 2.409  loss_ce6: 2.353    time: 1.6714  last_time: 1.6549  data_time: 0.0461  last_data_time: 0.0480   lr: 7.8485e-06  max_mem: 49046M
[03/05 15:58:53 d2.utils.events]:  eta: 1 day, 11:00:11  iter: 23619  total_loss: 10.02  loss_ce0: 0.7353  loss_ce1: 1.192  loss_ce2: 1.048  loss_ce3: 0.7894  loss_ce4: 1.012  loss_ce5: 2.375  loss_ce6: 2.69    time: 1.6714  last_time: 1.6013  data_time: 0.0449  last_data_time: 0.0432   lr: 7.8467e-06  max_mem: 49046M
[03/05 15:59:25 d2.utils.events]:  eta: 1 day, 10:58:38  iter: 23639  total_loss: 9.727  loss_ce0: 0.7302  loss_ce1: 1.166  loss_ce2: 1.218  loss_ce3: 0.8719  loss_ce4: 0.9848  loss_ce5: 2.23  loss_ce6: 2.253    time: 1.6712  last_time: 1.6008  data_time: 0.0481  last_data_time: 0.0455   lr: 7.8448e-06  max_mem: 49046M
[03/05 15:59:59 d2.utils.events]:  eta: 1 day, 10:56:05  iter: 23659  total_loss: 10.25  loss_ce0: 0.727  loss_ce1: 1.218  loss_ce2: 1.414  loss_ce3: 0.7758  loss_ce4: 1.024  loss_ce5: 2.362  loss_ce6: 2.789    time: 1.6711  last_time: 1.6116  data_time: 0.0452  last_data_time: 0.0466   lr: 7.843e-06  max_mem: 49046M
[03/05 16:00:31 d2.utils.events]:  eta: 1 day, 10:54:31  iter: 23679  total_loss: 9.597  loss_ce0: 0.6979  loss_ce1: 1.141  loss_ce2: 1.252  loss_ce3: 0.8082  loss_ce4: 1.029  loss_ce5: 2.184  loss_ce6: 2.253    time: 1.6709  last_time: 1.6342  data_time: 0.0451  last_data_time: 0.0410   lr: 7.8411e-06  max_mem: 49046M
[03/05 16:01:05 d2.utils.events]:  eta: 1 day, 10:53:58  iter: 23699  total_loss: 9.944  loss_ce0: 0.7339  loss_ce1: 1.241  loss_ce2: 1.123  loss_ce3: 0.7143  loss_ce4: 0.9959  loss_ce5: 2.118  loss_ce6: 2.593    time: 1.6709  last_time: 1.7054  data_time: 0.0453  last_data_time: 0.0465   lr: 7.8393e-06  max_mem: 49046M
[03/05 16:01:38 d2.utils.events]:  eta: 1 day, 10:53:53  iter: 23719  total_loss: 9.884  loss_ce0: 0.7223  loss_ce1: 1.18  loss_ce2: 1.329  loss_ce3: 0.7621  loss_ce4: 0.9979  loss_ce5: 2.471  loss_ce6: 2.345    time: 1.6709  last_time: 1.7519  data_time: 0.0487  last_data_time: 0.0465   lr: 7.8374e-06  max_mem: 49046M
[03/05 16:02:11 d2.utils.events]:  eta: 1 day, 10:51:37  iter: 23739  total_loss: 10.06  loss_ce0: 0.7016  loss_ce1: 1.128  loss_ce2: 1.143  loss_ce3: 0.7834  loss_ce4: 0.9906  loss_ce5: 2.619  loss_ce6: 2.382    time: 1.6708  last_time: 1.7905  data_time: 0.0450  last_data_time: 0.0430   lr: 7.8356e-06  max_mem: 49046M
[03/05 16:02:44 d2.utils.events]:  eta: 1 day, 10:51:04  iter: 23759  total_loss: 10.06  loss_ce0: 0.7278  loss_ce1: 1.237  loss_ce2: 1.11  loss_ce3: 0.7581  loss_ce4: 1.046  loss_ce5: 2.545  loss_ce6: 2.711    time: 1.6707  last_time: 1.5995  data_time: 0.0447  last_data_time: 0.0418   lr: 7.8338e-06  max_mem: 49046M
[03/05 16:03:18 d2.utils.events]:  eta: 1 day, 10:51:38  iter: 23779  total_loss: 10.28  loss_ce0: 0.7059  loss_ce1: 1.21  loss_ce2: 1.274  loss_ce3: 0.9387  loss_ce4: 0.9351  loss_ce5: 2.296  loss_ce6: 2.632    time: 1.6707  last_time: 1.7702  data_time: 0.0477  last_data_time: 0.0438   lr: 7.8319e-06  max_mem: 49046M
[03/05 16:03:51 d2.utils.events]:  eta: 1 day, 10:52:43  iter: 23799  total_loss: 10.15  loss_ce0: 0.7287  loss_ce1: 1.172  loss_ce2: 1.182  loss_ce3: 0.8543  loss_ce4: 1.032  loss_ce5: 2.359  loss_ce6: 2.533    time: 1.6707  last_time: 1.6519  data_time: 0.0480  last_data_time: 0.0455   lr: 7.8301e-06  max_mem: 49046M
[03/05 16:04:24 d2.utils.events]:  eta: 1 day, 10:51:55  iter: 23819  total_loss: 10.01  loss_ce0: 0.7072  loss_ce1: 1.25  loss_ce2: 1.048  loss_ce3: 0.806  loss_ce4: 0.9958  loss_ce5: 2.696  loss_ce6: 2.475    time: 1.6706  last_time: 1.6302  data_time: 0.0452  last_data_time: 0.0426   lr: 7.8282e-06  max_mem: 49046M
[03/05 16:04:58 d2.utils.events]:  eta: 1 day, 10:53:08  iter: 23839  total_loss: 10.24  loss_ce0: 0.7187  loss_ce1: 1.221  loss_ce2: 1.202  loss_ce3: 0.8632  loss_ce4: 0.9445  loss_ce5: 2.428  loss_ce6: 2.543    time: 1.6706  last_time: 1.6697  data_time: 0.0470  last_data_time: 0.0481   lr: 7.8264e-06  max_mem: 49046M
[03/05 16:05:31 d2.utils.events]:  eta: 1 day, 10:53:35  iter: 23859  total_loss: 9.742  loss_ce0: 0.6954  loss_ce1: 1.179  loss_ce2: 1.153  loss_ce3: 0.7892  loss_ce4: 0.9707  loss_ce5: 2.196  loss_ce6: 2.189    time: 1.6706  last_time: 1.6283  data_time: 0.0461  last_data_time: 0.0411   lr: 7.8245e-06  max_mem: 49046M
[03/05 16:06:04 d2.utils.events]:  eta: 1 day, 10:53:02  iter: 23879  total_loss: 9.924  loss_ce0: 0.7051  loss_ce1: 1.183  loss_ce2: 1.106  loss_ce3: 0.8869  loss_ce4: 1.013  loss_ce5: 2.275  loss_ce6: 2.252    time: 1.6704  last_time: 1.6045  data_time: 0.0451  last_data_time: 0.0407   lr: 7.8227e-06  max_mem: 49046M
[03/05 16:06:37 d2.utils.events]:  eta: 1 day, 10:52:06  iter: 23899  total_loss: 9.824  loss_ce0: 0.713  loss_ce1: 1.15  loss_ce2: 1.396  loss_ce3: 0.8716  loss_ce4: 1.001  loss_ce5: 2.078  loss_ce6: 2.335    time: 1.6703  last_time: 1.6145  data_time: 0.0444  last_data_time: 0.0426   lr: 7.8208e-06  max_mem: 49046M
[03/05 16:07:10 d2.utils.events]:  eta: 1 day, 10:50:00  iter: 23919  total_loss: 10.02  loss_ce0: 0.7338  loss_ce1: 1.121  loss_ce2: 1.121  loss_ce3: 0.7781  loss_ce4: 0.9925  loss_ce5: 2.435  loss_ce6: 2.599    time: 1.6702  last_time: 1.7185  data_time: 0.0453  last_data_time: 0.0508   lr: 7.819e-06  max_mem: 49046M
[03/05 16:07:43 d2.utils.events]:  eta: 1 day, 10:48:52  iter: 23939  total_loss: 10.22  loss_ce0: 0.6904  loss_ce1: 1.179  loss_ce2: 1.495  loss_ce3: 0.8251  loss_ce4: 0.9742  loss_ce5: 2.275  loss_ce6: 2.302    time: 1.6701  last_time: 1.6346  data_time: 0.0441  last_data_time: 0.0401   lr: 7.8171e-06  max_mem: 49046M
[03/05 16:08:16 d2.utils.events]:  eta: 1 day, 10:50:09  iter: 23959  total_loss: 10.04  loss_ce0: 0.7039  loss_ce1: 1.214  loss_ce2: 1.117  loss_ce3: 0.8259  loss_ce4: 0.9847  loss_ce5: 2.294  loss_ce6: 2.572    time: 1.6701  last_time: 1.6935  data_time: 0.0451  last_data_time: 0.0479   lr: 7.8153e-06  max_mem: 49046M
[03/05 16:08:50 d2.utils.events]:  eta: 1 day, 10:50:02  iter: 23979  total_loss: 10.09  loss_ce0: 0.7039  loss_ce1: 1.192  loss_ce2: 1.28  loss_ce3: 0.8626  loss_ce4: 0.983  loss_ce5: 2.379  loss_ce6: 2.587    time: 1.6701  last_time: 1.6260  data_time: 0.0458  last_data_time: 0.0446   lr: 7.8134e-06  max_mem: 49046M
[03/05 16:09:23 d2.utils.events]:  eta: 1 day, 10:48:44  iter: 23999  total_loss: 10.05  loss_ce0: 0.7054  loss_ce1: 1.101  loss_ce2: 1.303  loss_ce3: 0.7761  loss_ce4: 1.011  loss_ce5: 2.29  loss_ce6: 2.408    time: 1.6700  last_time: 1.6662  data_time: 0.0476  last_data_time: 0.0476   lr: 7.8116e-06  max_mem: 49046M
[03/05 16:09:56 d2.utils.events]:  eta: 1 day, 10:46:44  iter: 24019  total_loss: 9.748  loss_ce0: 0.6728  loss_ce1: 1.233  loss_ce2: 1.35  loss_ce3: 0.8878  loss_ce4: 0.9538  loss_ce5: 2.248  loss_ce6: 2.461    time: 1.6700  last_time: 1.6141  data_time: 0.0453  last_data_time: 0.0394   lr: 7.8097e-06  max_mem: 49046M
[03/05 16:10:29 d2.utils.events]:  eta: 1 day, 10:45:52  iter: 24039  total_loss: 10.07  loss_ce0: 0.7032  loss_ce1: 1.188  loss_ce2: 1.118  loss_ce3: 0.7901  loss_ce4: 1.054  loss_ce5: 2.368  loss_ce6: 2.602    time: 1.6699  last_time: 1.6684  data_time: 0.0456  last_data_time: 0.0537   lr: 7.8079e-06  max_mem: 49046M
[03/05 16:11:03 d2.utils.events]:  eta: 1 day, 10:45:05  iter: 24059  total_loss: 10.1  loss_ce0: 0.7566  loss_ce1: 1.176  loss_ce2: 1.221  loss_ce3: 0.7672  loss_ce4: 1.016  loss_ce5: 2.554  loss_ce6: 2.526    time: 1.6698  last_time: 1.6054  data_time: 0.0451  last_data_time: 0.0428   lr: 7.806e-06  max_mem: 49046M
[03/05 16:11:36 d2.utils.events]:  eta: 1 day, 10:45:37  iter: 24079  total_loss: 9.99  loss_ce0: 0.7102  loss_ce1: 1.187  loss_ce2: 1.152  loss_ce3: 0.8021  loss_ce4: 1.059  loss_ce5: 2.257  loss_ce6: 2.609    time: 1.6698  last_time: 1.6530  data_time: 0.0478  last_data_time: 0.0427   lr: 7.8042e-06  max_mem: 49046M
[03/05 16:12:09 d2.utils.events]:  eta: 1 day, 10:46:44  iter: 24099  total_loss: 10.34  loss_ce0: 0.7139  loss_ce1: 1.25  loss_ce2: 1.291  loss_ce3: 0.8187  loss_ce4: 0.9944  loss_ce5: 2.467  loss_ce6: 2.312    time: 1.6698  last_time: 1.6401  data_time: 0.0468  last_data_time: 0.0418   lr: 7.8023e-06  max_mem: 49046M
[03/05 16:12:43 d2.utils.events]:  eta: 1 day, 10:46:11  iter: 24119  total_loss: 10.01  loss_ce0: 0.7134  loss_ce1: 1.196  loss_ce2: 1.227  loss_ce3: 0.8615  loss_ce4: 1.04  loss_ce5: 2.218  loss_ce6: 2.399    time: 1.6698  last_time: 1.6093  data_time: 0.0472  last_data_time: 0.0452   lr: 7.8005e-06  max_mem: 49046M
[03/05 16:13:16 d2.utils.events]:  eta: 1 day, 10:46:39  iter: 24139  total_loss: 9.727  loss_ce0: 0.7197  loss_ce1: 1.212  loss_ce2: 1.306  loss_ce3: 0.7986  loss_ce4: 1.057  loss_ce5: 2.307  loss_ce6: 2.348    time: 1.6698  last_time: 1.6210  data_time: 0.0464  last_data_time: 0.0421   lr: 7.7986e-06  max_mem: 49046M
[03/05 16:13:49 d2.utils.events]:  eta: 1 day, 10:46:25  iter: 24159  total_loss: 9.511  loss_ce0: 0.7208  loss_ce1: 1.181  loss_ce2: 1.13  loss_ce3: 0.7938  loss_ce4: 0.9786  loss_ce5: 2.116  loss_ce6: 2.281    time: 1.6697  last_time: 1.6043  data_time: 0.0449  last_data_time: 0.0460   lr: 7.7968e-06  max_mem: 49046M
[03/05 16:14:22 d2.utils.events]:  eta: 1 day, 10:46:44  iter: 24179  total_loss: 9.712  loss_ce0: 0.7124  loss_ce1: 1.167  loss_ce2: 1.198  loss_ce3: 0.8143  loss_ce4: 0.9851  loss_ce5: 2.216  loss_ce6: 2.538    time: 1.6697  last_time: 1.6152  data_time: 0.0454  last_data_time: 0.0565   lr: 7.7949e-06  max_mem: 49046M
[03/05 16:14:56 d2.utils.events]:  eta: 1 day, 10:46:19  iter: 24199  total_loss: 9.75  loss_ce0: 0.6766  loss_ce1: 1.18  loss_ce2: 1.36  loss_ce3: 0.7733  loss_ce4: 0.9978  loss_ce5: 2.33  loss_ce6: 2.317    time: 1.6696  last_time: 1.6777  data_time: 0.0452  last_data_time: 0.0453   lr: 7.793e-06  max_mem: 49046M
[03/05 16:15:30 d2.utils.events]:  eta: 1 day, 10:47:10  iter: 24219  total_loss: 9.641  loss_ce0: 0.7222  loss_ce1: 1.168  loss_ce2: 1.208  loss_ce3: 0.7929  loss_ce4: 0.9812  loss_ce5: 2.312  loss_ce6: 2.339    time: 1.6698  last_time: 1.6505  data_time: 0.0500  last_data_time: 0.0500   lr: 7.7912e-06  max_mem: 49046M
[03/05 16:16:03 d2.utils.events]:  eta: 1 day, 10:46:05  iter: 24239  total_loss: 9.94  loss_ce0: 0.7157  loss_ce1: 1.189  loss_ce2: 1.299  loss_ce3: 0.8033  loss_ce4: 1.019  loss_ce5: 2.321  loss_ce6: 2.641    time: 1.6698  last_time: 1.6117  data_time: 0.0475  last_data_time: 0.0490   lr: 7.7893e-06  max_mem: 49046M
[03/05 16:16:36 d2.utils.events]:  eta: 1 day, 10:46:41  iter: 24259  total_loss: 9.872  loss_ce0: 0.7119  loss_ce1: 1.16  loss_ce2: 1.108  loss_ce3: 0.7779  loss_ce4: 1.026  loss_ce5: 2.164  loss_ce6: 2.526    time: 1.6697  last_time: 1.7198  data_time: 0.0496  last_data_time: 0.0540   lr: 7.7875e-06  max_mem: 49046M
[03/05 16:17:09 d2.utils.events]:  eta: 1 day, 10:45:57  iter: 24279  total_loss: 9.57  loss_ce0: 0.694  loss_ce1: 1.211  loss_ce2: 1.123  loss_ce3: 0.8091  loss_ce4: 1.011  loss_ce5: 2.125  loss_ce6: 2.503    time: 1.6697  last_time: 1.6054  data_time: 0.0485  last_data_time: 0.0460   lr: 7.7856e-06  max_mem: 49046M
[03/05 16:17:43 d2.utils.events]:  eta: 1 day, 10:45:41  iter: 24299  total_loss: 9.774  loss_ce0: 0.7218  loss_ce1: 1.176  loss_ce2: 1.057  loss_ce3: 0.8525  loss_ce4: 1  loss_ce5: 2.262  loss_ce6: 2.627    time: 1.6697  last_time: 1.7026  data_time: 0.0453  last_data_time: 0.0444   lr: 7.7838e-06  max_mem: 49046M
[03/05 16:18:16 d2.utils.events]:  eta: 1 day, 10:46:07  iter: 24319  total_loss: 9.978  loss_ce0: 0.6848  loss_ce1: 1.138  loss_ce2: 1.211  loss_ce3: 0.8858  loss_ce4: 1.01  loss_ce5: 2.305  loss_ce6: 2.469    time: 1.6696  last_time: 1.6499  data_time: 0.0454  last_data_time: 0.0408   lr: 7.7819e-06  max_mem: 49046M
[03/05 16:18:49 d2.utils.events]:  eta: 1 day, 10:46:29  iter: 24339  total_loss: 10.08  loss_ce0: 0.6907  loss_ce1: 1.237  loss_ce2: 1.171  loss_ce3: 0.8476  loss_ce4: 0.9849  loss_ce5: 2.312  loss_ce6: 2.439    time: 1.6696  last_time: 1.6723  data_time: 0.0497  last_data_time: 0.0425   lr: 7.7801e-06  max_mem: 49046M
[03/05 16:19:23 d2.utils.events]:  eta: 1 day, 10:46:03  iter: 24359  total_loss: 9.945  loss_ce0: 0.701  loss_ce1: 1.226  loss_ce2: 1.179  loss_ce3: 0.8265  loss_ce4: 1.015  loss_ce5: 2.307  loss_ce6: 2.354    time: 1.6696  last_time: 1.6964  data_time: 0.0463  last_data_time: 0.0471   lr: 7.7782e-06  max_mem: 49046M
[03/05 16:19:56 d2.utils.events]:  eta: 1 day, 10:45:47  iter: 24379  total_loss: 9.993  loss_ce0: 0.7076  loss_ce1: 1.213  loss_ce2: 1.177  loss_ce3: 0.7571  loss_ce4: 1.041  loss_ce5: 2.36  loss_ce6: 2.671    time: 1.6696  last_time: 1.6512  data_time: 0.0488  last_data_time: 0.0443   lr: 7.7764e-06  max_mem: 49046M
[03/05 16:20:29 d2.utils.events]:  eta: 1 day, 10:46:23  iter: 24399  total_loss: 10.24  loss_ce0: 0.7327  loss_ce1: 1.235  loss_ce2: 1.191  loss_ce3: 0.7915  loss_ce4: 0.984  loss_ce5: 2.58  loss_ce6: 2.579    time: 1.6695  last_time: 1.6255  data_time: 0.0471  last_data_time: 0.0453   lr: 7.7745e-06  max_mem: 49046M
[03/05 16:21:03 d2.utils.events]:  eta: 1 day, 10:46:15  iter: 24419  total_loss: 9.623  loss_ce0: 0.7044  loss_ce1: 1.208  loss_ce2: 1.157  loss_ce3: 0.8105  loss_ce4: 0.9505  loss_ce5: 2.418  loss_ce6: 2.463    time: 1.6696  last_time: 1.6073  data_time: 0.0463  last_data_time: 0.0388   lr: 7.7727e-06  max_mem: 49046M
[03/05 16:21:36 d2.utils.events]:  eta: 1 day, 10:47:00  iter: 24439  total_loss: 9.618  loss_ce0: 0.7521  loss_ce1: 1.176  loss_ce2: 1.139  loss_ce3: 0.8673  loss_ce4: 0.9954  loss_ce5: 2.361  loss_ce6: 2.437    time: 1.6696  last_time: 1.6619  data_time: 0.0456  last_data_time: 0.0461   lr: 7.7708e-06  max_mem: 49046M
[03/05 16:22:10 d2.utils.events]:  eta: 1 day, 10:46:14  iter: 24459  total_loss: 9.765  loss_ce0: 0.691  loss_ce1: 1.133  loss_ce2: 1.213  loss_ce3: 0.7872  loss_ce4: 0.9634  loss_ce5: 2.155  loss_ce6: 2.51    time: 1.6695  last_time: 1.6160  data_time: 0.0453  last_data_time: 0.0445   lr: 7.769e-06  max_mem: 49046M
[03/05 16:22:43 d2.utils.events]:  eta: 1 day, 10:45:41  iter: 24479  total_loss: 10  loss_ce0: 0.7307  loss_ce1: 1.218  loss_ce2: 1.252  loss_ce3: 0.8523  loss_ce4: 0.986  loss_ce5: 2.205  loss_ce6: 2.358    time: 1.6695  last_time: 1.6067  data_time: 0.0459  last_data_time: 0.0436   lr: 7.7671e-06  max_mem: 49046M
[03/05 16:23:17 d2.utils.events]:  eta: 1 day, 10:46:52  iter: 24499  total_loss: 9.262  loss_ce0: 0.7063  loss_ce1: 1.2  loss_ce2: 1.112  loss_ce3: 0.8075  loss_ce4: 1.007  loss_ce5: 2.064  loss_ce6: 2.275    time: 1.6696  last_time: 1.7463  data_time: 0.0448  last_data_time: 0.0538   lr: 7.7653e-06  max_mem: 49046M
[03/05 16:23:49 d2.utils.events]:  eta: 1 day, 10:46:34  iter: 24519  total_loss: 9.76  loss_ce0: 0.6866  loss_ce1: 1.127  loss_ce2: 1.117  loss_ce3: 0.9171  loss_ce4: 0.9662  loss_ce5: 2.374  loss_ce6: 2.435    time: 1.6694  last_time: 1.7111  data_time: 0.0449  last_data_time: 0.0470   lr: 7.7634e-06  max_mem: 49046M
[03/05 16:24:23 d2.utils.events]:  eta: 1 day, 10:47:32  iter: 24539  total_loss: 9.939  loss_ce0: 0.7042  loss_ce1: 1.233  loss_ce2: 1.149  loss_ce3: 0.811  loss_ce4: 1.046  loss_ce5: 2.263  loss_ce6: 2.203    time: 1.6695  last_time: 1.6655  data_time: 0.0469  last_data_time: 0.0433   lr: 7.7616e-06  max_mem: 49046M
[03/05 16:24:56 d2.utils.events]:  eta: 1 day, 10:45:28  iter: 24559  total_loss: 9.808  loss_ce0: 0.6946  loss_ce1: 1.117  loss_ce2: 1.108  loss_ce3: 0.8214  loss_ce4: 0.9435  loss_ce5: 2.318  loss_ce6: 2.371    time: 1.6694  last_time: 1.5962  data_time: 0.0444  last_data_time: 0.0427   lr: 7.7597e-06  max_mem: 49046M
[03/05 16:25:29 d2.utils.events]:  eta: 1 day, 10:45:10  iter: 24579  total_loss: 9.826  loss_ce0: 0.717  loss_ce1: 1.184  loss_ce2: 1.173  loss_ce3: 0.8379  loss_ce4: 0.9877  loss_ce5: 2.244  loss_ce6: 2.332    time: 1.6694  last_time: 1.6129  data_time: 0.0460  last_data_time: 0.0415   lr: 7.7579e-06  max_mem: 49046M
[03/05 16:26:03 d2.utils.events]:  eta: 1 day, 10:45:25  iter: 24599  total_loss: 9.752  loss_ce0: 0.6918  loss_ce1: 1.211  loss_ce2: 1.221  loss_ce3: 0.7694  loss_ce4: 1.003  loss_ce5: 2.049  loss_ce6: 2.41    time: 1.6694  last_time: 1.6098  data_time: 0.0461  last_data_time: 0.0464   lr: 7.756e-06  max_mem: 49046M
[03/05 16:26:36 d2.utils.events]:  eta: 1 day, 10:45:23  iter: 24619  total_loss: 9.846  loss_ce0: 0.6909  loss_ce1: 1.26  loss_ce2: 1.169  loss_ce3: 0.8364  loss_ce4: 0.9936  loss_ce5: 2.4  loss_ce6: 2.49    time: 1.6694  last_time: 1.6760  data_time: 0.0478  last_data_time: 0.0457   lr: 7.7542e-06  max_mem: 49046M
[03/05 16:27:09 d2.utils.events]:  eta: 1 day, 10:43:57  iter: 24639  total_loss: 9.74  loss_ce0: 0.7084  loss_ce1: 1.182  loss_ce2: 0.9808  loss_ce3: 0.7393  loss_ce4: 1  loss_ce5: 2.371  loss_ce6: 2.558    time: 1.6693  last_time: 1.6971  data_time: 0.0448  last_data_time: 0.0550   lr: 7.7523e-06  max_mem: 49046M
[03/05 16:27:42 d2.utils.events]:  eta: 1 day, 10:43:24  iter: 24659  total_loss: 9.535  loss_ce0: 0.7227  loss_ce1: 1.124  loss_ce2: 1.272  loss_ce3: 0.773  loss_ce4: 0.9924  loss_ce5: 2.26  loss_ce6: 2.413    time: 1.6692  last_time: 1.6683  data_time: 0.0466  last_data_time: 0.0488   lr: 7.7505e-06  max_mem: 49046M
[03/05 16:28:15 d2.utils.events]:  eta: 1 day, 10:43:13  iter: 24679  total_loss: 10.21  loss_ce0: 0.6769  loss_ce1: 1.256  loss_ce2: 1.307  loss_ce3: 0.9801  loss_ce4: 0.9487  loss_ce5: 2.407  loss_ce6: 2.436    time: 1.6691  last_time: 1.6103  data_time: 0.0471  last_data_time: 0.0451   lr: 7.7486e-06  max_mem: 49046M
[03/05 16:28:49 d2.utils.events]:  eta: 1 day, 10:42:39  iter: 24699  total_loss: 9.835  loss_ce0: 0.7215  loss_ce1: 1.21  loss_ce2: 1.178  loss_ce3: 0.8081  loss_ce4: 1.002  loss_ce5: 2.42  loss_ce6: 2.439    time: 1.6691  last_time: 1.6681  data_time: 0.0493  last_data_time: 0.0406   lr: 7.7468e-06  max_mem: 49046M
[03/05 16:29:22 d2.utils.events]:  eta: 1 day, 10:41:31  iter: 24719  total_loss: 10.04  loss_ce0: 0.711  loss_ce1: 1.243  loss_ce2: 1.189  loss_ce3: 0.7742  loss_ce4: 0.987  loss_ce5: 2.374  loss_ce6: 2.62    time: 1.6691  last_time: 1.6522  data_time: 0.0450  last_data_time: 0.0446   lr: 7.7449e-06  max_mem: 49046M
[03/05 16:29:55 d2.utils.events]:  eta: 1 day, 10:40:51  iter: 24739  total_loss: 9.92  loss_ce0: 0.7058  loss_ce1: 1.091  loss_ce2: 1.138  loss_ce3: 0.9226  loss_ce4: 0.9759  loss_ce5: 2.241  loss_ce6: 2.419    time: 1.6690  last_time: 1.7513  data_time: 0.0443  last_data_time: 0.0456   lr: 7.7431e-06  max_mem: 49046M
[03/05 16:30:28 d2.utils.events]:  eta: 1 day, 10:40:25  iter: 24759  total_loss: 10.12  loss_ce0: 0.7048  loss_ce1: 1.101  loss_ce2: 1.089  loss_ce3: 0.8859  loss_ce4: 1.005  loss_ce5: 2.312  loss_ce6: 2.525    time: 1.6690  last_time: 1.6067  data_time: 0.0470  last_data_time: 0.0422   lr: 7.7412e-06  max_mem: 49046M
[03/05 16:31:02 d2.utils.events]:  eta: 1 day, 10:39:51  iter: 24779  total_loss: 10.13  loss_ce0: 0.7135  loss_ce1: 1.219  loss_ce2: 1.173  loss_ce3: 0.8421  loss_ce4: 1.036  loss_ce5: 2.351  loss_ce6: 2.54    time: 1.6690  last_time: 1.6499  data_time: 0.0464  last_data_time: 0.0480   lr: 7.7394e-06  max_mem: 49046M
[03/05 16:31:35 d2.utils.events]:  eta: 1 day, 10:39:05  iter: 24799  total_loss: 10.08  loss_ce0: 0.6905  loss_ce1: 1.202  loss_ce2: 1.202  loss_ce3: 0.811  loss_ce4: 1.009  loss_ce5: 2.329  loss_ce6: 2.501    time: 1.6689  last_time: 1.7008  data_time: 0.0457  last_data_time: 0.0496   lr: 7.7375e-06  max_mem: 49046M
[03/05 16:32:08 d2.utils.events]:  eta: 1 day, 10:38:24  iter: 24819  total_loss: 9.698  loss_ce0: 0.7151  loss_ce1: 1.107  loss_ce2: 1.178  loss_ce3: 0.8035  loss_ce4: 0.997  loss_ce5: 2.339  loss_ce6: 2.517    time: 1.6689  last_time: 1.6005  data_time: 0.0449  last_data_time: 0.0460   lr: 7.7357e-06  max_mem: 49046M
[03/05 16:32:41 d2.utils.events]:  eta: 1 day, 10:37:25  iter: 24839  total_loss: 9.534  loss_ce0: 0.6902  loss_ce1: 1.192  loss_ce2: 1.144  loss_ce3: 0.8283  loss_ce4: 1.021  loss_ce5: 2.197  loss_ce6: 2.294    time: 1.6688  last_time: 1.7139  data_time: 0.0452  last_data_time: 0.0494   lr: 7.7338e-06  max_mem: 49046M
[03/05 16:33:14 d2.utils.events]:  eta: 1 day, 10:36:55  iter: 24859  total_loss: 9.834  loss_ce0: 0.7274  loss_ce1: 1.138  loss_ce2: 1.264  loss_ce3: 0.7679  loss_ce4: 1.019  loss_ce5: 2.356  loss_ce6: 2.453    time: 1.6687  last_time: 1.6047  data_time: 0.0445  last_data_time: 0.0424   lr: 7.732e-06  max_mem: 49046M
[03/05 16:33:48 d2.utils.events]:  eta: 1 day, 10:36:59  iter: 24879  total_loss: 9.64  loss_ce0: 0.7121  loss_ce1: 1.239  loss_ce2: 1.093  loss_ce3: 0.8121  loss_ce4: 0.994  loss_ce5: 2.26  loss_ce6: 2.403    time: 1.6687  last_time: 1.7268  data_time: 0.0445  last_data_time: 0.0466   lr: 7.7301e-06  max_mem: 49046M
[03/05 16:34:21 d2.utils.events]:  eta: 1 day, 10:36:32  iter: 24899  total_loss: 9.894  loss_ce0: 0.7155  loss_ce1: 1.166  loss_ce2: 1.266  loss_ce3: 0.7684  loss_ce4: 0.9622  loss_ce5: 2.365  loss_ce6: 2.343    time: 1.6687  last_time: 1.7903  data_time: 0.0461  last_data_time: 0.0457   lr: 7.7282e-06  max_mem: 49046M
[03/05 16:34:54 d2.utils.events]:  eta: 1 day, 10:36:24  iter: 24919  total_loss: 10.02  loss_ce0: 0.7148  loss_ce1: 1.097  loss_ce2: 1.287  loss_ce3: 0.8212  loss_ce4: 0.9873  loss_ce5: 2.244  loss_ce6: 2.745    time: 1.6686  last_time: 1.6701  data_time: 0.0444  last_data_time: 0.0449   lr: 7.7264e-06  max_mem: 49046M
[03/05 16:35:27 d2.utils.events]:  eta: 1 day, 10:37:05  iter: 24939  total_loss: 9.961  loss_ce0: 0.7003  loss_ce1: 1.195  loss_ce2: 1.088  loss_ce3: 0.8695  loss_ce4: 0.9803  loss_ce5: 2.256  loss_ce6: 2.429    time: 1.6687  last_time: 1.7023  data_time: 0.0476  last_data_time: 0.0469   lr: 7.7245e-06  max_mem: 49046M
[03/05 16:36:01 d2.utils.events]:  eta: 1 day, 10:36:11  iter: 24959  total_loss: 9.732  loss_ce0: 0.696  loss_ce1: 1.162  loss_ce2: 1.227  loss_ce3: 0.8285  loss_ce4: 0.9576  loss_ce5: 2.064  loss_ce6: 2.33    time: 1.6687  last_time: 1.6029  data_time: 0.0474  last_data_time: 0.0414   lr: 7.7227e-06  max_mem: 49046M
[03/05 16:36:34 d2.utils.events]:  eta: 1 day, 10:35:38  iter: 24979  total_loss: 9.579  loss_ce0: 0.7156  loss_ce1: 1.092  loss_ce2: 1.158  loss_ce3: 0.8064  loss_ce4: 0.9822  loss_ce5: 2.165  loss_ce6: 2.516    time: 1.6687  last_time: 1.6097  data_time: 0.0473  last_data_time: 0.0380   lr: 7.7208e-06  max_mem: 49046M
[03/05 16:37:07 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0024999.pth
[03/05 16:37:09 d2.utils.events]:  eta: 1 day, 10:35:05  iter: 24999  total_loss: 10.03  loss_ce0: 0.7009  loss_ce1: 1.21  loss_ce2: 1.153  loss_ce3: 0.898  loss_ce4: 1.015  loss_ce5: 2.163  loss_ce6: 2.63    time: 1.6686  last_time: 1.6348  data_time: 0.0458  last_data_time: 0.0458   lr: 7.719e-06  max_mem: 49046M
[03/05 16:37:42 d2.utils.events]:  eta: 1 day, 10:34:26  iter: 25019  total_loss: 9.721  loss_ce0: 0.7241  loss_ce1: 1.222  loss_ce2: 1.246  loss_ce3: 0.735  loss_ce4: 0.9564  loss_ce5: 2.268  loss_ce6: 2.352    time: 1.6685  last_time: 1.6720  data_time: 0.0466  last_data_time: 0.0448   lr: 7.7171e-06  max_mem: 49046M
[03/05 16:38:16 d2.utils.events]:  eta: 1 day, 10:34:26  iter: 25039  total_loss: 9.974  loss_ce0: 0.7134  loss_ce1: 1.238  loss_ce2: 1.217  loss_ce3: 0.8327  loss_ce4: 1.02  loss_ce5: 2.258  loss_ce6: 2.399    time: 1.6686  last_time: 1.6479  data_time: 0.0470  last_data_time: 0.0424   lr: 7.7153e-06  max_mem: 49046M
[03/05 16:38:49 d2.utils.events]:  eta: 1 day, 10:34:55  iter: 25059  total_loss: 9.711  loss_ce0: 0.6984  loss_ce1: 1.18  loss_ce2: 1.285  loss_ce3: 0.8034  loss_ce4: 1.01  loss_ce5: 2.188  loss_ce6: 2.185    time: 1.6686  last_time: 1.6755  data_time: 0.0461  last_data_time: 0.0467   lr: 7.7134e-06  max_mem: 49046M
[03/05 16:39:22 d2.utils.events]:  eta: 1 day, 10:33:20  iter: 25079  total_loss: 9.861  loss_ce0: 0.715  loss_ce1: 1.103  loss_ce2: 1.227  loss_ce3: 0.7714  loss_ce4: 0.9922  loss_ce5: 2.235  loss_ce6: 2.573    time: 1.6685  last_time: 1.7150  data_time: 0.0476  last_data_time: 0.0481   lr: 7.7116e-06  max_mem: 49046M
[03/05 16:39:56 d2.utils.events]:  eta: 1 day, 10:32:08  iter: 25099  total_loss: 10.06  loss_ce0: 0.7171  loss_ce1: 1.189  loss_ce2: 1.131  loss_ce3: 0.7931  loss_ce4: 0.9755  loss_ce5: 2.287  loss_ce6: 2.742    time: 1.6685  last_time: 1.6272  data_time: 0.0456  last_data_time: 0.0443   lr: 7.7097e-06  max_mem: 49046M
[03/05 16:40:29 d2.utils.events]:  eta: 1 day, 10:30:52  iter: 25119  total_loss: 10.23  loss_ce0: 0.715  loss_ce1: 1.173  loss_ce2: 1.212  loss_ce3: 0.8272  loss_ce4: 1.022  loss_ce5: 2.098  loss_ce6: 2.765    time: 1.6685  last_time: 1.6860  data_time: 0.0455  last_data_time: 0.0458   lr: 7.7079e-06  max_mem: 49046M
[03/05 16:41:02 d2.utils.events]:  eta: 1 day, 10:30:05  iter: 25139  total_loss: 9.689  loss_ce0: 0.7227  loss_ce1: 1.172  loss_ce2: 1.195  loss_ce3: 0.7728  loss_ce4: 1.003  loss_ce5: 2.211  loss_ce6: 2.414    time: 1.6685  last_time: 1.7645  data_time: 0.0454  last_data_time: 0.0455   lr: 7.706e-06  max_mem: 49046M
[03/05 16:41:35 d2.utils.events]:  eta: 1 day, 10:28:34  iter: 25159  total_loss: 10.13  loss_ce0: 0.6945  loss_ce1: 1.226  loss_ce2: 1.216  loss_ce3: 0.8309  loss_ce4: 0.9724  loss_ce5: 2.222  loss_ce6: 2.433    time: 1.6684  last_time: 1.6157  data_time: 0.0449  last_data_time: 0.0442   lr: 7.7042e-06  max_mem: 49046M
[03/05 16:42:08 d2.utils.events]:  eta: 1 day, 10:27:50  iter: 25179  total_loss: 10.21  loss_ce0: 0.7164  loss_ce1: 1.181  loss_ce2: 1.116  loss_ce3: 0.9319  loss_ce4: 1.01  loss_ce5: 2.294  loss_ce6: 2.491    time: 1.6683  last_time: 1.6926  data_time: 0.0460  last_data_time: 0.0477   lr: 7.7023e-06  max_mem: 49046M
[03/05 16:42:42 d2.utils.events]:  eta: 1 day, 10:27:38  iter: 25199  total_loss: 10.08  loss_ce0: 0.6989  loss_ce1: 1.197  loss_ce2: 1.298  loss_ce3: 0.7748  loss_ce4: 0.9953  loss_ce5: 2.189  loss_ce6: 2.654    time: 1.6683  last_time: 1.7081  data_time: 0.0464  last_data_time: 0.0584   lr: 7.7005e-06  max_mem: 49046M
[03/05 16:43:15 d2.utils.events]:  eta: 1 day, 10:26:57  iter: 25219  total_loss: 9.948  loss_ce0: 0.7044  loss_ce1: 1.113  loss_ce2: 1.177  loss_ce3: 0.8231  loss_ce4: 0.957  loss_ce5: 2.209  loss_ce6: 2.638    time: 1.6683  last_time: 1.7456  data_time: 0.0462  last_data_time: 0.0485   lr: 7.6986e-06  max_mem: 49046M
[03/05 16:43:48 d2.utils.events]:  eta: 1 day, 10:25:54  iter: 25239  total_loss: 9.737  loss_ce0: 0.7351  loss_ce1: 1.247  loss_ce2: 1.176  loss_ce3: 0.7833  loss_ce4: 0.9475  loss_ce5: 2.189  loss_ce6: 2.443    time: 1.6683  last_time: 1.6119  data_time: 0.0463  last_data_time: 0.0440   lr: 7.6968e-06  max_mem: 49046M
[03/05 16:44:22 d2.utils.events]:  eta: 1 day, 10:24:15  iter: 25259  total_loss: 9.966  loss_ce0: 0.6934  loss_ce1: 1.208  loss_ce2: 1.112  loss_ce3: 0.8689  loss_ce4: 1.014  loss_ce5: 2.307  loss_ce6: 2.327    time: 1.6683  last_time: 1.6263  data_time: 0.0464  last_data_time: 0.0401   lr: 7.6949e-06  max_mem: 49046M
[03/05 16:44:55 d2.utils.events]:  eta: 1 day, 10:25:15  iter: 25279  total_loss: 9.56  loss_ce0: 0.7131  loss_ce1: 1.157  loss_ce2: 1.071  loss_ce3: 0.7901  loss_ce4: 1.058  loss_ce5: 2.229  loss_ce6: 2.428    time: 1.6683  last_time: 1.6085  data_time: 0.0465  last_data_time: 0.0420   lr: 7.693e-06  max_mem: 49046M
[03/05 16:45:28 d2.utils.events]:  eta: 1 day, 10:24:31  iter: 25299  total_loss: 10.08  loss_ce0: 0.7477  loss_ce1: 1.236  loss_ce2: 1.235  loss_ce3: 0.8612  loss_ce4: 0.993  loss_ce5: 2.351  loss_ce6: 2.567    time: 1.6683  last_time: 1.7080  data_time: 0.0464  last_data_time: 0.0435   lr: 7.6912e-06  max_mem: 49046M
[03/05 16:46:02 d2.utils.events]:  eta: 1 day, 10:24:13  iter: 25319  total_loss: 9.848  loss_ce0: 0.7024  loss_ce1: 1.198  loss_ce2: 1.18  loss_ce3: 0.7693  loss_ce4: 1.038  loss_ce5: 2.139  loss_ce6: 2.555    time: 1.6683  last_time: 1.6076  data_time: 0.0456  last_data_time: 0.0386   lr: 7.6893e-06  max_mem: 49046M
[03/05 16:46:35 d2.utils.events]:  eta: 1 day, 10:22:02  iter: 25339  total_loss: 10.26  loss_ce0: 0.7077  loss_ce1: 1.244  loss_ce2: 1.301  loss_ce3: 0.7777  loss_ce4: 1.008  loss_ce5: 2.647  loss_ce6: 2.605    time: 1.6682  last_time: 1.6206  data_time: 0.0482  last_data_time: 0.0437   lr: 7.6875e-06  max_mem: 49046M
[03/05 16:47:08 d2.utils.events]:  eta: 1 day, 10:23:06  iter: 25359  total_loss: 9.735  loss_ce0: 0.6915  loss_ce1: 1.146  loss_ce2: 1.186  loss_ce3: 0.7709  loss_ce4: 0.9836  loss_ce5: 2.175  loss_ce6: 2.622    time: 1.6683  last_time: 1.7310  data_time: 0.0459  last_data_time: 0.0486   lr: 7.6856e-06  max_mem: 49046M
[03/05 16:47:42 d2.utils.events]:  eta: 1 day, 10:22:33  iter: 25379  total_loss: 10.18  loss_ce0: 0.701  loss_ce1: 1.191  loss_ce2: 1.111  loss_ce3: 0.7809  loss_ce4: 0.9909  loss_ce5: 2.313  loss_ce6: 2.256    time: 1.6683  last_time: 1.6095  data_time: 0.0486  last_data_time: 0.0419   lr: 7.6838e-06  max_mem: 49046M
[03/05 16:48:15 d2.utils.events]:  eta: 1 day, 10:21:57  iter: 25399  total_loss: 10.09  loss_ce0: 0.6964  loss_ce1: 1.179  loss_ce2: 1.369  loss_ce3: 0.8457  loss_ce4: 0.9703  loss_ce5: 2.405  loss_ce6: 2.505    time: 1.6682  last_time: 1.6225  data_time: 0.0461  last_data_time: 0.0447   lr: 7.6819e-06  max_mem: 49046M
[03/05 16:48:48 d2.utils.events]:  eta: 1 day, 10:21:27  iter: 25419  total_loss: 10.21  loss_ce0: 0.7107  loss_ce1: 1.266  loss_ce2: 1.105  loss_ce3: 0.8269  loss_ce4: 1.028  loss_ce5: 2.206  loss_ce6: 2.531    time: 1.6682  last_time: 1.6476  data_time: 0.0470  last_data_time: 0.0501   lr: 7.6801e-06  max_mem: 49046M
[03/05 16:49:22 d2.utils.events]:  eta: 1 day, 10:21:36  iter: 25439  total_loss: 9.839  loss_ce0: 0.6873  loss_ce1: 1.215  loss_ce2: 0.9598  loss_ce3: 0.8633  loss_ce4: 0.9998  loss_ce5: 2.369  loss_ce6: 2.458    time: 1.6683  last_time: 1.6919  data_time: 0.0492  last_data_time: 0.0437   lr: 7.6782e-06  max_mem: 49046M
[03/05 16:49:55 d2.utils.events]:  eta: 1 day, 10:21:19  iter: 25459  total_loss: 9.694  loss_ce0: 0.7149  loss_ce1: 1.171  loss_ce2: 1.017  loss_ce3: 0.8637  loss_ce4: 1.008  loss_ce5: 2.166  loss_ce6: 2.315    time: 1.6682  last_time: 1.6765  data_time: 0.0451  last_data_time: 0.0487   lr: 7.6764e-06  max_mem: 49046M
[03/05 16:50:29 d2.utils.events]:  eta: 1 day, 10:20:58  iter: 25479  total_loss: 10.02  loss_ce0: 0.7171  loss_ce1: 1.177  loss_ce2: 1.212  loss_ce3: 0.7922  loss_ce4: 1.1  loss_ce5: 2.364  loss_ce6: 2.446    time: 1.6682  last_time: 1.6467  data_time: 0.0474  last_data_time: 0.0466   lr: 7.6745e-06  max_mem: 49046M
[03/05 16:51:02 d2.utils.events]:  eta: 1 day, 10:19:52  iter: 25499  total_loss: 9.893  loss_ce0: 0.7283  loss_ce1: 1.228  loss_ce2: 1.135  loss_ce3: 0.7856  loss_ce4: 1.061  loss_ce5: 2.215  loss_ce6: 2.616    time: 1.6682  last_time: 1.6854  data_time: 0.0454  last_data_time: 0.0530   lr: 7.6727e-06  max_mem: 49046M
[03/05 16:51:35 d2.utils.events]:  eta: 1 day, 10:19:40  iter: 25519  total_loss: 9.733  loss_ce0: 0.7003  loss_ce1: 1.143  loss_ce2: 1.273  loss_ce3: 0.7714  loss_ce4: 0.9956  loss_ce5: 2.184  loss_ce6: 2.466    time: 1.6681  last_time: 1.6922  data_time: 0.0473  last_data_time: 0.0442   lr: 7.6708e-06  max_mem: 49046M
[03/05 16:52:08 d2.utils.events]:  eta: 1 day, 10:17:55  iter: 25539  total_loss: 9.946  loss_ce0: 0.7064  loss_ce1: 1.181  loss_ce2: 1.08  loss_ce3: 0.7975  loss_ce4: 1.034  loss_ce5: 2.415  loss_ce6: 2.496    time: 1.6680  last_time: 1.6143  data_time: 0.0458  last_data_time: 0.0440   lr: 7.669e-06  max_mem: 49046M
[03/05 16:52:41 d2.utils.events]:  eta: 1 day, 10:17:40  iter: 25559  total_loss: 9.499  loss_ce0: 0.6973  loss_ce1: 1.159  loss_ce2: 1.142  loss_ce3: 0.7952  loss_ce4: 0.9916  loss_ce5: 2.061  loss_ce6: 2.518    time: 1.6680  last_time: 1.6922  data_time: 0.0446  last_data_time: 0.0474   lr: 7.6671e-06  max_mem: 49046M
[03/05 16:53:15 d2.utils.events]:  eta: 1 day, 10:18:00  iter: 25579  total_loss: 9.66  loss_ce0: 0.7065  loss_ce1: 1.263  loss_ce2: 1.182  loss_ce3: 0.8063  loss_ce4: 0.9714  loss_ce5: 2.088  loss_ce6: 2.292    time: 1.6681  last_time: 1.7727  data_time: 0.0489  last_data_time: 0.0588   lr: 7.6652e-06  max_mem: 49046M
[03/05 16:53:48 d2.utils.events]:  eta: 1 day, 10:17:19  iter: 25599  total_loss: 9.845  loss_ce0: 0.7379  loss_ce1: 1.209  loss_ce2: 1.17  loss_ce3: 0.8851  loss_ce4: 0.9788  loss_ce5: 2.2  loss_ce6: 2.489    time: 1.6681  last_time: 1.6340  data_time: 0.0470  last_data_time: 0.0440   lr: 7.6634e-06  max_mem: 49046M
[03/05 16:54:21 d2.utils.events]:  eta: 1 day, 10:15:51  iter: 25619  total_loss: 9.568  loss_ce0: 0.7206  loss_ce1: 1.064  loss_ce2: 1.257  loss_ce3: 0.7703  loss_ce4: 0.9789  loss_ce5: 2.217  loss_ce6: 2.292    time: 1.6680  last_time: 1.6459  data_time: 0.0443  last_data_time: 0.0474   lr: 7.6615e-06  max_mem: 49046M
[03/05 16:54:54 d2.utils.events]:  eta: 1 day, 10:15:27  iter: 25639  total_loss: 9.748  loss_ce0: 0.6896  loss_ce1: 1.246  loss_ce2: 1.121  loss_ce3: 0.8893  loss_ce4: 1.008  loss_ce5: 2.046  loss_ce6: 2.616    time: 1.6679  last_time: 1.6111  data_time: 0.0442  last_data_time: 0.0449   lr: 7.6597e-06  max_mem: 49046M
[03/05 16:55:28 d2.utils.events]:  eta: 1 day, 10:15:36  iter: 25659  total_loss: 10.26  loss_ce0: 0.7169  loss_ce1: 1.235  loss_ce2: 1.22  loss_ce3: 0.9041  loss_ce4: 0.9847  loss_ce5: 2.275  loss_ce6: 2.692    time: 1.6680  last_time: 1.7416  data_time: 0.0470  last_data_time: 0.0519   lr: 7.6578e-06  max_mem: 49046M
[03/05 16:56:02 d2.utils.events]:  eta: 1 day, 10:16:09  iter: 25679  total_loss: 9.416  loss_ce0: 0.681  loss_ce1: 1.192  loss_ce2: 1.077  loss_ce3: 0.837  loss_ce4: 0.9521  loss_ce5: 2.294  loss_ce6: 1.946    time: 1.6681  last_time: 1.6818  data_time: 0.0472  last_data_time: 0.0446   lr: 7.656e-06  max_mem: 49046M
[03/05 16:56:35 d2.utils.events]:  eta: 1 day, 10:15:36  iter: 25699  total_loss: 10.27  loss_ce0: 0.7011  loss_ce1: 1.182  loss_ce2: 1.089  loss_ce3: 0.8176  loss_ce4: 1.054  loss_ce5: 2.335  loss_ce6: 2.656    time: 1.6680  last_time: 1.7307  data_time: 0.0455  last_data_time: 0.0488   lr: 7.6541e-06  max_mem: 49046M
[03/05 16:57:08 d2.utils.events]:  eta: 1 day, 10:16:23  iter: 25719  total_loss: 9.715  loss_ce0: 0.6841  loss_ce1: 1.197  loss_ce2: 1.229  loss_ce3: 0.8729  loss_ce4: 0.9321  loss_ce5: 2.031  loss_ce6: 2.651    time: 1.6680  last_time: 1.6927  data_time: 0.0471  last_data_time: 0.0452   lr: 7.6523e-06  max_mem: 49046M
[03/05 16:57:41 d2.utils.events]:  eta: 1 day, 10:15:51  iter: 25739  total_loss: 9.463  loss_ce0: 0.6893  loss_ce1: 1.083  loss_ce2: 1.097  loss_ce3: 0.7921  loss_ce4: 0.964  loss_ce5: 2.067  loss_ce6: 2.376    time: 1.6680  last_time: 1.6616  data_time: 0.0455  last_data_time: 0.0463   lr: 7.6504e-06  max_mem: 49046M
[03/05 16:58:15 d2.utils.events]:  eta: 1 day, 10:15:18  iter: 25759  total_loss: 9.708  loss_ce0: 0.7366  loss_ce1: 1.193  loss_ce2: 1.034  loss_ce3: 0.8605  loss_ce4: 1.043  loss_ce5: 2.371  loss_ce6: 2.275    time: 1.6680  last_time: 1.7722  data_time: 0.0453  last_data_time: 0.0492   lr: 7.6486e-06  max_mem: 49046M
[03/05 16:58:48 d2.utils.events]:  eta: 1 day, 10:14:21  iter: 25779  total_loss: 9.514  loss_ce0: 0.7079  loss_ce1: 1.132  loss_ce2: 1.196  loss_ce3: 0.8108  loss_ce4: 1.036  loss_ce5: 2.2  loss_ce6: 2.458    time: 1.6680  last_time: 1.6272  data_time: 0.0468  last_data_time: 0.0440   lr: 7.6467e-06  max_mem: 49046M
[03/05 16:59:21 d2.utils.events]:  eta: 1 day, 10:14:03  iter: 25799  total_loss: 9.716  loss_ce0: 0.7135  loss_ce1: 1.153  loss_ce2: 1.218  loss_ce3: 0.817  loss_ce4: 1.022  loss_ce5: 2.392  loss_ce6: 2.286    time: 1.6680  last_time: 1.6081  data_time: 0.0468  last_data_time: 0.0403   lr: 7.6448e-06  max_mem: 49046M
[03/05 16:59:55 d2.utils.events]:  eta: 1 day, 10:13:30  iter: 25819  total_loss: 9.499  loss_ce0: 0.7379  loss_ce1: 1.167  loss_ce2: 1.236  loss_ce3: 0.8131  loss_ce4: 0.9472  loss_ce5: 2.242  loss_ce6: 2.278    time: 1.6679  last_time: 1.6812  data_time: 0.0451  last_data_time: 0.0432   lr: 7.643e-06  max_mem: 49046M
[03/05 17:00:28 d2.utils.events]:  eta: 1 day, 10:13:09  iter: 25839  total_loss: 9.795  loss_ce0: 0.7316  loss_ce1: 1.185  loss_ce2: 1.247  loss_ce3: 0.782  loss_ce4: 0.9688  loss_ce5: 2.251  loss_ce6: 2.433    time: 1.6679  last_time: 1.6547  data_time: 0.0454  last_data_time: 0.0432   lr: 7.6411e-06  max_mem: 49046M
[03/05 17:01:01 d2.utils.events]:  eta: 1 day, 10:12:23  iter: 25859  total_loss: 9.571  loss_ce0: 0.6848  loss_ce1: 1.098  loss_ce2: 1.251  loss_ce3: 0.8146  loss_ce4: 0.9709  loss_ce5: 2.19  loss_ce6: 2.199    time: 1.6679  last_time: 1.6399  data_time: 0.0464  last_data_time: 0.0430   lr: 7.6393e-06  max_mem: 49046M
[03/05 17:01:39 d2.utils.events]:  eta: 1 day, 10:11:35  iter: 25879  total_loss: 9.409  loss_ce0: 0.6751  loss_ce1: 1.131  loss_ce2: 1.108  loss_ce3: 0.8072  loss_ce4: 0.9873  loss_ce5: 2.101  loss_ce6: 2.584    time: 1.6679  last_time: 1.6138  data_time: 0.0487  last_data_time: 0.0420   lr: 7.6374e-06  max_mem: 49046M
[03/05 17:02:12 d2.utils.events]:  eta: 1 day, 10:11:17  iter: 25899  total_loss: 10.03  loss_ce0: 0.6884  loss_ce1: 1.084  loss_ce2: 1.145  loss_ce3: 0.8333  loss_ce4: 0.9913  loss_ce5: 2.325  loss_ce6: 2.446    time: 1.6679  last_time: 1.6523  data_time: 0.0444  last_data_time: 0.0465   lr: 7.6356e-06  max_mem: 49046M
[03/05 17:02:49 d2.utils.events]:  eta: 1 day, 10:11:36  iter: 25919  total_loss: 9.664  loss_ce0: 0.7197  loss_ce1: 1.194  loss_ce2: 1.169  loss_ce3: 0.794  loss_ce4: 0.9816  loss_ce5: 2.057  loss_ce6: 2.631    time: 1.6684  last_time: 1.6639  data_time: 0.1757  last_data_time: 0.0511   lr: 7.6337e-06  max_mem: 49046M
[03/05 17:03:22 d2.utils.events]:  eta: 1 day, 10:10:23  iter: 25939  total_loss: 9.658  loss_ce0: 0.7141  loss_ce1: 1.185  loss_ce2: 1.207  loss_ce3: 0.7684  loss_ce4: 0.9654  loss_ce5: 2.203  loss_ce6: 2.403    time: 1.6683  last_time: 1.6177  data_time: 0.0454  last_data_time: 0.0420   lr: 7.6319e-06  max_mem: 49046M
[03/05 17:03:55 d2.utils.events]:  eta: 1 day, 10:09:37  iter: 25959  total_loss: 9.666  loss_ce0: 0.6997  loss_ce1: 1.145  loss_ce2: 1.203  loss_ce3: 0.7944  loss_ce4: 1.005  loss_ce5: 2.199  loss_ce6: 2.508    time: 1.6683  last_time: 1.7744  data_time: 0.0446  last_data_time: 0.0602   lr: 7.63e-06  max_mem: 49046M
[03/05 17:04:28 d2.utils.events]:  eta: 1 day, 10:09:16  iter: 25979  total_loss: 9.53  loss_ce0: 0.7209  loss_ce1: 1.142  loss_ce2: 1.203  loss_ce3: 0.758  loss_ce4: 0.9593  loss_ce5: 2.274  loss_ce6: 2.491    time: 1.6683  last_time: 1.6779  data_time: 0.0449  last_data_time: 0.0423   lr: 7.6282e-06  max_mem: 49046M
[03/05 17:05:02 d2.utils.events]:  eta: 1 day, 10:09:22  iter: 25999  total_loss: 10.15  loss_ce0: 0.6913  loss_ce1: 1.146  loss_ce2: 1.165  loss_ce3: 0.7652  loss_ce4: 1.007  loss_ce5: 2.489  loss_ce6: 2.6    time: 1.6683  last_time: 1.6617  data_time: 0.0455  last_data_time: 0.0396   lr: 7.6263e-06  max_mem: 49046M
[03/05 17:05:35 d2.utils.events]:  eta: 1 day, 10:08:53  iter: 26019  total_loss: 9.49  loss_ce0: 0.7064  loss_ce1: 1.2  loss_ce2: 1.207  loss_ce3: 0.8108  loss_ce4: 1.012  loss_ce5: 2.206  loss_ce6: 2.45    time: 1.6683  last_time: 1.7648  data_time: 0.0454  last_data_time: 0.0496   lr: 7.6244e-06  max_mem: 49046M
[03/05 17:06:08 d2.utils.events]:  eta: 1 day, 10:08:11  iter: 26039  total_loss: 9.532  loss_ce0: 0.7078  loss_ce1: 1.159  loss_ce2: 1.161  loss_ce3: 0.8085  loss_ce4: 0.9918  loss_ce5: 2.373  loss_ce6: 2.293    time: 1.6683  last_time: 1.6860  data_time: 0.0458  last_data_time: 0.0480   lr: 7.6226e-06  max_mem: 49046M
[03/05 17:06:41 d2.utils.events]:  eta: 1 day, 10:07:22  iter: 26059  total_loss: 9.746  loss_ce0: 0.6825  loss_ce1: 1.143  loss_ce2: 1.281  loss_ce3: 0.8187  loss_ce4: 1.029  loss_ce5: 2.287  loss_ce6: 2.389    time: 1.6682  last_time: 1.6309  data_time: 0.0443  last_data_time: 0.0461   lr: 7.6207e-06  max_mem: 49046M
[03/05 17:07:14 d2.utils.events]:  eta: 1 day, 10:06:18  iter: 26079  total_loss: 9.817  loss_ce0: 0.7182  loss_ce1: 1.135  loss_ce2: 1.165  loss_ce3: 0.9348  loss_ce4: 0.9907  loss_ce5: 2.084  loss_ce6: 2.272    time: 1.6682  last_time: 1.6455  data_time: 0.0456  last_data_time: 0.0439   lr: 7.6189e-06  max_mem: 49046M
[03/05 17:07:48 d2.utils.events]:  eta: 1 day, 10:06:16  iter: 26099  total_loss: 9.676  loss_ce0: 0.6929  loss_ce1: 1.17  loss_ce2: 1.203  loss_ce3: 0.8276  loss_ce4: 0.9979  loss_ce5: 2.376  loss_ce6: 2.515    time: 1.6682  last_time: 1.6298  data_time: 0.0460  last_data_time: 0.0441   lr: 7.617e-06  max_mem: 49046M
[03/05 17:08:21 d2.utils.events]:  eta: 1 day, 10:05:37  iter: 26119  total_loss: 9.61  loss_ce0: 0.731  loss_ce1: 1.176  loss_ce2: 1.119  loss_ce3: 0.7694  loss_ce4: 1.011  loss_ce5: 2.117  loss_ce6: 2.194    time: 1.6681  last_time: 1.6399  data_time: 0.0446  last_data_time: 0.0470   lr: 7.6152e-06  max_mem: 49046M
[03/05 17:08:54 d2.utils.events]:  eta: 1 day, 10:05:18  iter: 26139  total_loss: 9.233  loss_ce0: 0.6717  loss_ce1: 1.078  loss_ce2: 1.237  loss_ce3: 0.7881  loss_ce4: 0.9639  loss_ce5: 2.179  loss_ce6: 2.264    time: 1.6681  last_time: 1.6691  data_time: 0.0452  last_data_time: 0.0450   lr: 7.6133e-06  max_mem: 49046M
[03/05 17:09:27 d2.utils.events]:  eta: 1 day, 10:05:03  iter: 26159  total_loss: 9.52  loss_ce0: 0.7169  loss_ce1: 1.131  loss_ce2: 1.375  loss_ce3: 0.791  loss_ce4: 0.9813  loss_ce5: 2.068  loss_ce6: 2.46    time: 1.6681  last_time: 1.6351  data_time: 0.0439  last_data_time: 0.0423   lr: 7.6115e-06  max_mem: 49046M
[03/05 17:10:00 d2.utils.events]:  eta: 1 day, 10:04:27  iter: 26179  total_loss: 10.04  loss_ce0: 0.7412  loss_ce1: 1.186  loss_ce2: 1.201  loss_ce3: 0.7735  loss_ce4: 1.033  loss_ce5: 2.362  loss_ce6: 2.243    time: 1.6680  last_time: 1.6936  data_time: 0.0439  last_data_time: 0.0462   lr: 7.6096e-06  max_mem: 49046M
[03/05 17:10:34 d2.utils.events]:  eta: 1 day, 10:04:12  iter: 26199  total_loss: 9.946  loss_ce0: 0.6757  loss_ce1: 1.134  loss_ce2: 1.149  loss_ce3: 0.8272  loss_ce4: 0.9467  loss_ce5: 2.32  loss_ce6: 2.391    time: 1.6681  last_time: 1.7306  data_time: 0.0452  last_data_time: 0.0432   lr: 7.6077e-06  max_mem: 49046M
[03/05 17:11:08 d2.utils.events]:  eta: 1 day, 10:03:30  iter: 26219  total_loss: 9.934  loss_ce0: 0.6903  loss_ce1: 1.204  loss_ce2: 1.127  loss_ce3: 0.9155  loss_ce4: 0.9598  loss_ce5: 2.46  loss_ce6: 2.397    time: 1.6681  last_time: 1.6860  data_time: 0.0447  last_data_time: 0.0441   lr: 7.6059e-06  max_mem: 49046M
[03/05 17:11:41 d2.utils.events]:  eta: 1 day, 10:03:21  iter: 26239  total_loss: 9.366  loss_ce0: 0.685  loss_ce1: 1.202  loss_ce2: 1.098  loss_ce3: 0.8062  loss_ce4: 0.9752  loss_ce5: 2.042  loss_ce6: 2.597    time: 1.6681  last_time: 1.7150  data_time: 0.0469  last_data_time: 0.0553   lr: 7.604e-06  max_mem: 49046M
[03/05 17:12:14 d2.utils.events]:  eta: 1 day, 10:02:41  iter: 26259  total_loss: 9.478  loss_ce0: 0.6841  loss_ce1: 1.207  loss_ce2: 1.273  loss_ce3: 0.8136  loss_ce4: 1.055  loss_ce5: 2.273  loss_ce6: 2.226    time: 1.6681  last_time: 1.6609  data_time: 0.0484  last_data_time: 0.0474   lr: 7.6022e-06  max_mem: 49046M
[03/05 17:12:48 d2.utils.events]:  eta: 1 day, 10:02:17  iter: 26279  total_loss: 10.14  loss_ce0: 0.708  loss_ce1: 1.224  loss_ce2: 1.257  loss_ce3: 0.7932  loss_ce4: 0.9492  loss_ce5: 2.226  loss_ce6: 2.608    time: 1.6681  last_time: 1.6745  data_time: 0.0469  last_data_time: 0.0464   lr: 7.6003e-06  max_mem: 49046M
[03/05 17:13:21 d2.utils.events]:  eta: 1 day, 10:01:35  iter: 26299  total_loss: 9.61  loss_ce0: 0.6999  loss_ce1: 1.187  loss_ce2: 1.217  loss_ce3: 0.7711  loss_ce4: 1.017  loss_ce5: 2.141  loss_ce6: 2.532    time: 1.6681  last_time: 1.6927  data_time: 0.0476  last_data_time: 0.0501   lr: 7.5985e-06  max_mem: 49046M
[03/05 17:13:54 d2.utils.events]:  eta: 1 day, 10:00:55  iter: 26319  total_loss: 9.988  loss_ce0: 0.7312  loss_ce1: 1.181  loss_ce2: 1.242  loss_ce3: 0.8554  loss_ce4: 1.004  loss_ce5: 2.29  loss_ce6: 2.468    time: 1.6680  last_time: 1.7050  data_time: 0.0462  last_data_time: 0.0474   lr: 7.5966e-06  max_mem: 49046M
[03/05 17:14:27 d2.utils.events]:  eta: 1 day, 10:00:52  iter: 26339  total_loss: 9.936  loss_ce0: 0.6999  loss_ce1: 1.211  loss_ce2: 1.063  loss_ce3: 0.8616  loss_ce4: 0.9597  loss_ce5: 2.285  loss_ce6: 2.48    time: 1.6680  last_time: 1.6578  data_time: 0.0462  last_data_time: 0.0472   lr: 7.5948e-06  max_mem: 49046M
[03/05 17:15:01 d2.utils.events]:  eta: 1 day, 9:59:48  iter: 26359  total_loss: 9.977  loss_ce0: 0.7054  loss_ce1: 1.186  loss_ce2: 1.27  loss_ce3: 0.7875  loss_ce4: 1.01  loss_ce5: 2.242  loss_ce6: 2.427    time: 1.6680  last_time: 1.6598  data_time: 0.0451  last_data_time: 0.0519   lr: 7.5929e-06  max_mem: 49046M
[03/05 17:15:35 d2.utils.events]:  eta: 1 day, 9:59:29  iter: 26379  total_loss: 9.649  loss_ce0: 0.6803  loss_ce1: 1.146  loss_ce2: 1.045  loss_ce3: 0.8016  loss_ce4: 1.043  loss_ce5: 2.389  loss_ce6: 2.235    time: 1.6681  last_time: 1.8375  data_time: 0.0460  last_data_time: 0.0455   lr: 7.591e-06  max_mem: 49046M
[03/05 17:16:08 d2.utils.events]:  eta: 1 day, 9:58:45  iter: 26399  total_loss: 9.585  loss_ce0: 0.6931  loss_ce1: 1.248  loss_ce2: 1.161  loss_ce3: 0.7931  loss_ce4: 1.077  loss_ce5: 2.213  loss_ce6: 2.4    time: 1.6680  last_time: 1.6179  data_time: 0.0457  last_data_time: 0.0440   lr: 7.5892e-06  max_mem: 49046M
[03/05 17:16:41 d2.utils.events]:  eta: 1 day, 9:58:12  iter: 26419  total_loss: 9.492  loss_ce0: 0.7126  loss_ce1: 1.193  loss_ce2: 1.053  loss_ce3: 0.7726  loss_ce4: 0.9628  loss_ce5: 2.172  loss_ce6: 2.419    time: 1.6680  last_time: 1.6298  data_time: 0.0467  last_data_time: 0.0413   lr: 7.5873e-06  max_mem: 49046M
[03/05 17:17:14 d2.utils.events]:  eta: 1 day, 9:56:59  iter: 26439  total_loss: 9.956  loss_ce0: 0.7078  loss_ce1: 1.136  loss_ce2: 1.243  loss_ce3: 0.7638  loss_ce4: 0.9989  loss_ce5: 2.192  loss_ce6: 2.459    time: 1.6680  last_time: 1.6131  data_time: 0.0457  last_data_time: 0.0434   lr: 7.5855e-06  max_mem: 49046M
[03/05 17:17:48 d2.utils.events]:  eta: 1 day, 9:56:33  iter: 26459  total_loss: 9.788  loss_ce0: 0.6867  loss_ce1: 1.188  loss_ce2: 1.217  loss_ce3: 0.8659  loss_ce4: 1.012  loss_ce5: 2.201  loss_ce6: 2.398    time: 1.6680  last_time: 1.8256  data_time: 0.0470  last_data_time: 0.0468   lr: 7.5836e-06  max_mem: 49046M
[03/05 17:18:22 d2.utils.events]:  eta: 1 day, 9:56:11  iter: 26479  total_loss: 9.998  loss_ce0: 0.7199  loss_ce1: 1.186  loss_ce2: 1.262  loss_ce3: 0.7789  loss_ce4: 0.9941  loss_ce5: 2.225  loss_ce6: 2.482    time: 1.6681  last_time: 1.7771  data_time: 0.0461  last_data_time: 0.0489   lr: 7.5818e-06  max_mem: 49046M
[03/05 17:18:55 d2.utils.events]:  eta: 1 day, 9:55:57  iter: 26499  total_loss: 9.605  loss_ce0: 0.7109  loss_ce1: 1.174  loss_ce2: 1.306  loss_ce3: 0.8016  loss_ce4: 0.9391  loss_ce5: 2.12  loss_ce6: 2.346    time: 1.6681  last_time: 1.7665  data_time: 0.0460  last_data_time: 0.0477   lr: 7.5799e-06  max_mem: 49046M
[03/05 17:19:29 d2.utils.events]:  eta: 1 day, 9:55:56  iter: 26519  total_loss: 9.973  loss_ce0: 0.7195  loss_ce1: 1.226  loss_ce2: 1.261  loss_ce3: 0.7726  loss_ce4: 1.01  loss_ce5: 2.354  loss_ce6: 2.52    time: 1.6681  last_time: 1.7009  data_time: 0.0475  last_data_time: 0.0875   lr: 7.5781e-06  max_mem: 49046M
[03/05 17:20:02 d2.utils.events]:  eta: 1 day, 9:55:54  iter: 26539  total_loss: 9.593  loss_ce0: 0.7066  loss_ce1: 1.166  loss_ce2: 1.09  loss_ce3: 0.8412  loss_ce4: 0.9766  loss_ce5: 2.089  loss_ce6: 2.275    time: 1.6681  last_time: 1.6760  data_time: 0.0475  last_data_time: 0.0440   lr: 7.5762e-06  max_mem: 49046M
[03/05 17:20:36 d2.utils.events]:  eta: 1 day, 9:55:36  iter: 26559  total_loss: 9.499  loss_ce0: 0.7055  loss_ce1: 1.219  loss_ce2: 1.135  loss_ce3: 0.8641  loss_ce4: 0.9774  loss_ce5: 2.136  loss_ce6: 2.289    time: 1.6682  last_time: 1.6736  data_time: 0.0467  last_data_time: 0.0447   lr: 7.5743e-06  max_mem: 49046M
[03/05 17:21:10 d2.utils.events]:  eta: 1 day, 9:54:39  iter: 26579  total_loss: 9.808  loss_ce0: 0.7348  loss_ce1: 1.178  loss_ce2: 1.077  loss_ce3: 0.8107  loss_ce4: 0.9715  loss_ce5: 2.357  loss_ce6: 2.398    time: 1.6682  last_time: 1.8125  data_time: 0.0469  last_data_time: 0.0407   lr: 7.5725e-06  max_mem: 49046M
[03/05 17:21:43 d2.utils.events]:  eta: 1 day, 9:53:34  iter: 26599  total_loss: 9.78  loss_ce0: 0.6736  loss_ce1: 1.183  loss_ce2: 0.9612  loss_ce3: 0.859  loss_ce4: 1.004  loss_ce5: 2.374  loss_ce6: 2.51    time: 1.6682  last_time: 1.6035  data_time: 0.0464  last_data_time: 0.0406   lr: 7.5706e-06  max_mem: 49046M
[03/05 17:22:16 d2.utils.events]:  eta: 1 day, 9:53:14  iter: 26619  total_loss: 9.686  loss_ce0: 0.6841  loss_ce1: 1.154  loss_ce2: 1.172  loss_ce3: 0.8093  loss_ce4: 1.015  loss_ce5: 2.273  loss_ce6: 2.37    time: 1.6682  last_time: 1.6337  data_time: 0.0469  last_data_time: 0.0454   lr: 7.5688e-06  max_mem: 49046M
[03/05 17:22:50 d2.utils.events]:  eta: 1 day, 9:53:23  iter: 26639  total_loss: 9.587  loss_ce0: 0.6966  loss_ce1: 1.108  loss_ce2: 1.049  loss_ce3: 0.7989  loss_ce4: 1.038  loss_ce5: 2.477  loss_ce6: 2.215    time: 1.6682  last_time: 1.6465  data_time: 0.0473  last_data_time: 0.0445   lr: 7.5669e-06  max_mem: 49046M
[03/05 17:23:23 d2.utils.events]:  eta: 1 day, 9:53:06  iter: 26659  total_loss: 9.663  loss_ce0: 0.7154  loss_ce1: 1.082  loss_ce2: 1.058  loss_ce3: 0.7652  loss_ce4: 1.024  loss_ce5: 2.181  loss_ce6: 2.568    time: 1.6682  last_time: 1.6968  data_time: 0.0492  last_data_time: 0.0475   lr: 7.5651e-06  max_mem: 49046M
[03/05 17:23:56 d2.utils.events]:  eta: 1 day, 9:51:10  iter: 26679  total_loss: 9.603  loss_ce0: 0.701  loss_ce1: 1.266  loss_ce2: 0.9127  loss_ce3: 0.8044  loss_ce4: 1.008  loss_ce5: 2.186  loss_ce6: 2.434    time: 1.6681  last_time: 1.6000  data_time: 0.0443  last_data_time: 0.0436   lr: 7.5632e-06  max_mem: 49046M
[03/05 17:24:30 d2.utils.events]:  eta: 1 day, 9:50:56  iter: 26699  total_loss: 9.887  loss_ce0: 0.7163  loss_ce1: 1.165  loss_ce2: 1.166  loss_ce3: 0.7917  loss_ce4: 0.986  loss_ce5: 2.433  loss_ce6: 2.413    time: 1.6682  last_time: 1.6848  data_time: 0.0495  last_data_time: 0.0612   lr: 7.5613e-06  max_mem: 49046M
[03/05 17:25:03 d2.utils.events]:  eta: 1 day, 9:50:04  iter: 26719  total_loss: 9.921  loss_ce0: 0.7205  loss_ce1: 1.133  loss_ce2: 1.131  loss_ce3: 0.7938  loss_ce4: 0.988  loss_ce5: 2.266  loss_ce6: 2.269    time: 1.6681  last_time: 1.6586  data_time: 0.0458  last_data_time: 0.0452   lr: 7.5595e-06  max_mem: 49046M
[03/05 17:25:36 d2.utils.events]:  eta: 1 day, 9:50:04  iter: 26739  total_loss: 9.763  loss_ce0: 0.7278  loss_ce1: 1.141  loss_ce2: 1.128  loss_ce3: 0.8284  loss_ce4: 0.9818  loss_ce5: 2.072  loss_ce6: 2.345    time: 1.6681  last_time: 1.6752  data_time: 0.0455  last_data_time: 0.0460   lr: 7.5576e-06  max_mem: 49046M
[03/05 17:26:09 d2.utils.events]:  eta: 1 day, 9:49:40  iter: 26759  total_loss: 9.215  loss_ce0: 0.6946  loss_ce1: 1.099  loss_ce2: 1.104  loss_ce3: 0.8093  loss_ce4: 0.9742  loss_ce5: 2.12  loss_ce6: 2.277    time: 1.6681  last_time: 1.7782  data_time: 0.0450  last_data_time: 0.0487   lr: 7.5558e-06  max_mem: 49046M
[03/05 17:26:43 d2.utils.events]:  eta: 1 day, 9:48:43  iter: 26779  total_loss: 9.696  loss_ce0: 0.7273  loss_ce1: 1.157  loss_ce2: 1.156  loss_ce3: 0.8312  loss_ce4: 0.9336  loss_ce5: 2.202  loss_ce6: 2.368    time: 1.6681  last_time: 1.6614  data_time: 0.0448  last_data_time: 0.0513   lr: 7.5539e-06  max_mem: 49046M
[03/05 17:27:16 d2.utils.events]:  eta: 1 day, 9:47:51  iter: 26799  total_loss: 9.638  loss_ce0: 0.6881  loss_ce1: 1.174  loss_ce2: 1.134  loss_ce3: 0.8354  loss_ce4: 1.02  loss_ce5: 2.352  loss_ce6: 2.44    time: 1.6680  last_time: 1.6805  data_time: 0.0455  last_data_time: 0.0465   lr: 7.5521e-06  max_mem: 49046M
[03/05 17:27:49 d2.utils.events]:  eta: 1 day, 9:47:37  iter: 26819  total_loss: 9.601  loss_ce0: 0.6907  loss_ce1: 1.19  loss_ce2: 1.107  loss_ce3: 0.7825  loss_ce4: 0.9863  loss_ce5: 2.087  loss_ce6: 2.397    time: 1.6680  last_time: 1.6297  data_time: 0.0450  last_data_time: 0.0424   lr: 7.5502e-06  max_mem: 49046M
[03/05 17:28:22 d2.utils.events]:  eta: 1 day, 9:46:39  iter: 26839  total_loss: 9.73  loss_ce0: 0.7137  loss_ce1: 1.138  loss_ce2: 1.217  loss_ce3: 0.7444  loss_ce4: 1.002  loss_ce5: 2.376  loss_ce6: 2.431    time: 1.6679  last_time: 1.6887  data_time: 0.0453  last_data_time: 0.0434   lr: 7.5483e-06  max_mem: 49046M
[03/05 17:28:56 d2.utils.events]:  eta: 1 day, 9:46:37  iter: 26859  total_loss: 9.572  loss_ce0: 0.7207  loss_ce1: 1.169  loss_ce2: 1.056  loss_ce3: 0.8801  loss_ce4: 0.9862  loss_ce5: 2.108  loss_ce6: 2.292    time: 1.6680  last_time: 1.6600  data_time: 0.0494  last_data_time: 0.0436   lr: 7.5465e-06  max_mem: 49046M
[03/05 17:29:29 d2.utils.events]:  eta: 1 day, 9:46:01  iter: 26879  total_loss: 9.595  loss_ce0: 0.7037  loss_ce1: 1.175  loss_ce2: 1.208  loss_ce3: 0.8161  loss_ce4: 0.9834  loss_ce5: 2.116  loss_ce6: 2.36    time: 1.6680  last_time: 1.6538  data_time: 0.0474  last_data_time: 0.0400   lr: 7.5446e-06  max_mem: 49046M
[03/05 17:30:03 d2.utils.events]:  eta: 1 day, 9:45:31  iter: 26899  total_loss: 9.507  loss_ce0: 0.7239  loss_ce1: 1.173  loss_ce2: 1.195  loss_ce3: 0.8446  loss_ce4: 0.9792  loss_ce5: 2.189  loss_ce6: 2.298    time: 1.6680  last_time: 1.7067  data_time: 0.0453  last_data_time: 0.0476   lr: 7.5428e-06  max_mem: 49046M
[03/05 17:30:36 d2.utils.events]:  eta: 1 day, 9:44:51  iter: 26919  total_loss: 9.721  loss_ce0: 0.7113  loss_ce1: 1.159  loss_ce2: 1.145  loss_ce3: 0.762  loss_ce4: 0.9993  loss_ce5: 2.114  loss_ce6: 2.321    time: 1.6680  last_time: 1.6746  data_time: 0.0444  last_data_time: 0.0444   lr: 7.5409e-06  max_mem: 49046M
[03/05 17:31:09 d2.utils.events]:  eta: 1 day, 9:44:32  iter: 26939  total_loss: 9.766  loss_ce0: 0.6737  loss_ce1: 1.186  loss_ce2: 1.221  loss_ce3: 0.7585  loss_ce4: 0.9772  loss_ce5: 2.389  loss_ce6: 2.498    time: 1.6680  last_time: 1.6543  data_time: 0.0506  last_data_time: 0.0474   lr: 7.5391e-06  max_mem: 49046M
[03/05 17:31:43 d2.utils.events]:  eta: 1 day, 9:43:59  iter: 26959  total_loss: 9.788  loss_ce0: 0.7031  loss_ce1: 1.122  loss_ce2: 1.162  loss_ce3: 0.8533  loss_ce4: 1.014  loss_ce5: 2.271  loss_ce6: 2.521    time: 1.6680  last_time: 1.6844  data_time: 0.0474  last_data_time: 0.0455   lr: 7.5372e-06  max_mem: 49046M
[03/05 17:32:16 d2.utils.events]:  eta: 1 day, 9:43:11  iter: 26979  total_loss: 10.17  loss_ce0: 0.7145  loss_ce1: 1.263  loss_ce2: 1.149  loss_ce3: 0.8164  loss_ce4: 1.028  loss_ce5: 2.338  loss_ce6: 2.552    time: 1.6680  last_time: 1.6727  data_time: 0.0451  last_data_time: 0.0482   lr: 7.5353e-06  max_mem: 49046M
[03/05 17:32:49 d2.utils.events]:  eta: 1 day, 9:42:23  iter: 26999  total_loss: 9.769  loss_ce0: 0.7424  loss_ce1: 1.228  loss_ce2: 1.195  loss_ce3: 0.7875  loss_ce4: 0.9596  loss_ce5: 2.151  loss_ce6: 2.489    time: 1.6680  last_time: 1.6667  data_time: 0.0476  last_data_time: 0.0417   lr: 7.5335e-06  max_mem: 49046M
[03/05 17:33:23 d2.utils.events]:  eta: 1 day, 9:42:08  iter: 27019  total_loss: 9.461  loss_ce0: 0.6941  loss_ce1: 1.092  loss_ce2: 1.039  loss_ce3: 0.8819  loss_ce4: 1.009  loss_ce5: 2.121  loss_ce6: 2.549    time: 1.6680  last_time: 1.6668  data_time: 0.0464  last_data_time: 0.0493   lr: 7.5316e-06  max_mem: 49046M
[03/05 17:33:56 d2.utils.events]:  eta: 1 day, 9:41:31  iter: 27039  total_loss: 10.21  loss_ce0: 0.7416  loss_ce1: 1.161  loss_ce2: 1.299  loss_ce3: 0.7969  loss_ce4: 0.9478  loss_ce5: 2.438  loss_ce6: 2.374    time: 1.6680  last_time: 1.6663  data_time: 0.0482  last_data_time: 0.0478   lr: 7.5298e-06  max_mem: 49046M
[03/05 17:34:29 d2.utils.events]:  eta: 1 day, 9:41:10  iter: 27059  total_loss: 9.74  loss_ce0: 0.7367  loss_ce1: 1.179  loss_ce2: 1.206  loss_ce3: 0.7986  loss_ce4: 1.111  loss_ce5: 2.11  loss_ce6: 2.403    time: 1.6680  last_time: 1.6777  data_time: 0.0471  last_data_time: 0.0493   lr: 7.5279e-06  max_mem: 49046M
[03/05 17:35:02 d2.utils.events]:  eta: 1 day, 9:40:37  iter: 27079  total_loss: 9.627  loss_ce0: 0.687  loss_ce1: 1.175  loss_ce2: 1.18  loss_ce3: 0.856  loss_ce4: 1.043  loss_ce5: 2.173  loss_ce6: 2.604    time: 1.6680  last_time: 1.6101  data_time: 0.0466  last_data_time: 0.0462   lr: 7.5261e-06  max_mem: 49046M
[03/05 17:35:36 d2.utils.events]:  eta: 1 day, 9:39:58  iter: 27099  total_loss: 9.604  loss_ce0: 0.6827  loss_ce1: 1.126  loss_ce2: 1.363  loss_ce3: 0.8099  loss_ce4: 0.9933  loss_ce5: 2.245  loss_ce6: 2.395    time: 1.6679  last_time: 1.6693  data_time: 0.0464  last_data_time: 0.0484   lr: 7.5242e-06  max_mem: 49046M
[03/05 17:36:09 d2.utils.events]:  eta: 1 day, 9:39:30  iter: 27119  total_loss: 10.04  loss_ce0: 0.7064  loss_ce1: 1.114  loss_ce2: 1.241  loss_ce3: 0.8705  loss_ce4: 1.018  loss_ce5: 2.402  loss_ce6: 2.555    time: 1.6679  last_time: 1.6078  data_time: 0.0447  last_data_time: 0.0439   lr: 7.5223e-06  max_mem: 49046M
[03/05 17:36:42 d2.utils.events]:  eta: 1 day, 9:38:57  iter: 27139  total_loss: 9.645  loss_ce0: 0.6858  loss_ce1: 1.148  loss_ce2: 1.284  loss_ce3: 0.7676  loss_ce4: 1.002  loss_ce5: 2.667  loss_ce6: 2.181    time: 1.6679  last_time: 1.7575  data_time: 0.0455  last_data_time: 0.0433   lr: 7.5205e-06  max_mem: 49046M
[03/05 17:37:15 d2.utils.events]:  eta: 1 day, 9:38:16  iter: 27159  total_loss: 9.304  loss_ce0: 0.7002  loss_ce1: 1.188  loss_ce2: 1.218  loss_ce3: 0.7678  loss_ce4: 0.9667  loss_ce5: 2.085  loss_ce6: 2.478    time: 1.6678  last_time: 1.6045  data_time: 0.0443  last_data_time: 0.0423   lr: 7.5186e-06  max_mem: 49046M
[03/05 17:37:49 d2.utils.events]:  eta: 1 day, 9:38:00  iter: 27179  total_loss: 9.721  loss_ce0: 0.6856  loss_ce1: 1.189  loss_ce2: 1.172  loss_ce3: 0.8952  loss_ce4: 1.009  loss_ce5: 2.233  loss_ce6: 2.556    time: 1.6678  last_time: 1.5999  data_time: 0.0444  last_data_time: 0.0458   lr: 7.5168e-06  max_mem: 49046M
[03/05 17:38:22 d2.utils.events]:  eta: 1 day, 9:36:32  iter: 27199  total_loss: 9.65  loss_ce0: 0.7053  loss_ce1: 1.241  loss_ce2: 1.282  loss_ce3: 0.7937  loss_ce4: 1.037  loss_ce5: 2.141  loss_ce6: 2.408    time: 1.6678  last_time: 1.6824  data_time: 0.0447  last_data_time: 0.0460   lr: 7.5149e-06  max_mem: 49046M
[03/05 17:38:55 d2.utils.events]:  eta: 1 day, 9:35:44  iter: 27219  total_loss: 9.79  loss_ce0: 0.7133  loss_ce1: 1.197  loss_ce2: 1.168  loss_ce3: 0.7951  loss_ce4: 0.9632  loss_ce5: 2.278  loss_ce6: 2.448    time: 1.6678  last_time: 1.6086  data_time: 0.0460  last_data_time: 0.0433   lr: 7.513e-06  max_mem: 49046M
[03/05 17:39:28 d2.utils.events]:  eta: 1 day, 9:34:50  iter: 27239  total_loss: 9.529  loss_ce0: 0.6904  loss_ce1: 1.204  loss_ce2: 1.239  loss_ce3: 0.822  loss_ce4: 0.9836  loss_ce5: 2.207  loss_ce6: 2.444    time: 1.6678  last_time: 1.6017  data_time: 0.0457  last_data_time: 0.0473   lr: 7.5112e-06  max_mem: 49046M
[03/05 17:40:01 d2.utils.events]:  eta: 1 day, 9:34:52  iter: 27259  total_loss: 9.811  loss_ce0: 0.7232  loss_ce1: 1.112  loss_ce2: 1.182  loss_ce3: 0.9431  loss_ce4: 0.9403  loss_ce5: 2.046  loss_ce6: 2.559    time: 1.6678  last_time: 1.7033  data_time: 0.0478  last_data_time: 0.0500   lr: 7.5093e-06  max_mem: 49046M
[03/05 17:40:35 d2.utils.events]:  eta: 1 day, 9:34:22  iter: 27279  total_loss: 9.636  loss_ce0: 0.713  loss_ce1: 1.207  loss_ce2: 1.141  loss_ce3: 0.835  loss_ce4: 0.979  loss_ce5: 2.074  loss_ce6: 2.394    time: 1.6678  last_time: 1.7630  data_time: 0.0463  last_data_time: 0.0733   lr: 7.5075e-06  max_mem: 49046M
[03/05 17:41:08 d2.utils.events]:  eta: 1 day, 9:34:04  iter: 27299  total_loss: 9.906  loss_ce0: 0.6932  loss_ce1: 1.129  loss_ce2: 1.101  loss_ce3: 0.7929  loss_ce4: 0.9943  loss_ce5: 2.323  loss_ce6: 2.372    time: 1.6677  last_time: 1.6124  data_time: 0.0473  last_data_time: 0.0441   lr: 7.5056e-06  max_mem: 49046M
[03/05 17:41:41 d2.utils.events]:  eta: 1 day, 9:33:31  iter: 27319  total_loss: 10.05  loss_ce0: 0.7019  loss_ce1: 1.216  loss_ce2: 1.267  loss_ce3: 0.9752  loss_ce4: 0.9956  loss_ce5: 2.195  loss_ce6: 2.309    time: 1.6677  last_time: 1.6459  data_time: 0.0462  last_data_time: 0.0438   lr: 7.5038e-06  max_mem: 49046M
[03/05 17:42:14 d2.utils.events]:  eta: 1 day, 9:32:10  iter: 27339  total_loss: 9.803  loss_ce0: 0.6881  loss_ce1: 1.203  loss_ce2: 1.177  loss_ce3: 0.7915  loss_ce4: 0.9495  loss_ce5: 2.199  loss_ce6: 2.501    time: 1.6677  last_time: 1.6964  data_time: 0.0444  last_data_time: 0.0420   lr: 7.5019e-06  max_mem: 49046M
[03/05 17:42:47 d2.utils.events]:  eta: 1 day, 9:31:30  iter: 27359  total_loss: 9.765  loss_ce0: 0.7131  loss_ce1: 1.219  loss_ce2: 1.115  loss_ce3: 0.7902  loss_ce4: 0.9346  loss_ce5: 2.144  loss_ce6: 2.591    time: 1.6676  last_time: 1.6608  data_time: 0.0459  last_data_time: 0.0463   lr: 7.5e-06  max_mem: 49046M
[03/05 17:43:21 d2.utils.events]:  eta: 1 day, 9:30:51  iter: 27379  total_loss: 9.805  loss_ce0: 0.7342  loss_ce1: 1.164  loss_ce2: 1.144  loss_ce3: 0.7932  loss_ce4: 1.037  loss_ce5: 2.329  loss_ce6: 2.373    time: 1.6676  last_time: 1.6199  data_time: 0.0456  last_data_time: 0.0416   lr: 7.4982e-06  max_mem: 49046M
[03/05 17:43:54 d2.utils.events]:  eta: 1 day, 9:30:30  iter: 27399  total_loss: 9.429  loss_ce0: 0.6805  loss_ce1: 1.104  loss_ce2: 1.17  loss_ce3: 0.8363  loss_ce4: 0.9542  loss_ce5: 2.14  loss_ce6: 2.263    time: 1.6676  last_time: 1.6966  data_time: 0.0450  last_data_time: 0.0441   lr: 7.4963e-06  max_mem: 49046M
[03/05 17:44:28 d2.utils.events]:  eta: 1 day, 9:29:51  iter: 27419  total_loss: 9.825  loss_ce0: 0.7046  loss_ce1: 1.179  loss_ce2: 1.179  loss_ce3: 0.8307  loss_ce4: 0.9535  loss_ce5: 2.106  loss_ce6: 2.497    time: 1.6676  last_time: 1.7612  data_time: 0.0457  last_data_time: 0.0488   lr: 7.4945e-06  max_mem: 49046M
[03/05 17:45:01 d2.utils.events]:  eta: 1 day, 9:30:46  iter: 27439  total_loss: 9.85  loss_ce0: 0.7209  loss_ce1: 1.115  loss_ce2: 1.167  loss_ce3: 0.857  loss_ce4: 0.9876  loss_ce5: 2.317  loss_ce6: 2.384    time: 1.6677  last_time: 1.6514  data_time: 0.0492  last_data_time: 0.0446   lr: 7.4926e-06  max_mem: 49046M
[03/05 17:45:34 d2.utils.events]:  eta: 1 day, 9:30:12  iter: 27459  total_loss: 9.791  loss_ce0: 0.7005  loss_ce1: 1.162  loss_ce2: 1.1  loss_ce3: 0.9085  loss_ce4: 1.005  loss_ce5: 2.285  loss_ce6: 2.424    time: 1.6676  last_time: 1.6786  data_time: 0.0439  last_data_time: 0.0444   lr: 7.4907e-06  max_mem: 49046M
[03/05 17:46:08 d2.utils.events]:  eta: 1 day, 9:28:17  iter: 27479  total_loss: 9.578  loss_ce0: 0.7201  loss_ce1: 1.107  loss_ce2: 1.168  loss_ce3: 0.8115  loss_ce4: 0.9849  loss_ce5: 2.393  loss_ce6: 2.233    time: 1.6676  last_time: 1.6240  data_time: 0.0455  last_data_time: 0.0376   lr: 7.4889e-06  max_mem: 49046M
[03/05 17:46:41 d2.utils.events]:  eta: 1 day, 9:27:38  iter: 27499  total_loss: 9.82  loss_ce0: 0.732  loss_ce1: 1.152  loss_ce2: 1.178  loss_ce3: 0.832  loss_ce4: 1.01  loss_ce5: 2.062  loss_ce6: 2.672    time: 1.6676  last_time: 1.7032  data_time: 0.0467  last_data_time: 0.0486   lr: 7.487e-06  max_mem: 49046M
[03/05 17:47:14 d2.utils.events]:  eta: 1 day, 9:26:51  iter: 27519  total_loss: 9.902  loss_ce0: 0.6931  loss_ce1: 1.17  loss_ce2: 1.131  loss_ce3: 0.8169  loss_ce4: 1.033  loss_ce5: 2.418  loss_ce6: 2.41    time: 1.6676  last_time: 1.6174  data_time: 0.0448  last_data_time: 0.0479   lr: 7.4852e-06  max_mem: 49046M
[03/05 17:47:48 d2.utils.events]:  eta: 1 day, 9:26:09  iter: 27539  total_loss: 9.848  loss_ce0: 0.7215  loss_ce1: 1.198  loss_ce2: 1.111  loss_ce3: 0.8032  loss_ce4: 1.089  loss_ce5: 2.249  loss_ce6: 2.494    time: 1.6676  last_time: 1.7284  data_time: 0.0446  last_data_time: 0.0439   lr: 7.4833e-06  max_mem: 49046M
[03/05 17:48:21 d2.utils.events]:  eta: 1 day, 9:24:56  iter: 27559  total_loss: 9.886  loss_ce0: 0.7262  loss_ce1: 1.214  loss_ce2: 1.118  loss_ce3: 0.7809  loss_ce4: 0.9491  loss_ce5: 2.076  loss_ce6: 2.605    time: 1.6676  last_time: 1.6881  data_time: 0.0451  last_data_time: 0.0473   lr: 7.4815e-06  max_mem: 49046M
[03/05 17:48:54 d2.utils.events]:  eta: 1 day, 9:23:24  iter: 27579  total_loss: 9.613  loss_ce0: 0.7004  loss_ce1: 1.127  loss_ce2: 1.179  loss_ce3: 0.8011  loss_ce4: 0.9861  loss_ce5: 2.263  loss_ce6: 2.315    time: 1.6675  last_time: 1.6948  data_time: 0.0441  last_data_time: 0.0398   lr: 7.4796e-06  max_mem: 49046M
[03/05 17:49:27 d2.utils.events]:  eta: 1 day, 9:23:22  iter: 27599  total_loss: 9.512  loss_ce0: 0.7326  loss_ce1: 1.145  loss_ce2: 1.11  loss_ce3: 0.7531  loss_ce4: 0.9751  loss_ce5: 2.161  loss_ce6: 2.572    time: 1.6675  last_time: 1.6100  data_time: 0.0457  last_data_time: 0.0416   lr: 7.4777e-06  max_mem: 49046M
[03/05 17:50:01 d2.utils.events]:  eta: 1 day, 9:23:36  iter: 27619  total_loss: 9.964  loss_ce0: 0.7251  loss_ce1: 1.157  loss_ce2: 1.254  loss_ce3: 0.8295  loss_ce4: 1.003  loss_ce5: 2.147  loss_ce6: 2.531    time: 1.6675  last_time: 1.7819  data_time: 0.0464  last_data_time: 0.0466   lr: 7.4759e-06  max_mem: 49046M
[03/05 17:50:34 d2.utils.events]:  eta: 1 day, 9:23:03  iter: 27639  total_loss: 9.508  loss_ce0: 0.6914  loss_ce1: 1.11  loss_ce2: 1.099  loss_ce3: 0.8811  loss_ce4: 1.004  loss_ce5: 2.214  loss_ce6: 2.193    time: 1.6675  last_time: 1.6394  data_time: 0.0453  last_data_time: 0.0436   lr: 7.474e-06  max_mem: 49046M
[03/05 17:51:08 d2.utils.events]:  eta: 1 day, 9:22:11  iter: 27659  total_loss: 9.979  loss_ce0: 0.706  loss_ce1: 1.182  loss_ce2: 1.261  loss_ce3: 0.7834  loss_ce4: 0.9817  loss_ce5: 2.308  loss_ce6: 2.451    time: 1.6676  last_time: 1.6707  data_time: 0.0475  last_data_time: 0.0462   lr: 7.4722e-06  max_mem: 49046M
[03/05 17:51:41 d2.utils.events]:  eta: 1 day, 9:22:05  iter: 27679  total_loss: 9.757  loss_ce0: 0.7207  loss_ce1: 1.158  loss_ce2: 1.136  loss_ce3: 0.7699  loss_ce4: 1.022  loss_ce5: 2.234  loss_ce6: 2.469    time: 1.6676  last_time: 1.7258  data_time: 0.0449  last_data_time: 0.0457   lr: 7.4703e-06  max_mem: 49046M
[03/05 17:52:14 d2.utils.events]:  eta: 1 day, 9:21:24  iter: 27699  total_loss: 9.884  loss_ce0: 0.6891  loss_ce1: 1.179  loss_ce2: 1.209  loss_ce3: 0.9435  loss_ce4: 0.9807  loss_ce5: 2.061  loss_ce6: 2.565    time: 1.6676  last_time: 1.7091  data_time: 0.0451  last_data_time: 0.0468   lr: 7.4684e-06  max_mem: 49046M
[03/05 17:52:48 d2.utils.events]:  eta: 1 day, 9:21:03  iter: 27719  total_loss: 9.642  loss_ce0: 0.7006  loss_ce1: 1.141  loss_ce2: 1.221  loss_ce3: 0.7643  loss_ce4: 0.9823  loss_ce5: 2.179  loss_ce6: 2.492    time: 1.6676  last_time: 1.7046  data_time: 0.0466  last_data_time: 0.0419   lr: 7.4666e-06  max_mem: 49046M
[03/05 17:53:21 d2.utils.events]:  eta: 1 day, 9:20:20  iter: 27739  total_loss: 10.24  loss_ce0: 0.6926  loss_ce1: 1.249  loss_ce2: 1.077  loss_ce3: 0.8124  loss_ce4: 0.9796  loss_ce5: 2.152  loss_ce6: 2.994    time: 1.6676  last_time: 1.6908  data_time: 0.0451  last_data_time: 0.0471   lr: 7.4647e-06  max_mem: 49046M
[03/05 17:53:55 d2.utils.events]:  eta: 1 day, 9:19:56  iter: 27759  total_loss: 9.897  loss_ce0: 0.7341  loss_ce1: 1.144  loss_ce2: 1.299  loss_ce3: 0.8148  loss_ce4: 0.9074  loss_ce5: 2.331  loss_ce6: 2.416    time: 1.6676  last_time: 1.6720  data_time: 0.0467  last_data_time: 0.0448   lr: 7.4629e-06  max_mem: 49046M
[03/05 17:54:29 d2.utils.events]:  eta: 1 day, 9:19:33  iter: 27779  total_loss: 9.624  loss_ce0: 0.7063  loss_ce1: 1.19  loss_ce2: 1.124  loss_ce3: 0.7816  loss_ce4: 0.9843  loss_ce5: 2.114  loss_ce6: 2.597    time: 1.6676  last_time: 1.7174  data_time: 0.0474  last_data_time: 0.0514   lr: 7.461e-06  max_mem: 49046M
[03/05 17:55:02 d2.utils.events]:  eta: 1 day, 9:19:40  iter: 27799  total_loss: 9.352  loss_ce0: 0.6872  loss_ce1: 1.166  loss_ce2: 1.26  loss_ce3: 0.7733  loss_ce4: 0.9829  loss_ce5: 2.127  loss_ce6: 2.235    time: 1.6677  last_time: 1.6367  data_time: 0.0463  last_data_time: 0.0465   lr: 7.4591e-06  max_mem: 49046M
[03/05 17:55:35 d2.utils.events]:  eta: 1 day, 9:19:27  iter: 27819  total_loss: 9.371  loss_ce0: 0.7183  loss_ce1: 1.082  loss_ce2: 1.201  loss_ce3: 0.7892  loss_ce4: 0.9658  loss_ce5: 2.284  loss_ce6: 2.322    time: 1.6676  last_time: 1.6162  data_time: 0.0443  last_data_time: 0.0472   lr: 7.4573e-06  max_mem: 49046M
[03/05 17:56:08 d2.utils.events]:  eta: 1 day, 9:18:54  iter: 27839  total_loss: 9.426  loss_ce0: 0.6873  loss_ce1: 1.182  loss_ce2: 1.054  loss_ce3: 0.7934  loss_ce4: 0.9444  loss_ce5: 2.103  loss_ce6: 2.558    time: 1.6676  last_time: 1.7241  data_time: 0.0442  last_data_time: 0.0492   lr: 7.4554e-06  max_mem: 49046M
[03/05 17:56:41 d2.utils.events]:  eta: 1 day, 9:17:18  iter: 27859  total_loss: 9.808  loss_ce0: 0.7094  loss_ce1: 1.162  loss_ce2: 1.161  loss_ce3: 0.803  loss_ce4: 0.9827  loss_ce5: 2.246  loss_ce6: 2.354    time: 1.6675  last_time: 1.7204  data_time: 0.0466  last_data_time: 0.0419   lr: 7.4536e-06  max_mem: 49046M
[03/05 17:57:15 d2.utils.events]:  eta: 1 day, 9:16:44  iter: 27879  total_loss: 9.898  loss_ce0: 0.711  loss_ce1: 1.194  loss_ce2: 1.208  loss_ce3: 0.7798  loss_ce4: 0.9622  loss_ce5: 2.282  loss_ce6: 2.715    time: 1.6676  last_time: 1.8631  data_time: 0.0478  last_data_time: 0.0463   lr: 7.4517e-06  max_mem: 49046M
[03/05 17:57:48 d2.utils.events]:  eta: 1 day, 9:16:27  iter: 27899  total_loss: 9.888  loss_ce0: 0.7089  loss_ce1: 1.138  loss_ce2: 1.124  loss_ce3: 0.8392  loss_ce4: 0.9992  loss_ce5: 2.012  loss_ce6: 2.451    time: 1.6676  last_time: 1.6940  data_time: 0.0459  last_data_time: 0.0467   lr: 7.4498e-06  max_mem: 49046M
[03/05 17:58:21 d2.utils.events]:  eta: 1 day, 9:15:39  iter: 27919  total_loss: 9.747  loss_ce0: 0.7036  loss_ce1: 1.207  loss_ce2: 1.054  loss_ce3: 0.8334  loss_ce4: 0.9827  loss_ce5: 2.5  loss_ce6: 2.39    time: 1.6675  last_time: 1.6836  data_time: 0.0462  last_data_time: 0.0486   lr: 7.448e-06  max_mem: 49046M
[03/05 17:58:54 d2.utils.events]:  eta: 1 day, 9:14:41  iter: 27939  total_loss: 9.726  loss_ce0: 0.7138  loss_ce1: 1.199  loss_ce2: 1.159  loss_ce3: 0.8353  loss_ce4: 0.9501  loss_ce5: 2.161  loss_ce6: 2.345    time: 1.6675  last_time: 1.6284  data_time: 0.0457  last_data_time: 0.0452   lr: 7.4461e-06  max_mem: 49046M
[03/05 17:59:28 d2.utils.events]:  eta: 1 day, 9:14:08  iter: 27959  total_loss: 9.416  loss_ce0: 0.7275  loss_ce1: 1.182  loss_ce2: 1.021  loss_ce3: 0.817  loss_ce4: 0.9497  loss_ce5: 2.219  loss_ce6: 2.458    time: 1.6675  last_time: 1.7799  data_time: 0.0454  last_data_time: 0.0461   lr: 7.4443e-06  max_mem: 49046M
[03/05 18:00:01 d2.utils.events]:  eta: 1 day, 9:14:00  iter: 27979  total_loss: 10.02  loss_ce0: 0.701  loss_ce1: 1.139  loss_ce2: 1.217  loss_ce3: 0.7817  loss_ce4: 1.033  loss_ce5: 2.378  loss_ce6: 2.621    time: 1.6675  last_time: 1.6949  data_time: 0.0502  last_data_time: 0.0629   lr: 7.4424e-06  max_mem: 49046M
[03/05 18:00:35 d2.utils.events]:  eta: 1 day, 9:14:08  iter: 27999  total_loss: 9.402  loss_ce0: 0.6984  loss_ce1: 1.21  loss_ce2: 1.03  loss_ce3: 0.7879  loss_ce4: 0.933  loss_ce5: 2.223  loss_ce6: 2.222    time: 1.6676  last_time: 1.7231  data_time: 0.0495  last_data_time: 0.0478   lr: 7.4405e-06  max_mem: 49046M
[03/05 18:01:08 d2.utils.events]:  eta: 1 day, 9:12:45  iter: 28019  total_loss: 9.826  loss_ce0: 0.7173  loss_ce1: 1.206  loss_ce2: 1.13  loss_ce3: 0.8051  loss_ce4: 0.9129  loss_ce5: 2.334  loss_ce6: 2.423    time: 1.6675  last_time: 1.6749  data_time: 0.0438  last_data_time: 0.0503   lr: 7.4387e-06  max_mem: 49046M
[03/05 18:01:41 d2.utils.events]:  eta: 1 day, 9:12:12  iter: 28039  total_loss: 10.01  loss_ce0: 0.6789  loss_ce1: 1.124  loss_ce2: 1.077  loss_ce3: 0.7857  loss_ce4: 1.088  loss_ce5: 2.505  loss_ce6: 2.445    time: 1.6675  last_time: 1.6935  data_time: 0.0466  last_data_time: 0.0465   lr: 7.4368e-06  max_mem: 49046M
[03/05 18:02:15 d2.utils.events]:  eta: 1 day, 9:11:41  iter: 28059  total_loss: 10.01  loss_ce0: 0.6924  loss_ce1: 1.147  loss_ce2: 1.228  loss_ce3: 0.7587  loss_ce4: 1.003  loss_ce5: 2.177  loss_ce6: 2.678    time: 1.6675  last_time: 1.6693  data_time: 0.0465  last_data_time: 0.0442   lr: 7.435e-06  max_mem: 49046M
[03/05 18:02:48 d2.utils.events]:  eta: 1 day, 9:12:20  iter: 28079  total_loss: 9.701  loss_ce0: 0.6956  loss_ce1: 1.164  loss_ce2: 1.084  loss_ce3: 0.7791  loss_ce4: 0.9918  loss_ce5: 2.267  loss_ce6: 2.591    time: 1.6675  last_time: 1.6232  data_time: 0.0494  last_data_time: 0.0580   lr: 7.4331e-06  max_mem: 49046M
[03/05 18:03:21 d2.utils.events]:  eta: 1 day, 9:10:51  iter: 28099  total_loss: 10.23  loss_ce0: 0.6919  loss_ce1: 1.159  loss_ce2: 1.264  loss_ce3: 0.7758  loss_ce4: 0.9337  loss_ce5: 2.363  loss_ce6: 2.498    time: 1.6675  last_time: 1.6167  data_time: 0.0450  last_data_time: 0.0405   lr: 7.4312e-06  max_mem: 49046M
[03/05 18:03:54 d2.utils.events]:  eta: 1 day, 9:10:17  iter: 28119  total_loss: 10.17  loss_ce0: 0.6991  loss_ce1: 1.163  loss_ce2: 1.165  loss_ce3: 0.8214  loss_ce4: 1.027  loss_ce5: 2.264  loss_ce6: 2.48    time: 1.6674  last_time: 1.7041  data_time: 0.0440  last_data_time: 0.0481   lr: 7.4294e-06  max_mem: 49046M
[03/05 18:04:28 d2.utils.events]:  eta: 1 day, 9:09:56  iter: 28139  total_loss: 9.709  loss_ce0: 0.6906  loss_ce1: 1.181  loss_ce2: 1.419  loss_ce3: 0.7599  loss_ce4: 0.951  loss_ce5: 2.355  loss_ce6: 2.199    time: 1.6674  last_time: 1.6905  data_time: 0.0455  last_data_time: 0.0450   lr: 7.4275e-06  max_mem: 49046M
[03/05 18:05:01 d2.utils.events]:  eta: 1 day, 9:10:07  iter: 28159  total_loss: 9.78  loss_ce0: 0.735  loss_ce1: 1.154  loss_ce2: 1.093  loss_ce3: 0.838  loss_ce4: 0.9372  loss_ce5: 2.393  loss_ce6: 2.57    time: 1.6674  last_time: 1.6051  data_time: 0.0488  last_data_time: 0.0441   lr: 7.4257e-06  max_mem: 49046M
[03/05 18:05:34 d2.utils.events]:  eta: 1 day, 9:09:28  iter: 28179  total_loss: 9.74  loss_ce0: 0.6993  loss_ce1: 1.135  loss_ce2: 1.167  loss_ce3: 0.7651  loss_ce4: 0.9888  loss_ce5: 2.209  loss_ce6: 2.384    time: 1.6674  last_time: 1.6152  data_time: 0.0457  last_data_time: 0.0430   lr: 7.4238e-06  max_mem: 49046M
[03/05 18:06:08 d2.utils.events]:  eta: 1 day, 9:09:31  iter: 28199  total_loss: 10.1  loss_ce0: 0.732  loss_ce1: 1.214  loss_ce2: 1.271  loss_ce3: 0.8345  loss_ce4: 1.024  loss_ce5: 2.238  loss_ce6: 2.529    time: 1.6674  last_time: 1.7370  data_time: 0.0468  last_data_time: 0.0473   lr: 7.4219e-06  max_mem: 49046M
[03/05 18:06:41 d2.utils.events]:  eta: 1 day, 9:08:57  iter: 28219  total_loss: 9.759  loss_ce0: 0.6988  loss_ce1: 1.086  loss_ce2: 1.049  loss_ce3: 0.8012  loss_ce4: 1.006  loss_ce5: 2.364  loss_ce6: 2.496    time: 1.6674  last_time: 1.6143  data_time: 0.0469  last_data_time: 0.0408   lr: 7.4201e-06  max_mem: 49046M
[03/05 18:07:14 d2.utils.events]:  eta: 1 day, 9:09:16  iter: 28239  total_loss: 9.614  loss_ce0: 0.7068  loss_ce1: 1.189  loss_ce2: 1.139  loss_ce3: 0.7992  loss_ce4: 1.001  loss_ce5: 2.106  loss_ce6: 2.474    time: 1.6674  last_time: 1.6811  data_time: 0.0445  last_data_time: 0.0466   lr: 7.4182e-06  max_mem: 49046M
[03/05 18:07:47 d2.utils.events]:  eta: 1 day, 9:07:43  iter: 28259  total_loss: 9.938  loss_ce0: 0.7095  loss_ce1: 1.257  loss_ce2: 1.092  loss_ce3: 0.8388  loss_ce4: 0.9657  loss_ce5: 2.41  loss_ce6: 2.294    time: 1.6674  last_time: 1.6802  data_time: 0.0446  last_data_time: 0.0486   lr: 7.4164e-06  max_mem: 49046M
[03/05 18:08:21 d2.utils.events]:  eta: 1 day, 9:06:50  iter: 28279  total_loss: 9.858  loss_ce0: 0.7101  loss_ce1: 1.198  loss_ce2: 1.004  loss_ce3: 0.7839  loss_ce4: 0.9499  loss_ce5: 2.21  loss_ce6: 2.455    time: 1.6674  last_time: 1.6047  data_time: 0.0469  last_data_time: 0.0460   lr: 7.4145e-06  max_mem: 49046M
[03/05 18:08:54 d2.utils.events]:  eta: 1 day, 9:06:09  iter: 28299  total_loss: 9.691  loss_ce0: 0.6871  loss_ce1: 1.13  loss_ce2: 1.174  loss_ce3: 0.7564  loss_ce4: 0.9402  loss_ce5: 2.348  loss_ce6: 2.284    time: 1.6673  last_time: 1.6134  data_time: 0.0443  last_data_time: 0.0477   lr: 7.4126e-06  max_mem: 49046M
[03/05 18:09:27 d2.utils.events]:  eta: 1 day, 9:04:55  iter: 28319  total_loss: 9.535  loss_ce0: 0.7298  loss_ce1: 1.188  loss_ce2: 1.04  loss_ce3: 0.7535  loss_ce4: 0.949  loss_ce5: 2.173  loss_ce6: 2.46    time: 1.6673  last_time: 1.6606  data_time: 0.0441  last_data_time: 0.0427   lr: 7.4108e-06  max_mem: 49046M
[03/05 18:10:00 d2.utils.events]:  eta: 1 day, 9:04:14  iter: 28339  total_loss: 9.723  loss_ce0: 0.7089  loss_ce1: 1.194  loss_ce2: 1.11  loss_ce3: 0.7889  loss_ce4: 0.9865  loss_ce5: 2.159  loss_ce6: 2.515    time: 1.6672  last_time: 1.6515  data_time: 0.0450  last_data_time: 0.0431   lr: 7.4089e-06  max_mem: 49046M
[03/05 18:10:33 d2.utils.events]:  eta: 1 day, 9:04:29  iter: 28359  total_loss: 9.683  loss_ce0: 0.6839  loss_ce1: 1.246  loss_ce2: 1.194  loss_ce3: 0.8697  loss_ce4: 0.9905  loss_ce5: 2.294  loss_ce6: 2.378    time: 1.6672  last_time: 1.6466  data_time: 0.0467  last_data_time: 0.0378   lr: 7.4071e-06  max_mem: 49046M
[03/05 18:11:07 d2.utils.events]:  eta: 1 day, 9:03:50  iter: 28379  total_loss: 9.413  loss_ce0: 0.7564  loss_ce1: 1.226  loss_ce2: 1.144  loss_ce3: 0.7974  loss_ce4: 0.9535  loss_ce5: 2.276  loss_ce6: 2.397    time: 1.6673  last_time: 1.7103  data_time: 0.0463  last_data_time: 0.0383   lr: 7.4052e-06  max_mem: 49046M
[03/05 18:11:40 d2.utils.events]:  eta: 1 day, 9:03:09  iter: 28399  total_loss: 9.061  loss_ce0: 0.695  loss_ce1: 1.215  loss_ce2: 0.9848  loss_ce3: 0.772  loss_ce4: 0.9615  loss_ce5: 2.301  loss_ce6: 2.263    time: 1.6673  last_time: 1.7239  data_time: 0.0467  last_data_time: 0.0581   lr: 7.4033e-06  max_mem: 49046M
[03/05 18:12:13 d2.utils.events]:  eta: 1 day, 9:02:49  iter: 28419  total_loss: 9.652  loss_ce0: 0.6886  loss_ce1: 1.133  loss_ce2: 1.209  loss_ce3: 0.7702  loss_ce4: 0.9566  loss_ce5: 2.241  loss_ce6: 2.47    time: 1.6672  last_time: 1.7295  data_time: 0.0449  last_data_time: 0.0456   lr: 7.4015e-06  max_mem: 49046M
[03/05 18:12:47 d2.utils.events]:  eta: 1 day, 9:02:24  iter: 28439  total_loss: 9.666  loss_ce0: 0.6921  loss_ce1: 1.205  loss_ce2: 1.021  loss_ce3: 0.7739  loss_ce4: 0.9696  loss_ce5: 2.175  loss_ce6: 2.654    time: 1.6673  last_time: 1.6874  data_time: 0.0460  last_data_time: 0.0489   lr: 7.3996e-06  max_mem: 49046M
[03/05 18:13:20 d2.utils.events]:  eta: 1 day, 9:01:47  iter: 28459  total_loss: 9.528  loss_ce0: 0.6943  loss_ce1: 1.165  loss_ce2: 1.054  loss_ce3: 0.7588  loss_ce4: 0.9721  loss_ce5: 2.071  loss_ce6: 2.636    time: 1.6673  last_time: 1.6850  data_time: 0.0466  last_data_time: 0.0463   lr: 7.3977e-06  max_mem: 49046M
[03/05 18:13:53 d2.utils.events]:  eta: 1 day, 9:00:29  iter: 28479  total_loss: 9.433  loss_ce0: 0.6779  loss_ce1: 1.174  loss_ce2: 1.23  loss_ce3: 0.7978  loss_ce4: 0.9582  loss_ce5: 2.119  loss_ce6: 2.284    time: 1.6672  last_time: 1.6982  data_time: 0.0453  last_data_time: 0.0463   lr: 7.3959e-06  max_mem: 49046M
[03/05 18:14:26 d2.utils.events]:  eta: 1 day, 8:59:42  iter: 28499  total_loss: 9.335  loss_ce0: 0.7092  loss_ce1: 1.281  loss_ce2: 1.091  loss_ce3: 0.7696  loss_ce4: 0.9581  loss_ce5: 1.953  loss_ce6: 2.171    time: 1.6672  last_time: 1.6289  data_time: 0.0449  last_data_time: 0.0460   lr: 7.394e-06  max_mem: 49046M
[03/05 18:14:59 d2.utils.events]:  eta: 1 day, 8:58:54  iter: 28519  total_loss: 9.872  loss_ce0: 0.7109  loss_ce1: 1.193  loss_ce2: 1.237  loss_ce3: 0.808  loss_ce4: 1.014  loss_ce5: 2.293  loss_ce6: 2.442    time: 1.6671  last_time: 1.6129  data_time: 0.0447  last_data_time: 0.0441   lr: 7.3922e-06  max_mem: 49046M
[03/05 18:15:32 d2.utils.events]:  eta: 1 day, 8:58:21  iter: 28539  total_loss: 9.944  loss_ce0: 0.7135  loss_ce1: 1.209  loss_ce2: 1.088  loss_ce3: 0.7975  loss_ce4: 0.9918  loss_ce5: 2.362  loss_ce6: 2.261    time: 1.6671  last_time: 1.5930  data_time: 0.0436  last_data_time: 0.0355   lr: 7.3903e-06  max_mem: 49046M
[03/05 18:16:05 d2.utils.events]:  eta: 1 day, 8:57:53  iter: 28559  total_loss: 9.675  loss_ce0: 0.6926  loss_ce1: 1.223  loss_ce2: 1.247  loss_ce3: 0.944  loss_ce4: 1.022  loss_ce5: 2.147  loss_ce6: 2.145    time: 1.6671  last_time: 1.6247  data_time: 0.0452  last_data_time: 0.0373   lr: 7.3884e-06  max_mem: 49046M
[03/05 18:16:39 d2.utils.events]:  eta: 1 day, 8:57:27  iter: 28579  total_loss: 9.628  loss_ce0: 0.7226  loss_ce1: 1.144  loss_ce2: 1.198  loss_ce3: 0.7223  loss_ce4: 0.9513  loss_ce5: 2.256  loss_ce6: 2.488    time: 1.6670  last_time: 1.6338  data_time: 0.0472  last_data_time: 0.0394   lr: 7.3866e-06  max_mem: 49046M
[03/05 18:17:12 d2.utils.events]:  eta: 1 day, 8:56:52  iter: 28599  total_loss: 9.53  loss_ce0: 0.7039  loss_ce1: 1.158  loss_ce2: 1.106  loss_ce3: 0.8092  loss_ce4: 1.03  loss_ce5: 2.267  loss_ce6: 2.176    time: 1.6670  last_time: 1.8643  data_time: 0.0453  last_data_time: 0.0477   lr: 7.3847e-06  max_mem: 49046M
[03/05 18:17:46 d2.utils.events]:  eta: 1 day, 8:56:13  iter: 28619  total_loss: 9.759  loss_ce0: 0.6877  loss_ce1: 1.167  loss_ce2: 1.152  loss_ce3: 0.9472  loss_ce4: 1.052  loss_ce5: 2.322  loss_ce6: 2.439    time: 1.6671  last_time: 1.7093  data_time: 0.0462  last_data_time: 0.0473   lr: 7.3829e-06  max_mem: 49046M
[03/05 18:18:19 d2.utils.events]:  eta: 1 day, 8:55:55  iter: 28639  total_loss: 9.923  loss_ce0: 0.7091  loss_ce1: 1.175  loss_ce2: 1.086  loss_ce3: 0.7767  loss_ce4: 0.978  loss_ce5: 2.297  loss_ce6: 2.563    time: 1.6671  last_time: 1.7248  data_time: 0.0489  last_data_time: 0.0714   lr: 7.381e-06  max_mem: 49046M
[03/05 18:18:52 d2.utils.events]:  eta: 1 day, 8:55:14  iter: 28659  total_loss: 10.13  loss_ce0: 0.712  loss_ce1: 1.14  loss_ce2: 1.218  loss_ce3: 1.028  loss_ce4: 0.9982  loss_ce5: 2.202  loss_ce6: 2.593    time: 1.6671  last_time: 1.6851  data_time: 0.0467  last_data_time: 0.0452   lr: 7.3791e-06  max_mem: 49046M
[03/05 18:19:25 d2.utils.events]:  eta: 1 day, 8:53:59  iter: 28679  total_loss: 9.676  loss_ce0: 0.7203  loss_ce1: 1.13  loss_ce2: 1.004  loss_ce3: 0.865  loss_ce4: 0.968  loss_ce5: 2.355  loss_ce6: 2.519    time: 1.6670  last_time: 1.6008  data_time: 0.0451  last_data_time: 0.0420   lr: 7.3773e-06  max_mem: 49046M
[03/05 18:19:58 d2.utils.events]:  eta: 1 day, 8:53:37  iter: 28699  total_loss: 9.978  loss_ce0: 0.7118  loss_ce1: 1.183  loss_ce2: 1.247  loss_ce3: 0.83  loss_ce4: 0.9463  loss_ce5: 2.248  loss_ce6: 2.32    time: 1.6670  last_time: 1.7541  data_time: 0.0479  last_data_time: 0.0588   lr: 7.3754e-06  max_mem: 49046M
[03/05 18:20:32 d2.utils.events]:  eta: 1 day, 8:52:50  iter: 28719  total_loss: 9.349  loss_ce0: 0.7054  loss_ce1: 1.13  loss_ce2: 1.135  loss_ce3: 0.8164  loss_ce4: 0.9975  loss_ce5: 2.277  loss_ce6: 2.509    time: 1.6670  last_time: 1.6026  data_time: 0.0466  last_data_time: 0.0419   lr: 7.3735e-06  max_mem: 49046M
[03/05 18:21:05 d2.utils.events]:  eta: 1 day, 8:51:12  iter: 28739  total_loss: 9.749  loss_ce0: 0.6923  loss_ce1: 1.157  loss_ce2: 1.11  loss_ce3: 0.881  loss_ce4: 0.9679  loss_ce5: 2.264  loss_ce6: 2.689    time: 1.6670  last_time: 1.7213  data_time: 0.0443  last_data_time: 0.0483   lr: 7.3717e-06  max_mem: 49046M
[03/05 18:21:38 d2.utils.events]:  eta: 1 day, 8:49:54  iter: 28759  total_loss: 9.659  loss_ce0: 0.7368  loss_ce1: 1.263  loss_ce2: 1.009  loss_ce3: 0.8038  loss_ce4: 0.9404  loss_ce5: 2.127  loss_ce6: 2.425    time: 1.6669  last_time: 1.6028  data_time: 0.0464  last_data_time: 0.0416   lr: 7.3698e-06  max_mem: 49046M
[03/05 18:22:12 d2.utils.events]:  eta: 1 day, 8:49:37  iter: 28779  total_loss: 9.504  loss_ce0: 0.703  loss_ce1: 1.172  loss_ce2: 1.105  loss_ce3: 0.7557  loss_ce4: 0.9685  loss_ce5: 2.141  loss_ce6: 2.491    time: 1.6670  last_time: 1.7297  data_time: 0.0467  last_data_time: 0.0416   lr: 7.368e-06  max_mem: 49046M
[03/05 18:22:45 d2.utils.events]:  eta: 1 day, 8:48:32  iter: 28799  total_loss: 9.915  loss_ce0: 0.6797  loss_ce1: 1.131  loss_ce2: 1.239  loss_ce3: 0.8303  loss_ce4: 0.9228  loss_ce5: 2.368  loss_ce6: 2.371    time: 1.6670  last_time: 1.6599  data_time: 0.0463  last_data_time: 0.0423   lr: 7.3661e-06  max_mem: 49046M
[03/05 18:23:18 d2.utils.events]:  eta: 1 day, 8:48:30  iter: 28819  total_loss: 9.75  loss_ce0: 0.7026  loss_ce1: 1.237  loss_ce2: 1.306  loss_ce3: 0.8185  loss_ce4: 0.9916  loss_ce5: 1.975  loss_ce6: 2.216    time: 1.6670  last_time: 1.6085  data_time: 0.0474  last_data_time: 0.0473   lr: 7.3642e-06  max_mem: 49046M
[03/05 18:23:51 d2.utils.events]:  eta: 1 day, 8:48:09  iter: 28839  total_loss: 9.839  loss_ce0: 0.6989  loss_ce1: 1.19  loss_ce2: 1.135  loss_ce3: 0.7635  loss_ce4: 0.9459  loss_ce5: 2.352  loss_ce6: 2.642    time: 1.6669  last_time: 1.6953  data_time: 0.0449  last_data_time: 0.0440   lr: 7.3624e-06  max_mem: 49046M
[03/05 18:24:25 d2.utils.events]:  eta: 1 day, 8:48:53  iter: 28859  total_loss: 9.745  loss_ce0: 0.7025  loss_ce1: 1.192  loss_ce2: 1.154  loss_ce3: 0.8064  loss_ce4: 0.9893  loss_ce5: 2.032  loss_ce6: 2.451    time: 1.6669  last_time: 1.6021  data_time: 0.0471  last_data_time: 0.0442   lr: 7.3605e-06  max_mem: 49046M
[03/05 18:24:58 d2.utils.events]:  eta: 1 day, 8:48:38  iter: 28879  total_loss: 9.872  loss_ce0: 0.6924  loss_ce1: 1.227  loss_ce2: 1.22  loss_ce3: 0.7928  loss_ce4: 0.9905  loss_ce5: 2.329  loss_ce6: 2.345    time: 1.6670  last_time: 1.6618  data_time: 0.0476  last_data_time: 0.0437   lr: 7.3586e-06  max_mem: 49046M
[03/05 18:25:32 d2.utils.events]:  eta: 1 day, 8:48:05  iter: 28899  total_loss: 9.306  loss_ce0: 0.6883  loss_ce1: 1.172  loss_ce2: 1.103  loss_ce3: 0.8005  loss_ce4: 0.9987  loss_ce5: 1.949  loss_ce6: 2.502    time: 1.6670  last_time: 1.6067  data_time: 0.0470  last_data_time: 0.0462   lr: 7.3568e-06  max_mem: 49046M
[03/05 18:26:06 d2.utils.events]:  eta: 1 day, 8:48:04  iter: 28919  total_loss: 9.644  loss_ce0: 0.6935  loss_ce1: 1.147  loss_ce2: 1.16  loss_ce3: 0.7582  loss_ce4: 1.009  loss_ce5: 2.143  loss_ce6: 2.473    time: 1.6670  last_time: 1.7416  data_time: 0.0476  last_data_time: 0.0498   lr: 7.3549e-06  max_mem: 49046M
[03/05 18:26:40 d2.utils.events]:  eta: 1 day, 8:47:56  iter: 28939  total_loss: 10.4  loss_ce0: 0.7277  loss_ce1: 1.195  loss_ce2: 1.221  loss_ce3: 0.7377  loss_ce4: 0.9625  loss_ce5: 2.446  loss_ce6: 2.752    time: 1.6671  last_time: 1.6367  data_time: 0.0479  last_data_time: 0.0440   lr: 7.3531e-06  max_mem: 49046M
[03/05 18:27:13 d2.utils.events]:  eta: 1 day, 8:47:56  iter: 28959  total_loss: 9.272  loss_ce0: 0.6931  loss_ce1: 1.189  loss_ce2: 1.052  loss_ce3: 0.7554  loss_ce4: 0.9689  loss_ce5: 2.186  loss_ce6: 2.319    time: 1.6671  last_time: 1.6364  data_time: 0.0468  last_data_time: 0.0450   lr: 7.3512e-06  max_mem: 49046M
[03/05 18:27:46 d2.utils.events]:  eta: 1 day, 8:46:36  iter: 28979  total_loss: 9.577  loss_ce0: 0.7295  loss_ce1: 1.114  loss_ce2: 1.171  loss_ce3: 0.8487  loss_ce4: 0.9552  loss_ce5: 1.995  loss_ce6: 2.33    time: 1.6671  last_time: 1.6593  data_time: 0.0456  last_data_time: 0.0469   lr: 7.3493e-06  max_mem: 49046M
[03/05 18:28:20 d2.utils.events]:  eta: 1 day, 8:45:56  iter: 28999  total_loss: 9.941  loss_ce0: 0.6949  loss_ce1: 1.178  loss_ce2: 1.022  loss_ce3: 0.7581  loss_ce4: 1.019  loss_ce5: 2.299  loss_ce6: 2.382    time: 1.6671  last_time: 1.6815  data_time: 0.0489  last_data_time: 0.0503   lr: 7.3475e-06  max_mem: 49046M
[03/05 18:28:53 d2.utils.events]:  eta: 1 day, 8:45:22  iter: 29019  total_loss: 9.371  loss_ce0: 0.6918  loss_ce1: 1.155  loss_ce2: 1.166  loss_ce3: 0.828  loss_ce4: 1  loss_ce5: 2.101  loss_ce6: 2.419    time: 1.6670  last_time: 1.6276  data_time: 0.0462  last_data_time: 0.0488   lr: 7.3456e-06  max_mem: 49046M
[03/05 18:29:26 d2.utils.events]:  eta: 1 day, 8:44:45  iter: 29039  total_loss: 10.21  loss_ce0: 0.7147  loss_ce1: 1.175  loss_ce2: 1.368  loss_ce3: 0.7744  loss_ce4: 0.9552  loss_ce5: 2.452  loss_ce6: 2.22    time: 1.6670  last_time: 1.6168  data_time: 0.0458  last_data_time: 0.0436   lr: 7.3437e-06  max_mem: 49046M
[03/05 18:29:59 d2.utils.events]:  eta: 1 day, 8:44:02  iter: 29059  total_loss: 10.17  loss_ce0: 0.7096  loss_ce1: 1.14  loss_ce2: 1.112  loss_ce3: 0.8134  loss_ce4: 1.036  loss_ce5: 2.372  loss_ce6: 2.364    time: 1.6670  last_time: 1.6541  data_time: 0.0476  last_data_time: 0.0459   lr: 7.3419e-06  max_mem: 49046M
[03/05 18:30:33 d2.utils.events]:  eta: 1 day, 8:43:37  iter: 29079  total_loss: 9.489  loss_ce0: 0.7025  loss_ce1: 1.154  loss_ce2: 1.069  loss_ce3: 0.8627  loss_ce4: 1.036  loss_ce5: 2.233  loss_ce6: 2.459    time: 1.6671  last_time: 1.6044  data_time: 0.0510  last_data_time: 0.0489   lr: 7.34e-06  max_mem: 49046M
[03/05 18:31:06 d2.utils.events]:  eta: 1 day, 8:43:03  iter: 29099  total_loss: 9.684  loss_ce0: 0.7146  loss_ce1: 1.137  loss_ce2: 1.211  loss_ce3: 0.8462  loss_ce4: 0.9592  loss_ce5: 2.225  loss_ce6: 2.479    time: 1.6671  last_time: 1.6166  data_time: 0.0450  last_data_time: 0.0444   lr: 7.3382e-06  max_mem: 49046M
[03/05 18:31:40 d2.utils.events]:  eta: 1 day, 8:42:32  iter: 29119  total_loss: 9.803  loss_ce0: 0.7  loss_ce1: 1.124  loss_ce2: 1.337  loss_ce3: 0.8686  loss_ce4: 1.062  loss_ce5: 1.891  loss_ce6: 2.508    time: 1.6671  last_time: 1.6129  data_time: 0.0450  last_data_time: 0.0444   lr: 7.3363e-06  max_mem: 49046M
[03/05 18:32:13 d2.utils.events]:  eta: 1 day, 8:41:59  iter: 29139  total_loss: 9.69  loss_ce0: 0.7086  loss_ce1: 1.135  loss_ce2: 1.18  loss_ce3: 0.7959  loss_ce4: 1.045  loss_ce5: 2.49  loss_ce6: 2.291    time: 1.6671  last_time: 1.5968  data_time: 0.0490  last_data_time: 0.0404   lr: 7.3344e-06  max_mem: 49046M
[03/05 18:32:46 d2.utils.events]:  eta: 1 day, 8:41:04  iter: 29159  total_loss: 9.691  loss_ce0: 0.7597  loss_ce1: 1.177  loss_ce2: 1.065  loss_ce3: 0.7985  loss_ce4: 0.9502  loss_ce5: 2.349  loss_ce6: 2.302    time: 1.6670  last_time: 1.6593  data_time: 0.0470  last_data_time: 0.0473   lr: 7.3326e-06  max_mem: 49046M
[03/05 18:33:20 d2.utils.events]:  eta: 1 day, 8:40:51  iter: 29179  total_loss: 9.195  loss_ce0: 0.6865  loss_ce1: 1.116  loss_ce2: 1.072  loss_ce3: 0.797  loss_ce4: 1.009  loss_ce5: 2.128  loss_ce6: 2.245    time: 1.6671  last_time: 1.6112  data_time: 0.0478  last_data_time: 0.0444   lr: 7.3307e-06  max_mem: 49046M
[03/05 18:33:53 d2.utils.events]:  eta: 1 day, 8:40:07  iter: 29199  total_loss: 9.082  loss_ce0: 0.6966  loss_ce1: 1.211  loss_ce2: 1.177  loss_ce3: 0.7459  loss_ce4: 1.029  loss_ce5: 2.127  loss_ce6: 2.329    time: 1.6671  last_time: 1.6798  data_time: 0.0471  last_data_time: 0.0436   lr: 7.3288e-06  max_mem: 49046M
[03/05 18:34:27 d2.utils.events]:  eta: 1 day, 8:39:50  iter: 29219  total_loss: 10.04  loss_ce0: 0.7124  loss_ce1: 1.181  loss_ce2: 1.055  loss_ce3: 0.9174  loss_ce4: 0.964  loss_ce5: 2.403  loss_ce6: 2.462    time: 1.6671  last_time: 1.6191  data_time: 0.0461  last_data_time: 0.0447   lr: 7.327e-06  max_mem: 49046M
[03/05 18:35:00 d2.utils.events]:  eta: 1 day, 8:38:48  iter: 29239  total_loss: 9.925  loss_ce0: 0.6857  loss_ce1: 1.232  loss_ce2: 1.159  loss_ce3: 0.7803  loss_ce4: 0.9768  loss_ce5: 2.235  loss_ce6: 2.472    time: 1.6670  last_time: 1.6132  data_time: 0.0470  last_data_time: 0.0432   lr: 7.3251e-06  max_mem: 49046M
[03/05 18:35:33 d2.utils.events]:  eta: 1 day, 8:38:11  iter: 29259  total_loss: 9.388  loss_ce0: 0.6942  loss_ce1: 1.139  loss_ce2: 1.158  loss_ce3: 0.8026  loss_ce4: 1.006  loss_ce5: 2.08  loss_ce6: 2.349    time: 1.6670  last_time: 1.6627  data_time: 0.0464  last_data_time: 0.0492   lr: 7.3233e-06  max_mem: 49046M
[03/05 18:36:06 d2.utils.events]:  eta: 1 day, 8:37:33  iter: 29279  total_loss: 9.597  loss_ce0: 0.6967  loss_ce1: 1.224  loss_ce2: 1.115  loss_ce3: 0.8207  loss_ce4: 0.9791  loss_ce5: 2.278  loss_ce6: 2.422    time: 1.6670  last_time: 1.6269  data_time: 0.0471  last_data_time: 0.0443   lr: 7.3214e-06  max_mem: 49046M
[03/05 18:36:39 d2.utils.events]:  eta: 1 day, 8:37:44  iter: 29299  total_loss: 9.553  loss_ce0: 0.6995  loss_ce1: 1.193  loss_ce2: 1.047  loss_ce3: 0.7958  loss_ce4: 0.9064  loss_ce5: 2.18  loss_ce6: 2.241    time: 1.6670  last_time: 1.6746  data_time: 0.0485  last_data_time: 0.0564   lr: 7.3195e-06  max_mem: 49046M
[03/05 18:37:13 d2.utils.events]:  eta: 1 day, 8:37:35  iter: 29319  total_loss: 9.623  loss_ce0: 0.7635  loss_ce1: 1.213  loss_ce2: 1.129  loss_ce3: 0.7459  loss_ce4: 0.9551  loss_ce5: 2.21  loss_ce6: 2.286    time: 1.6670  last_time: 1.6619  data_time: 0.0459  last_data_time: 0.0481   lr: 7.3177e-06  max_mem: 49046M
[03/05 18:37:47 d2.utils.events]:  eta: 1 day, 8:37:28  iter: 29339  total_loss: 9.669  loss_ce0: 0.7026  loss_ce1: 1.22  loss_ce2: 1.103  loss_ce3: 0.7368  loss_ce4: 1.025  loss_ce5: 2.238  loss_ce6: 2.628    time: 1.6671  last_time: 1.6960  data_time: 0.0478  last_data_time: 0.0475   lr: 7.3158e-06  max_mem: 49046M
[03/05 18:38:20 d2.utils.events]:  eta: 1 day, 8:36:39  iter: 29359  total_loss: 9.575  loss_ce0: 0.6775  loss_ce1: 1.194  loss_ce2: 0.9524  loss_ce3: 0.8374  loss_ce4: 0.9972  loss_ce5: 2.163  loss_ce6: 2.492    time: 1.6670  last_time: 1.6625  data_time: 0.0473  last_data_time: 0.0483   lr: 7.3139e-06  max_mem: 49046M
[03/05 18:38:53 d2.utils.events]:  eta: 1 day, 8:36:03  iter: 29379  total_loss: 9.8  loss_ce0: 0.7168  loss_ce1: 1.156  loss_ce2: 1.387  loss_ce3: 0.7719  loss_ce4: 0.9726  loss_ce5: 2.375  loss_ce6: 2.383    time: 1.6670  last_time: 1.6947  data_time: 0.0466  last_data_time: 0.0409   lr: 7.3121e-06  max_mem: 49046M
[03/05 18:39:26 d2.utils.events]:  eta: 1 day, 8:35:30  iter: 29399  total_loss: 9.672  loss_ce0: 0.702  loss_ce1: 1.075  loss_ce2: 1.129  loss_ce3: 0.7679  loss_ce4: 1.038  loss_ce5: 2.339  loss_ce6: 2.521    time: 1.6670  last_time: 1.6609  data_time: 0.0458  last_data_time: 0.0488   lr: 7.3102e-06  max_mem: 49046M
[03/05 18:40:00 d2.utils.events]:  eta: 1 day, 8:35:15  iter: 29419  total_loss: 9.411  loss_ce0: 0.6913  loss_ce1: 1.11  loss_ce2: 1.093  loss_ce3: 0.7565  loss_ce4: 0.9995  loss_ce5: 2.21  loss_ce6: 2.541    time: 1.6670  last_time: 1.6797  data_time: 0.0470  last_data_time: 0.0580   lr: 7.3083e-06  max_mem: 49046M
[03/05 18:40:33 d2.utils.events]:  eta: 1 day, 8:33:50  iter: 29439  total_loss: 9.733  loss_ce0: 0.7078  loss_ce1: 1.187  loss_ce2: 1.134  loss_ce3: 0.7509  loss_ce4: 0.9567  loss_ce5: 2.338  loss_ce6: 2.355    time: 1.6670  last_time: 1.7442  data_time: 0.0455  last_data_time: 0.0615   lr: 7.3065e-06  max_mem: 49046M
[03/05 18:41:06 d2.utils.events]:  eta: 1 day, 8:32:44  iter: 29459  total_loss: 9.564  loss_ce0: 0.719  loss_ce1: 1.146  loss_ce2: 1.001  loss_ce3: 0.8535  loss_ce4: 0.9642  loss_ce5: 2.238  loss_ce6: 2.28    time: 1.6670  last_time: 1.6021  data_time: 0.0458  last_data_time: 0.0414   lr: 7.3046e-06  max_mem: 49046M
[03/05 18:41:40 d2.utils.events]:  eta: 1 day, 8:33:12  iter: 29479  total_loss: 9.326  loss_ce0: 0.7058  loss_ce1: 1.156  loss_ce2: 1.16  loss_ce3: 0.8595  loss_ce4: 0.9856  loss_ce5: 2.049  loss_ce6: 2.214    time: 1.6670  last_time: 1.6128  data_time: 0.0472  last_data_time: 0.0407   lr: 7.3028e-06  max_mem: 49046M
[03/05 18:42:13 d2.utils.events]:  eta: 1 day, 8:33:22  iter: 29499  total_loss: 9.82  loss_ce0: 0.7236  loss_ce1: 1.218  loss_ce2: 1.23  loss_ce3: 0.7894  loss_ce4: 0.9971  loss_ce5: 2.193  loss_ce6: 2.622    time: 1.6670  last_time: 1.7027  data_time: 0.0466  last_data_time: 0.0461   lr: 7.3009e-06  max_mem: 49046M
[03/05 18:42:46 d2.utils.events]:  eta: 1 day, 8:32:56  iter: 29519  total_loss: 10.1  loss_ce0: 0.712  loss_ce1: 1.216  loss_ce2: 1.1  loss_ce3: 0.8105  loss_ce4: 0.9808  loss_ce5: 2.314  loss_ce6: 2.636    time: 1.6670  last_time: 1.6741  data_time: 0.0455  last_data_time: 0.0468   lr: 7.299e-06  max_mem: 49046M
[03/05 18:43:19 d2.utils.events]:  eta: 1 day, 8:32:15  iter: 29539  total_loss: 9.589  loss_ce0: 0.6955  loss_ce1: 1.187  loss_ce2: 1.027  loss_ce3: 0.8133  loss_ce4: 0.9899  loss_ce5: 2.078  loss_ce6: 2.78    time: 1.6669  last_time: 1.6071  data_time: 0.0496  last_data_time: 0.0452   lr: 7.2972e-06  max_mem: 49046M
[03/05 18:43:52 d2.utils.events]:  eta: 1 day, 8:31:42  iter: 29559  total_loss: 9.848  loss_ce0: 0.7006  loss_ce1: 1.156  loss_ce2: 1.307  loss_ce3: 0.8951  loss_ce4: 0.9741  loss_ce5: 2.323  loss_ce6: 2.313    time: 1.6669  last_time: 1.6489  data_time: 0.0459  last_data_time: 0.0445   lr: 7.2953e-06  max_mem: 49046M
[03/05 18:44:26 d2.utils.events]:  eta: 1 day, 8:31:40  iter: 29579  total_loss: 10.22  loss_ce0: 0.7024  loss_ce1: 1.259  loss_ce2: 1.315  loss_ce3: 0.8121  loss_ce4: 0.9671  loss_ce5: 2.097  loss_ce6: 2.678    time: 1.6670  last_time: 1.6994  data_time: 0.0463  last_data_time: 0.0464   lr: 7.2934e-06  max_mem: 49046M
[03/05 18:45:00 d2.utils.events]:  eta: 1 day, 8:31:47  iter: 29599  total_loss: 9.679  loss_ce0: 0.6842  loss_ce1: 1.207  loss_ce2: 1.236  loss_ce3: 0.84  loss_ce4: 1.008  loss_ce5: 2.179  loss_ce6: 2.37    time: 1.6670  last_time: 1.7004  data_time: 0.0495  last_data_time: 0.0443   lr: 7.2916e-06  max_mem: 49046M
[03/05 18:45:33 d2.utils.events]:  eta: 1 day, 8:31:14  iter: 29619  total_loss: 10.14  loss_ce0: 0.735  loss_ce1: 1.144  loss_ce2: 1.204  loss_ce3: 0.8333  loss_ce4: 0.9984  loss_ce5: 2.202  loss_ce6: 2.515    time: 1.6670  last_time: 1.7276  data_time: 0.0473  last_data_time: 0.0463   lr: 7.2897e-06  max_mem: 49046M
[03/05 18:46:07 d2.utils.events]:  eta: 1 day, 8:30:18  iter: 29639  total_loss: 10.02  loss_ce0: 0.702  loss_ce1: 1.246  loss_ce2: 1.257  loss_ce3: 0.7798  loss_ce4: 1.024  loss_ce5: 2.255  loss_ce6: 2.355    time: 1.6670  last_time: 1.6267  data_time: 0.0454  last_data_time: 0.0444   lr: 7.2878e-06  max_mem: 49046M
[03/05 18:46:40 d2.utils.events]:  eta: 1 day, 8:30:22  iter: 29659  total_loss: 9.797  loss_ce0: 0.6871  loss_ce1: 1.101  loss_ce2: 1.137  loss_ce3: 0.838  loss_ce4: 0.9339  loss_ce5: 2.416  loss_ce6: 2.439    time: 1.6670  last_time: 1.6149  data_time: 0.0466  last_data_time: 0.0409   lr: 7.286e-06  max_mem: 49046M
[03/05 18:47:13 d2.utils.events]:  eta: 1 day, 8:30:25  iter: 29679  total_loss: 9.569  loss_ce0: 0.702  loss_ce1: 1.134  loss_ce2: 1.282  loss_ce3: 0.8824  loss_ce4: 0.973  loss_ce5: 2.252  loss_ce6: 2.103    time: 1.6669  last_time: 1.6335  data_time: 0.0444  last_data_time: 0.0427   lr: 7.2841e-06  max_mem: 49046M
[03/05 18:47:46 d2.utils.events]:  eta: 1 day, 8:30:02  iter: 29699  total_loss: 9.598  loss_ce0: 0.7046  loss_ce1: 1.206  loss_ce2: 0.9851  loss_ce3: 0.779  loss_ce4: 0.9813  loss_ce5: 2.125  loss_ce6: 2.53    time: 1.6670  last_time: 1.6749  data_time: 0.0462  last_data_time: 0.0434   lr: 7.2822e-06  max_mem: 49046M
[03/05 18:48:19 d2.utils.events]:  eta: 1 day, 8:28:42  iter: 29719  total_loss: 9.515  loss_ce0: 0.7004  loss_ce1: 1.194  loss_ce2: 1.14  loss_ce3: 0.7893  loss_ce4: 0.9746  loss_ce5: 1.961  loss_ce6: 2.257    time: 1.6669  last_time: 1.6498  data_time: 0.0452  last_data_time: 0.0554   lr: 7.2804e-06  max_mem: 49046M
[03/05 18:48:53 d2.utils.events]:  eta: 1 day, 8:28:55  iter: 29739  total_loss: 9.772  loss_ce0: 0.6959  loss_ce1: 1.125  loss_ce2: 1.166  loss_ce3: 0.838  loss_ce4: 0.9353  loss_ce5: 2.133  loss_ce6: 2.442    time: 1.6669  last_time: 1.7203  data_time: 0.0489  last_data_time: 0.0437   lr: 7.2785e-06  max_mem: 49046M
[03/05 18:49:26 d2.utils.events]:  eta: 1 day, 8:28:22  iter: 29759  total_loss: 9.755  loss_ce0: 0.6953  loss_ce1: 1.181  loss_ce2: 1.081  loss_ce3: 0.8239  loss_ce4: 0.9599  loss_ce5: 2.046  loss_ce6: 2.62    time: 1.6669  last_time: 1.5966  data_time: 0.0460  last_data_time: 0.0457   lr: 7.2767e-06  max_mem: 49046M
[03/05 18:49:59 d2.utils.events]:  eta: 1 day, 8:26:25  iter: 29779  total_loss: 9.585  loss_ce0: 0.6999  loss_ce1: 1.123  loss_ce2: 1.09  loss_ce3: 0.7707  loss_ce4: 0.9669  loss_ce5: 2.253  loss_ce6: 2.378    time: 1.6668  last_time: 1.6185  data_time: 0.0430  last_data_time: 0.0423   lr: 7.2748e-06  max_mem: 49046M
[03/05 18:50:32 d2.utils.events]:  eta: 1 day, 8:26:14  iter: 29799  total_loss: 9.784  loss_ce0: 0.6971  loss_ce1: 1.152  loss_ce2: 1.177  loss_ce3: 0.8136  loss_ce4: 0.9785  loss_ce5: 2.132  loss_ce6: 2.203    time: 1.6668  last_time: 1.6406  data_time: 0.0467  last_data_time: 0.0534   lr: 7.2729e-06  max_mem: 49046M
[03/05 18:51:05 d2.utils.events]:  eta: 1 day, 8:25:06  iter: 29819  total_loss: 9.562  loss_ce0: 0.6732  loss_ce1: 1.191  loss_ce2: 1.184  loss_ce3: 0.8328  loss_ce4: 0.9413  loss_ce5: 2.205  loss_ce6: 2.425    time: 1.6668  last_time: 1.7178  data_time: 0.0447  last_data_time: 0.0512   lr: 7.2711e-06  max_mem: 49046M
[03/05 18:51:38 d2.utils.events]:  eta: 1 day, 8:24:45  iter: 29839  total_loss: 9.731  loss_ce0: 0.7049  loss_ce1: 1.201  loss_ce2: 1.196  loss_ce3: 0.7905  loss_ce4: 0.9617  loss_ce5: 2.107  loss_ce6: 2.529    time: 1.6668  last_time: 1.6840  data_time: 0.0466  last_data_time: 0.0500   lr: 7.2692e-06  max_mem: 49046M
[03/05 18:52:12 d2.utils.events]:  eta: 1 day, 8:23:23  iter: 29859  total_loss: 9.685  loss_ce0: 0.6818  loss_ce1: 1.205  loss_ce2: 1.115  loss_ce3: 0.7337  loss_ce4: 0.9823  loss_ce5: 2.194  loss_ce6: 2.281    time: 1.6668  last_time: 1.6052  data_time: 0.0450  last_data_time: 0.0462   lr: 7.2673e-06  max_mem: 49046M
[03/05 18:52:45 d2.utils.events]:  eta: 1 day, 8:22:55  iter: 29879  total_loss: 9.878  loss_ce0: 0.7013  loss_ce1: 1.156  loss_ce2: 1.19  loss_ce3: 0.8025  loss_ce4: 0.9632  loss_ce5: 2.369  loss_ce6: 2.668    time: 1.6668  last_time: 1.7025  data_time: 0.0474  last_data_time: 0.0542   lr: 7.2655e-06  max_mem: 49046M
[03/05 18:53:19 d2.utils.events]:  eta: 1 day, 8:22:31  iter: 29899  total_loss: 9.322  loss_ce0: 0.6791  loss_ce1: 1.178  loss_ce2: 1.036  loss_ce3: 0.7701  loss_ce4: 1.027  loss_ce5: 2.285  loss_ce6: 2.259    time: 1.6669  last_time: 1.6323  data_time: 0.0471  last_data_time: 0.0400   lr: 7.2636e-06  max_mem: 49046M
[03/05 18:53:52 d2.utils.events]:  eta: 1 day, 8:21:09  iter: 29919  total_loss: 9.819  loss_ce0: 0.7087  loss_ce1: 1.103  loss_ce2: 1.21  loss_ce3: 0.7649  loss_ce4: 0.9376  loss_ce5: 2.23  loss_ce6: 2.537    time: 1.6669  last_time: 1.6982  data_time: 0.0470  last_data_time: 0.0439   lr: 7.2617e-06  max_mem: 49046M
[03/05 18:54:26 d2.utils.events]:  eta: 1 day, 8:20:26  iter: 29939  total_loss: 9.548  loss_ce0: 0.7291  loss_ce1: 1.099  loss_ce2: 1.112  loss_ce3: 0.8009  loss_ce4: 0.9673  loss_ce5: 2.334  loss_ce6: 2.482    time: 1.6668  last_time: 1.6264  data_time: 0.0451  last_data_time: 0.0431   lr: 7.2599e-06  max_mem: 49046M
[03/05 18:54:59 d2.utils.events]:  eta: 1 day, 8:19:44  iter: 29959  total_loss: 9.493  loss_ce0: 0.7069  loss_ce1: 1.05  loss_ce2: 1.147  loss_ce3: 0.7487  loss_ce4: 1.043  loss_ce5: 2.293  loss_ce6: 2.424    time: 1.6668  last_time: 1.6141  data_time: 0.0469  last_data_time: 0.0427   lr: 7.258e-06  max_mem: 49046M
[03/05 18:55:32 d2.utils.events]:  eta: 1 day, 8:19:05  iter: 29979  total_loss: 9.506  loss_ce0: 0.7095  loss_ce1: 1.105  loss_ce2: 1.18  loss_ce3: 0.8647  loss_ce4: 0.9478  loss_ce5: 2.24  loss_ce6: 2.25    time: 1.6668  last_time: 1.6770  data_time: 0.0446  last_data_time: 0.0482   lr: 7.2561e-06  max_mem: 49046M
[03/05 18:56:05 fvcore.common.checkpoint]: Saving checkpoint to ./output/model_0029999.pth
[03/05 18:56:07 d2.engine.defaults]: cur name: cs_sem_seg_val
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c0aaeb0>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c0aa850>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c0aac70>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c0aa670>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c0aa5e0>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c0aa100>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c098d30>, RandomFlip()]
[03/05 18:56:08 mask2former.data.dataloader.DaliDataLoader]: evaluate cs_sem_seg_val
[03/05 18:56:08 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 18:56:08 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[03/05 18:56:08 d2.data.common]: Serialized dataset takes 0.16 MiB
[03/05 18:56:08 d2.evaluation.evaluator]: Start inference on 500 batches
[03/05 18:56:11 d2.evaluation.evaluator]: Inference done 11/500. Dataloading: 0.0041 s/iter. Inference: 0.0927 s/iter. Eval: 0.2216 s/iter. Total: 0.3184 s/iter. ETA=0:02:35
[03/05 18:56:17 d2.evaluation.evaluator]: Inference done 27/500. Dataloading: 0.0056 s/iter. Inference: 0.0905 s/iter. Eval: 0.2246 s/iter. Total: 0.3208 s/iter. ETA=0:02:31
[03/05 18:56:22 d2.evaluation.evaluator]: Inference done 44/500. Dataloading: 0.0053 s/iter. Inference: 0.0900 s/iter. Eval: 0.2218 s/iter. Total: 0.3171 s/iter. ETA=0:02:24
[03/05 18:56:27 d2.evaluation.evaluator]: Inference done 60/500. Dataloading: 0.0052 s/iter. Inference: 0.0901 s/iter. Eval: 0.2220 s/iter. Total: 0.3175 s/iter. ETA=0:02:19
[03/05 18:56:32 d2.evaluation.evaluator]: Inference done 77/500. Dataloading: 0.0052 s/iter. Inference: 0.0900 s/iter. Eval: 0.2184 s/iter. Total: 0.3139 s/iter. ETA=0:02:12
[03/05 18:56:37 d2.evaluation.evaluator]: Inference done 93/500. Dataloading: 0.0052 s/iter. Inference: 0.0898 s/iter. Eval: 0.2187 s/iter. Total: 0.3139 s/iter. ETA=0:02:07
[03/05 18:56:42 d2.evaluation.evaluator]: Inference done 109/500. Dataloading: 0.0052 s/iter. Inference: 0.0900 s/iter. Eval: 0.2198 s/iter. Total: 0.3152 s/iter. ETA=0:02:03
[03/05 18:56:48 d2.evaluation.evaluator]: Inference done 126/500. Dataloading: 0.0051 s/iter. Inference: 0.0899 s/iter. Eval: 0.2185 s/iter. Total: 0.3137 s/iter. ETA=0:01:57
[03/05 18:56:53 d2.evaluation.evaluator]: Inference done 143/500. Dataloading: 0.0050 s/iter. Inference: 0.0897 s/iter. Eval: 0.2172 s/iter. Total: 0.3122 s/iter. ETA=0:01:51
[03/05 18:56:58 d2.evaluation.evaluator]: Inference done 160/500. Dataloading: 0.0050 s/iter. Inference: 0.0897 s/iter. Eval: 0.2160 s/iter. Total: 0.3109 s/iter. ETA=0:01:45
[03/05 18:57:03 d2.evaluation.evaluator]: Inference done 177/500. Dataloading: 0.0050 s/iter. Inference: 0.0896 s/iter. Eval: 0.2155 s/iter. Total: 0.3102 s/iter. ETA=0:01:40
[03/05 18:57:08 d2.evaluation.evaluator]: Inference done 194/500. Dataloading: 0.0050 s/iter. Inference: 0.0896 s/iter. Eval: 0.2158 s/iter. Total: 0.3105 s/iter. ETA=0:01:35
[03/05 18:57:13 d2.evaluation.evaluator]: Inference done 211/500. Dataloading: 0.0050 s/iter. Inference: 0.0895 s/iter. Eval: 0.2155 s/iter. Total: 0.3102 s/iter. ETA=0:01:29
[03/05 18:57:19 d2.evaluation.evaluator]: Inference done 228/500. Dataloading: 0.0050 s/iter. Inference: 0.0896 s/iter. Eval: 0.2151 s/iter. Total: 0.3099 s/iter. ETA=0:01:24
[03/05 18:57:24 d2.evaluation.evaluator]: Inference done 246/500. Dataloading: 0.0050 s/iter. Inference: 0.0895 s/iter. Eval: 0.2140 s/iter. Total: 0.3087 s/iter. ETA=0:01:18
[03/05 18:57:29 d2.evaluation.evaluator]: Inference done 264/500. Dataloading: 0.0050 s/iter. Inference: 0.0895 s/iter. Eval: 0.2133 s/iter. Total: 0.3079 s/iter. ETA=0:01:12
[03/05 18:57:35 d2.evaluation.evaluator]: Inference done 282/500. Dataloading: 0.0050 s/iter. Inference: 0.0894 s/iter. Eval: 0.2123 s/iter. Total: 0.3068 s/iter. ETA=0:01:06
[03/05 18:57:40 d2.evaluation.evaluator]: Inference done 299/500. Dataloading: 0.0050 s/iter. Inference: 0.0894 s/iter. Eval: 0.2117 s/iter. Total: 0.3063 s/iter. ETA=0:01:01
[03/05 18:57:45 d2.evaluation.evaluator]: Inference done 315/500. Dataloading: 0.0050 s/iter. Inference: 0.0894 s/iter. Eval: 0.2122 s/iter. Total: 0.3068 s/iter. ETA=0:00:56
[03/05 18:57:50 d2.evaluation.evaluator]: Inference done 332/500. Dataloading: 0.0050 s/iter. Inference: 0.0893 s/iter. Eval: 0.2122 s/iter. Total: 0.3066 s/iter. ETA=0:00:51
[03/05 18:57:55 d2.evaluation.evaluator]: Inference done 349/500. Dataloading: 0.0050 s/iter. Inference: 0.0893 s/iter. Eval: 0.2119 s/iter. Total: 0.3063 s/iter. ETA=0:00:46
[03/05 18:58:00 d2.evaluation.evaluator]: Inference done 366/500. Dataloading: 0.0050 s/iter. Inference: 0.0893 s/iter. Eval: 0.2121 s/iter. Total: 0.3065 s/iter. ETA=0:00:41
[03/05 18:58:05 d2.evaluation.evaluator]: Inference done 383/500. Dataloading: 0.0050 s/iter. Inference: 0.0893 s/iter. Eval: 0.2121 s/iter. Total: 0.3064 s/iter. ETA=0:00:35
[03/05 18:58:11 d2.evaluation.evaluator]: Inference done 400/500. Dataloading: 0.0050 s/iter. Inference: 0.0893 s/iter. Eval: 0.2121 s/iter. Total: 0.3066 s/iter. ETA=0:00:30
[03/05 18:58:16 d2.evaluation.evaluator]: Inference done 417/500. Dataloading: 0.0050 s/iter. Inference: 0.0893 s/iter. Eval: 0.2118 s/iter. Total: 0.3062 s/iter. ETA=0:00:25
[03/05 18:58:21 d2.evaluation.evaluator]: Inference done 434/500. Dataloading: 0.0050 s/iter. Inference: 0.0894 s/iter. Eval: 0.2114 s/iter. Total: 0.3058 s/iter. ETA=0:00:20
[03/05 18:58:26 d2.evaluation.evaluator]: Inference done 451/500. Dataloading: 0.0049 s/iter. Inference: 0.0893 s/iter. Eval: 0.2112 s/iter. Total: 0.3056 s/iter. ETA=0:00:14
[03/05 18:58:31 d2.evaluation.evaluator]: Inference done 468/500. Dataloading: 0.0049 s/iter. Inference: 0.0893 s/iter. Eval: 0.2113 s/iter. Total: 0.3056 s/iter. ETA=0:00:09
[03/05 18:58:36 d2.evaluation.evaluator]: Inference done 485/500. Dataloading: 0.0049 s/iter. Inference: 0.0893 s/iter. Eval: 0.2110 s/iter. Total: 0.3053 s/iter. ETA=0:00:04
[03/05 18:58:40 d2.evaluation.evaluator]: Total inference time: 0:02:30.518986 (0.304079 s / iter per device, on 1 devices)
[03/05 18:58:40 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:44 (0.089098 s / iter per device, on 1 devices)
[03/05 18:58:40 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 70.9445940563224, 'fwIoU': 91.35351890146102, 'IoU-road': 97.48474248018869, 'BoundaryIoU-road': 88.54038188348471, 'min(IoU, B-Iou)-road': 88.54038188348471, 'IoU-sidewalk': 80.72305000090006, 'BoundaryIoU-sidewalk': 48.47719796220413, 'min(IoU, B-Iou)-sidewalk': 48.47719796220413, 'IoU-building': 91.65096244964978, 'BoundaryIoU-building': 70.28149434182573, 'min(IoU, B-Iou)-building': 70.28149434182573, 'IoU-wall': 54.6604529935638, 'BoundaryIoU-wall': 41.248366844883584, 'min(IoU, B-Iou)-wall': 41.248366844883584, 'IoU-fence': 56.22207907519281, 'BoundaryIoU-fence': 28.78326384393916, 'min(IoU, B-Iou)-fence': 28.78326384393916, 'IoU-pole': 58.586168674115946, 'BoundaryIoU-pole': 42.14568434121091, 'min(IoU, B-Iou)-pole': 42.14568434121091, 'IoU-traffic light': 59.30244397074183, 'BoundaryIoU-traffic light': 62.91373921075497, 'min(IoU, B-Iou)-traffic light': 59.30244397074183, 'IoU-traffic sign': 70.19996530272766, 'BoundaryIoU-traffic sign': 42.76167821688488, 'min(IoU, B-Iou)-traffic sign': 42.76167821688488, 'IoU-vegetation': 91.7510373619009, 'BoundaryIoU-vegetation': 75.86378040241729, 'min(IoU, B-Iou)-vegetation': 75.86378040241729, 'IoU-terrain': 58.2882272171574, 'BoundaryIoU-terrain': 53.313482563552384, 'min(IoU, B-Iou)-terrain': 53.313482563552384, 'IoU-sky': 94.60125152953235, 'BoundaryIoU-sky': 72.47906254159484, 'min(IoU, B-Iou)-sky': 72.47906254159484, 'IoU-person': 76.9609113794063, 'BoundaryIoU-person': 64.50463802496316, 'min(IoU, B-Iou)-person': 64.50463802496316, 'IoU-rider': 52.433502377307775, 'BoundaryIoU-rider': 43.3036822496824, 'min(IoU, B-Iou)-rider': 43.3036822496824, 'IoU-car': 93.90998096396815, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-truck': 76.27378311179736, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-bus': 70.75594677559714, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-train': 40.49996428722401, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-motorcycle': 52.001651929556715, 'BoundaryIoU-motorcycle': 0.0, 'min(IoU, B-Iou)-motorcycle': 0.0, 'IoU-bicycle': 71.6411651895968, 'BoundaryIoU-bicycle': 0.0, 'min(IoU, B-Iou)-bicycle': 0.0, 'mACC': 80.37268034130838, 'pACC': 95.24300171868569, 'ACC-road': 98.2486132583619, 'ACC-sidewalk': 92.09613656089692, 'ACC-building': 96.11024194762585, 'ACC-wall': 65.94579450145017, 'ACC-fence': 69.42099148545738, 'ACC-pole': 68.96741152611749, 'ACC-traffic light': 71.40999489065956, 'ACC-traffic sign': 76.39197215587413, 'ACC-vegetation': 96.40310902583187, 'ACC-terrain': 70.68211964129696, 'ACC-sky': 97.41508197518462, 'ACC-person': 88.49206542880411, 'ACC-rider': 65.3660464993855, 'ACC-car': 97.64695305278678, 'ACC-truck': 85.04440421402568, 'ACC-bus': 78.90851276409438, 'ACC-train': 53.86362402679984, 'ACC-motorcycle': 70.60479973677536, 'ACC-bicycle': 84.06305379343056})])
[03/05 18:58:40 d2.engine.defaults]: Evaluation results for cs_sem_seg_val in csv format:
[03/05 18:58:40 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/05 18:58:40 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/05 18:58:40 d2.evaluation.testing]: copypaste: 70.9446,91.3535,80.3727,95.2430
[03/05 18:58:40 d2.engine.defaults]: cur name: sunrgbd_sem_seg_val
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c4d0ac0>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9afbefaac0>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9afbefaf10>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9afbefa460>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9afbdfa760>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9afbdfadf0>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7f9a2c561e80>, RandomFlip()]
[03/05 18:58:40 mask2former.data.dataloader.DaliDataLoader]: evaluate sunrgbd_sem_seg_val
[03/05 18:58:40 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/05 18:58:40 d2.data.common]: Serializing 5050 elements to byte tensors and concatenating them all ...
[03/05 18:58:40 d2.data.common]: Serialized dataset takes 1.08 MiB
[03/05 18:58:40 d2.evaluation.evaluator]: Start inference on 5050 batches
ERROR [03/05 18:58:41 d2.engine.train_loop]: Exception during training:
Traceback (most recent call last):
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/defaults.py", line 455, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/defaults.py", line 621, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/evaluation/evaluator.py", line 172, in inference_on_dataset
    evaluator.process(inputs, outputs)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/evaluation/sem_seg_evaluation.py", line 139, in process
    (self._num_classes + 1) * pred.reshape(-1) + gt.reshape(-1),
ValueError: operands could not be broadcast together with shapes (258048,) (239547,) 
[03/05 18:58:41 d2.engine.hooks]: Overall training speed: 9997 iterations in 4:37:44 (1.6669 s / it)
[03/05 18:58:41 d2.engine.hooks]: Total training time: 4:40:40 (0:02:55 on hooks)
[03/05 18:58:41 d2.utils.events]:  eta: 1 day, 8:18:11  iter: 29999  total_loss: 9.598  loss_ce0: 0.7185  loss_ce1: 1.217  loss_ce2: 1.216  loss_ce3: 0.7605  loss_ce4: 1.015  loss_ce5: 1.963  loss_ce6: 2.262    time: 1.6668  last_time: 1.6723  data_time: 0.0449  last_data_time: 0.0456   lr: 7.2543e-06  max_mem: 49046M
Traceback (most recent call last):
  File "train_net2.py", line 377, in <module>
    launch(
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/launch.py", line 84, in launch
    main_func(*args)
  File "train_net2.py", line 371, in main
    return trainer.train()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/defaults.py", line 486, in train
    super().train(self.start_iter, self.max_iter)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/train_loop.py", line 156, in train
    self.after_step()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/train_loop.py", line 190, in after_step
    h.after_step()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/hooks.py", line 556, in after_step
    self._do_eval()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/hooks.py", line 529, in _do_eval
    results = self._func()
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/defaults.py", line 455, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/engine/defaults.py", line 621, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/evaluation/evaluator.py", line 172, in inference_on_dataset
    evaluator.process(inputs, outputs)
  File "/cpfs01/projects-HDD/pujianxiangmuzu_HDD/mr_22210240239/detectron2/detectron2/evaluation/sem_seg_evaluation.py", line 139, in process
    (self._num_classes + 1) * pred.reshape(-1) + gt.reshape(-1),
ValueError: operands could not be broadcast together with shapes (258048,) (239547,) 
