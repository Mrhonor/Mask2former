Loading config configs/7_datasets/Base-Cityscapes-SemanticSegmentation_snp.yaml with yaml.unsafe_load. Your machine may be at risk if the file contains malicious content.
Command Line Args: Namespace(config_file='configs/7_datasets/snp_bs16_90k.yaml', dist_url='tcp://127.0.0.1:51078', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/model_0009999.pth'], resume=False)
[03/11 13:10:58 detectron2]: Rank of current process: 0. World size: 1
[03/11 13:11:01 detectron2]: Environment info:
-------------------------------  --------------------------------------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.18 (default, Sep 11 2023, 13:40:15) [GCC 11.2.0]
numpy                            1.24.3
detectron2                       0.6 @/home1/marong/.conda/envs/mask2former/lib/python3.8/site-packages/detectron2
Compiler                         GCC 11.1
CUDA compiler                    CUDA 12.1
detectron2 arch flags            /home1/marong/.conda/envs/mask2former/lib/python3.8/site-packages/detectron2/_C.cpython-38-x86_64-linux-gnu.so
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.2.1 @/home1/marong/.conda/envs/mask2former/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0                            Tesla V100-SXM2-32GB (arch=7.0)
Driver version                   525.105.17
CUDA_HOME                        None - invalid!
Pillow                           8.4.0
torchvision                      0.17.1 @/home1/marong/.conda/envs/mask2former/lib/python3.8/site-packages/torchvision
torchvision arch flags           /home1/marong/.conda/envs/mask2former/lib/python3.8/site-packages/torchvision/_C.so
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.9.0
-------------------------------  --------------------------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.2 (Git Hash 2dc95a2ad0841e29db8b22fbccaf3e5da7992b01)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.1
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.9.2
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.2.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[03/11 13:11:01 detectron2]: Command line arguments: Namespace(config_file='configs/7_datasets/snp_bs16_90k.yaml', dist_url='tcp://127.0.0.1:51078', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['MODEL.WEIGHTS', 'output/model_0009999.pth'], resume=False)
[03/11 13:11:01 detectron2]: Contents of args.config_file=configs/7_datasets/snp_bs16_90k.yaml:
_BASE_: Base-Cityscapes-SemanticSegmentation_snp.yaml
MODEL:
  META_ARCHITECTURE: "HRNet_W48_ARCH"
  SEM_SEG_HEAD:
    NAME: "SemsegModel"
    OUTPUT_FEAT_DIM: 512
    BN_TYPE: "torchbn"
  GNN:
    NFEAT: 1024
    NFEAT_OUT: 512
    nfeat_adj: 256
    adj_feat_dim: 128
    dropout_rate: 0.5
    threshold_value: 0.95
    calc_bipartite: False
    output_max_adj: True
    output_softmax_adj: True
    uot_ratio: 1.01
    mse_or_adv: "None"
    GNN_type: "GSAGE"
    with_datasets_aux: False
    init_stage_iters: 10000
    isGumbelSoftmax: False
    GNN_ITERS: 20000
    SEG_ITERS: 20000
    FIRST_STAGE_GNN_ITERS: 15000
    INIT_ADJ_PATH: "output/init_adj_7_datasets.pt"
[03/11 13:11:01 detectron2]: Running with full config:
CUDNN_BENCHMARK: false
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 4
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  CONFIGER: configs/ltbgnn_7_datasets_snp.json
  DATASETS_CATS:
  - 19
  - 64
  - 37
  - 19
  - 26
  - 150
  - 133
  EVAL: []
  IGNORE_LB: 255
  NUM_UNIFY_CLASS: 448
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - cs_sem_seg_val
  - sunrgbd_sem_seg_val
  - bdd_sem_seg_val
  - idd_sem_seg_val
  - ade_sem_seg_val
  - coco_sem_seg_val
  TRAIN:
  - cs_sem_seg_train
  - mapi_sem_seg_train
  - sunrgbd_sem_seg_train
  - bdd_sem_seg_train
  - idd_sem_seg_train
  - ade_sem_seg_train
  - coco_sem_seg_train
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 768
    - 768
    TYPE: absolute
  DATASET_MAPPER_NAME: DALI
  FORMAT: RGB
  IMAGE_SIZE: 1024
  MASK_FORMAT: polygon
  MAX_SCALE: 2.0
  MAX_SIZE_TEST: 4096
  MAX_SIZE_TRAIN: 4096
  MIN_SCALE: 0.1
  MIN_SIZE_TEST: 512
  MIN_SIZE_TRAIN:
  - 256
  - 307
  - 358
  - 409
  - 460
  - 512
  - 563
  - 614
  - 665
  - 716
  - 768
  - 819
  - 870
  - 921
  - 972
  - 1024
  - 1075
  - 1126
  - 1177
  - 1228
  - 1280
  - 1331
  - 1382
  - 1433
  - 1484
  - 1536
  - 1587
  - 1638
  - 1689
  - 1740
  - 1792
  - 1843
  - 1894
  - 1945
  - 1996
  - 2048
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 768
LOSS:
  OHEM_THRESH: 0.7
  WITH_ADJ_LOSS: false
  WITH_ORTH_LOSS: false
  WITH_SPA_LOSS: true
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  AUX_MODE: train
  BACKBONE:
    FREEZE_AT: 0
    NAME: SnpResNet
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  GNN:
    FIRST_STAGE_GNN_ITERS: 15000
    GNN_ITERS: 20000
    GNN_MODEL_NAME: Learnable_Topology_BGNN
    GNN_type: GSAGE
    INIT_ADJ_PATH: output/init_adj_7_datasets.pt
    NFEAT: 1024
    NFEAT_OUT: 512
    N_POINTS: 12455
    SEG_ITERS: 20000
    adj_feat_dim: 128
    calc_bipartite: false
    dropout_rate: 0.5
    init_stage_iters: 10000
    isGumbelSoftmax: false
    mse_or_adv: null
    nfeat_adj: 256
    output_max_adj: true
    output_softmax_adj: true
    threshold_value: 0.95
    uot_ratio: 1.01
    with_datasets_aux: false
  HRNET:
    BN_TYPE: torchbn
    DROP_STAGE4: false
    FULL_RES_STEM: false
    HRNET_CFG: hrnet48
    KEEP_IMAGENET_HEAD: false
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_ON: false
  META_ARCHITECTURE: HRNet_W48_ARCH
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PRETRAINING: true
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    BN_TYPE: torchbn
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - p2
    - p3
    - p4
    - p5
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: SemsegModel
    NORM: GN
    NUM_CLASSES: 54
    OUTPUT_FEAT_DIM: 512
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WITH_DATASETS_AUX: false
  WEIGHTS: output/model_0009999.pth
  WITH_DATASETS_AUX: false
OUTPUT_DIR: ./output
SEED: -1
SOLVER:
  AMP:
    ENABLED: true
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 6
  LR_SCHEDULER_NAME: WarmupPolyLR
  MAX_ITER: 100000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.05
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4096
    MIN_SIZES:
    - 256
    - 384
    - 512
    - 640
    - 768
    - 896
    - 512
    - 768
    - 1024
    - 1280
    - 1536
    - 1792
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 10000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0

[03/11 13:11:01 detectron2]: Full config saved to ./output/config.yaml
[03/11 13:11:01 d2.utils.env]: Using a generated random seed 1482469
torch.Size([448, 1024])
[03/11 13:11:36 d2.engine.defaults]: Model:
HRNet_W48_ARCH(
  (backbone): SnpResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): ModuleList(
      (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): ModuleList(
          (0-2): 3 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (relu_inp): ReLU(inplace=True)
        (relu): ReLU()
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): ModuleList(
          (0-2): 3 x BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (upsample_bottlenecks): ModuleList(
      (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (3): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
    )
    (upsample_blends): ModuleList(
      (0-4): 5 x _UpsampleBlend(
        (blend_conv): _BNReluConv(
          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        )
      )
    )
  )
  (gnn_model): Learnable_Topology_BGNN(
    (linear_before): Linear(in_features=1024, out_features=512, bias=True)
    (linear_adj): Linear(in_features=512, out_features=256, bias=True)
    (relu): ReLU()
    (GCN_layer1): GSAGE(
      (gc1): GraphSAGEConvolution (512 -> 512)
    )
    (GCN_layer2): GSAGE(
      (gc1): GraphSAGEConvolution (512 -> 512)
    )
    (GCN_layer3): GSAGE(
      (gc1): GraphSAGEConvolution (512 -> 512)
    )
    (linear1): Linear(in_features=512, out_features=512, bias=True)
    (linear2): Linear(in_features=512, out_features=128, bias=True)
  )
  (proj_head): SemsegModel(
    (logits): _BNReluConv(
      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))
    )
    (bipartite_graphs): ParameterList(
        (0): Parameter containing: [torch.float32 of size 19x448 (cuda:0)]
        (1): Parameter containing: [torch.float32 of size 64x448 (cuda:0)]
        (2): Parameter containing: [torch.float32 of size 37x448 (cuda:0)]
        (3): Parameter containing: [torch.float32 of size 19x448 (cuda:0)]
        (4): Parameter containing: [torch.float32 of size 26x448 (cuda:0)]
        (5): Parameter containing: [torch.float32 of size 150x448 (cuda:0)]
        (6): Parameter containing: [torch.float32 of size 133x448 (cuda:0)]
    )
  )
  (criterion): OhemCELoss(
    (criteria): CrossEntropyLoss()
  )
  (celoss): CrossEntropyLoss()
  (MSE_sum_loss): MSELoss()
)
[03/11 13:11:36 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from output/model_0009999.pth ...
[03/11 13:11:36 fvcore.common.checkpoint]: [Checkpointer] Loading from output/model_0009999.pth ...
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa513bc70>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa513b8b0>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa513b520>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa513b280>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520bf70>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520bc10>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520b9d0>, RandomFlip()]
[03/11 13:11:36 mask2former.data.dataloader.DaliDataLoader]: evaluate cs_sem_seg_val
[03/11 13:11:36 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/11 13:11:36 d2.data.common]: Serializing 500 elements to byte tensors and concatenating them all ...
[03/11 13:11:36 d2.data.common]: Serialized dataset takes 0.13 MiB
[03/11 13:11:36 d2.evaluation.evaluator]: Start inference on 500 batches
[03/11 13:11:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:46 d2.evaluation.evaluator]: Inference done 11/500. Dataloading: 0.0103 s/iter. Inference: 0.0683 s/iter. Eval: 0.3295 s/iter. Total: 0.4081 s/iter. ETA=0:03:19
[03/11 13:11:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:51 d2.evaluation.evaluator]: Inference done 25/500. Dataloading: 0.0093 s/iter. Inference: 0.0697 s/iter. Eval: 0.3121 s/iter. Total: 0.3911 s/iter. ETA=0:03:05
[03/11 13:11:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:57 d2.evaluation.evaluator]: Inference done 39/500. Dataloading: 0.0103 s/iter. Inference: 0.0709 s/iter. Eval: 0.3030 s/iter. Total: 0.3844 s/iter. ETA=0:02:57
[03/11 13:11:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:11:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:02 d2.evaluation.evaluator]: Inference done 53/500. Dataloading: 0.0096 s/iter. Inference: 0.0673 s/iter. Eval: 0.3024 s/iter. Total: 0.3794 s/iter. ETA=0:02:49
[03/11 13:12:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:07 d2.evaluation.evaluator]: Inference done 66/500. Dataloading: 0.0096 s/iter. Inference: 0.0701 s/iter. Eval: 0.3016 s/iter. Total: 0.3814 s/iter. ETA=0:02:45
[03/11 13:12:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:12 d2.evaluation.evaluator]: Inference done 80/500. Dataloading: 0.0100 s/iter. Inference: 0.0706 s/iter. Eval: 0.2969 s/iter. Total: 0.3776 s/iter. ETA=0:02:38
[03/11 13:12:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:17 d2.evaluation.evaluator]: Inference done 93/500. Dataloading: 0.0102 s/iter. Inference: 0.0721 s/iter. Eval: 0.2983 s/iter. Total: 0.3807 s/iter. ETA=0:02:34
[03/11 13:12:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:22 d2.evaluation.evaluator]: Inference done 107/500. Dataloading: 0.0104 s/iter. Inference: 0.0716 s/iter. Eval: 0.2965 s/iter. Total: 0.3786 s/iter. ETA=0:02:28
[03/11 13:12:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:28 d2.evaluation.evaluator]: Inference done 121/500. Dataloading: 0.0104 s/iter. Inference: 0.0724 s/iter. Eval: 0.2966 s/iter. Total: 0.3796 s/iter. ETA=0:02:23
[03/11 13:12:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:33 d2.evaluation.evaluator]: Inference done 136/500. Dataloading: 0.0102 s/iter. Inference: 0.0718 s/iter. Eval: 0.2945 s/iter. Total: 0.3766 s/iter. ETA=0:02:17
[03/11 13:12:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:38 d2.evaluation.evaluator]: Inference done 150/500. Dataloading: 0.0101 s/iter. Inference: 0.0721 s/iter. Eval: 0.2942 s/iter. Total: 0.3765 s/iter. ETA=0:02:11
[03/11 13:12:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:43 d2.evaluation.evaluator]: Inference done 164/500. Dataloading: 0.0103 s/iter. Inference: 0.0720 s/iter. Eval: 0.2944 s/iter. Total: 0.3768 s/iter. ETA=0:02:06
[03/11 13:12:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:49 d2.evaluation.evaluator]: Inference done 179/500. Dataloading: 0.0102 s/iter. Inference: 0.0727 s/iter. Eval: 0.2924 s/iter. Total: 0.3754 s/iter. ETA=0:02:00
[03/11 13:12:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:54 d2.evaluation.evaluator]: Inference done 192/500. Dataloading: 0.0102 s/iter. Inference: 0.0731 s/iter. Eval: 0.2927 s/iter. Total: 0.3761 s/iter. ETA=0:01:55
[03/11 13:12:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:59 d2.evaluation.evaluator]: Inference done 206/500. Dataloading: 0.0101 s/iter. Inference: 0.0727 s/iter. Eval: 0.2924 s/iter. Total: 0.3753 s/iter. ETA=0:01:50
[03/11 13:12:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:12:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:04 d2.evaluation.evaluator]: Inference done 220/500. Dataloading: 0.0100 s/iter. Inference: 0.0719 s/iter. Eval: 0.2922 s/iter. Total: 0.3742 s/iter. ETA=0:01:44
[03/11 13:13:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:09 d2.evaluation.evaluator]: Inference done 234/500. Dataloading: 0.0100 s/iter. Inference: 0.0721 s/iter. Eval: 0.2919 s/iter. Total: 0.3742 s/iter. ETA=0:01:39
[03/11 13:13:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:14 d2.evaluation.evaluator]: Inference done 247/500. Dataloading: 0.0101 s/iter. Inference: 0.0724 s/iter. Eval: 0.2924 s/iter. Total: 0.3750 s/iter. ETA=0:01:34
[03/11 13:13:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:19 d2.evaluation.evaluator]: Inference done 261/500. Dataloading: 0.0100 s/iter. Inference: 0.0722 s/iter. Eval: 0.2921 s/iter. Total: 0.3745 s/iter. ETA=0:01:29
[03/11 13:13:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:25 d2.evaluation.evaluator]: Inference done 275/500. Dataloading: 0.0100 s/iter. Inference: 0.0723 s/iter. Eval: 0.2922 s/iter. Total: 0.3745 s/iter. ETA=0:01:24
[03/11 13:13:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:30 d2.evaluation.evaluator]: Inference done 290/500. Dataloading: 0.0100 s/iter. Inference: 0.0730 s/iter. Eval: 0.2905 s/iter. Total: 0.3735 s/iter. ETA=0:01:18
[03/11 13:13:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:35 d2.evaluation.evaluator]: Inference done 305/500. Dataloading: 0.0098 s/iter. Inference: 0.0728 s/iter. Eval: 0.2894 s/iter. Total: 0.3720 s/iter. ETA=0:01:12
[03/11 13:13:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:40 d2.evaluation.evaluator]: Inference done 319/500. Dataloading: 0.0097 s/iter. Inference: 0.0732 s/iter. Eval: 0.2886 s/iter. Total: 0.3716 s/iter. ETA=0:01:07
[03/11 13:13:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:45 d2.evaluation.evaluator]: Inference done 333/500. Dataloading: 0.0096 s/iter. Inference: 0.0731 s/iter. Eval: 0.2887 s/iter. Total: 0.3715 s/iter. ETA=0:01:02
[03/11 13:13:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:50 d2.evaluation.evaluator]: Inference done 346/500. Dataloading: 0.0096 s/iter. Inference: 0.0733 s/iter. Eval: 0.2891 s/iter. Total: 0.3721 s/iter. ETA=0:00:57
[03/11 13:13:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:56 d2.evaluation.evaluator]: Inference done 361/500. Dataloading: 0.0094 s/iter. Inference: 0.0729 s/iter. Eval: 0.2883 s/iter. Total: 0.3708 s/iter. ETA=0:00:51
[03/11 13:13:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:13:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:01 d2.evaluation.evaluator]: Inference done 376/500. Dataloading: 0.0094 s/iter. Inference: 0.0733 s/iter. Eval: 0.2874 s/iter. Total: 0.3702 s/iter. ETA=0:00:45
[03/11 13:14:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:06 d2.evaluation.evaluator]: Inference done 391/500. Dataloading: 0.0094 s/iter. Inference: 0.0732 s/iter. Eval: 0.2866 s/iter. Total: 0.3692 s/iter. ETA=0:00:40
[03/11 13:14:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:11 d2.evaluation.evaluator]: Inference done 405/500. Dataloading: 0.0093 s/iter. Inference: 0.0730 s/iter. Eval: 0.2867 s/iter. Total: 0.3691 s/iter. ETA=0:00:35
[03/11 13:14:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:16 d2.evaluation.evaluator]: Inference done 419/500. Dataloading: 0.0093 s/iter. Inference: 0.0732 s/iter. Eval: 0.2864 s/iter. Total: 0.3690 s/iter. ETA=0:00:29
[03/11 13:14:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:21 d2.evaluation.evaluator]: Inference done 434/500. Dataloading: 0.0092 s/iter. Inference: 0.0734 s/iter. Eval: 0.2854 s/iter. Total: 0.3682 s/iter. ETA=0:00:24
[03/11 13:14:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:27 d2.evaluation.evaluator]: Inference done 448/500. Dataloading: 0.0092 s/iter. Inference: 0.0736 s/iter. Eval: 0.2853 s/iter. Total: 0.3682 s/iter. ETA=0:00:19
[03/11 13:14:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:32 d2.evaluation.evaluator]: Inference done 462/500. Dataloading: 0.0093 s/iter. Inference: 0.0741 s/iter. Eval: 0.2848 s/iter. Total: 0.3682 s/iter. ETA=0:00:13
[03/11 13:14:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:37 d2.evaluation.evaluator]: Inference done 477/500. Dataloading: 0.0092 s/iter. Inference: 0.0740 s/iter. Eval: 0.2843 s/iter. Total: 0.3676 s/iter. ETA=0:00:08
[03/11 13:14:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:42 d2.evaluation.evaluator]: Inference done 492/500. Dataloading: 0.0091 s/iter. Inference: 0.0741 s/iter. Eval: 0.2835 s/iter. Total: 0.3668 s/iter. ETA=0:00:02
[03/11 13:14:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1024, 2048])
[03/11 13:14:45 d2.evaluation.evaluator]: Total inference time: 0:03:01.272885 (0.366208 s / iter per device, on 1 devices)
[03/11 13:14:45 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:36 (0.074104 s / iter per device, on 1 devices)
[03/11 13:14:45 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 23.84087487864908, 'fwIoU': 71.56028454679927, 'IoU-road': 88.06286067164011, 'BoundaryIoU-road': 78.57418966811316, 'min(IoU, B-Iou)-road': 78.57418966811316, 'IoU-sidewalk': 28.370106388805, 'BoundaryIoU-sidewalk': 18.783358221873996, 'min(IoU, B-Iou)-sidewalk': 18.783358221873996, 'IoU-building': 73.81724998181409, 'BoundaryIoU-building': 54.85608060909134, 'min(IoU, B-Iou)-building': 54.85608060909134, 'IoU-wall': 0.03293783384573975, 'BoundaryIoU-wall': 2.611795186718162, 'min(IoU, B-Iou)-wall': 0.03293783384573975, 'IoU-fence': 0.25499178209508633, 'BoundaryIoU-fence': 0.5964218996672608, 'min(IoU, B-Iou)-fence': 0.25499178209508633, 'IoU-pole': 2.6140425559688367, 'BoundaryIoU-pole': 7.861022002652783, 'min(IoU, B-Iou)-pole': 2.6140425559688367, 'IoU-traffic light': 0.0, 'BoundaryIoU-traffic light': 36.124709543985304, 'min(IoU, B-Iou)-traffic light': 0.0, 'IoU-traffic sign': 0.0, 'BoundaryIoU-traffic sign': 9.829585816413914, 'min(IoU, B-Iou)-traffic sign': 0.0, 'IoU-vegetation': 77.83815687940482, 'BoundaryIoU-vegetation': 55.80560371619867, 'min(IoU, B-Iou)-vegetation': 55.80560371619867, 'IoU-terrain': 21.083939926488114, 'BoundaryIoU-terrain': 9.326868728838312, 'min(IoU, B-Iou)-terrain': 9.326868728838312, 'IoU-sky': 86.19591017169694, 'BoundaryIoU-sky': 55.80121737727557, 'min(IoU, B-Iou)-sky': 55.80121737727557, 'IoU-person': 13.95129266999573, 'BoundaryIoU-person': 24.73339038073975, 'min(IoU, B-Iou)-person': 13.95129266999573, 'IoU-rider': 0.0, 'BoundaryIoU-rider': 3.012721423460669, 'min(IoU, B-Iou)-rider': 0.0, 'IoU-car': 59.972246134594776, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-truck': 0.0, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-bus': 0.0002244012833509395, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-train': 0.0, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-motorcycle': 0.0008221869899871329, 'BoundaryIoU-motorcycle': 0.0, 'min(IoU, B-Iou)-motorcycle': 0.0, 'IoU-bicycle': 0.7818411097099622, 'BoundaryIoU-bicycle': 0.0, 'min(IoU, B-Iou)-bicycle': 0.0, 'mACC': 28.558569996596077, 'pACC': 83.22082992548947, 'ACC-road': 97.50022055077173, 'ACC-sidewalk': 34.732709161692455, 'ACC-building': 91.02405575590082, 'ACC-wall': 0.034083896292909324, 'ACC-fence': 0.2583262762845676, 'ACC-pole': 2.6590039512536108, 'ACC-traffic light': 0.0, 'ACC-traffic sign': 0.0, 'ACC-vegetation': 87.41433400984555, 'ACC-terrain': 27.432103182336693, 'ACC-sky': 91.73424242541455, 'ACC-person': 17.650295553163133, 'ACC-rider': 0.0, 'ACC-car': 91.38227740535633, 'ACC-truck': 0.0, 'ACC-bus': 0.00022452232874559374, 'ACC-train': 0.0, 'ACC-motorcycle': 0.0008225769966342892, 'ACC-bicycle': 0.7901306676876293})])
[03/11 13:14:45 d2.engine.defaults]: Evaluation results for cs_sem_seg_val in csv format:
[03/11 13:14:45 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/11 13:14:45 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/11 13:14:45 d2.evaluation.testing]: copypaste: 23.8409,71.5603,28.5586,83.2208
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa508eaf0>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa508ed90>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa508e430>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa508e610>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa508ea00>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa509be20>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa509bdf0>, RandomFlip()]
[03/11 13:14:45 mask2former.data.dataloader.DaliDataLoader]: evaluate sunrgbd_sem_seg_val
[03/11 13:14:45 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/11 13:14:45 d2.data.common]: Serializing 5050 elements to byte tensors and concatenating them all ...
[03/11 13:14:45 d2.data.common]: Serialized dataset takes 0.81 MiB
[03/11 13:14:45 d2.evaluation.evaluator]: Start inference on 5050 batches
[03/11 13:14:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:48 d2.evaluation.evaluator]: Inference done 11/5050. Dataloading: 0.0022 s/iter. Inference: 0.0339 s/iter. Eval: 0.0696 s/iter. Total: 0.1057 s/iter. ETA=0:08:52
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:53 d2.evaluation.evaluator]: Inference done 57/5050. Dataloading: 0.0056 s/iter. Inference: 0.0400 s/iter. Eval: 0.0629 s/iter. Total: 0.1086 s/iter. ETA=0:09:02
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:58 d2.evaluation.evaluator]: Inference done 112/5050. Dataloading: 0.0054 s/iter. Inference: 0.0388 s/iter. Eval: 0.0556 s/iter. Total: 0.0999 s/iter. ETA=0:08:13
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:14:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:03 d2.evaluation.evaluator]: Inference done 164/5050. Dataloading: 0.0061 s/iter. Inference: 0.0389 s/iter. Eval: 0.0542 s/iter. Total: 0.0992 s/iter. ETA=0:08:04
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:08 d2.evaluation.evaluator]: Inference done 212/5050. Dataloading: 0.0063 s/iter. Inference: 0.0392 s/iter. Eval: 0.0548 s/iter. Total: 0.1004 s/iter. ETA=0:08:05
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:13 d2.evaluation.evaluator]: Inference done 257/5050. Dataloading: 0.0064 s/iter. Inference: 0.0392 s/iter. Eval: 0.0567 s/iter. Total: 0.1025 s/iter. ETA=0:08:11
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:18 d2.evaluation.evaluator]: Inference done 304/5050. Dataloading: 0.0065 s/iter. Inference: 0.0392 s/iter. Eval: 0.0573 s/iter. Total: 0.1032 s/iter. ETA=0:08:09
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:23 d2.evaluation.evaluator]: Inference done 360/5050. Dataloading: 0.0064 s/iter. Inference: 0.0386 s/iter. Eval: 0.0561 s/iter. Total: 0.1012 s/iter. ETA=0:07:54
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:28 d2.evaluation.evaluator]: Inference done 408/5050. Dataloading: 0.0064 s/iter. Inference: 0.0385 s/iter. Eval: 0.0565 s/iter. Total: 0.1016 s/iter. ETA=0:07:51
[03/11 13:15:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:33 d2.evaluation.evaluator]: Inference done 455/5050. Dataloading: 0.0064 s/iter. Inference: 0.0387 s/iter. Eval: 0.0569 s/iter. Total: 0.1022 s/iter. ETA=0:07:49
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:38 d2.evaluation.evaluator]: Inference done 507/5050. Dataloading: 0.0065 s/iter. Inference: 0.0388 s/iter. Eval: 0.0562 s/iter. Total: 0.1016 s/iter. ETA=0:07:41
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:43 d2.evaluation.evaluator]: Inference done 558/5050. Dataloading: 0.0066 s/iter. Inference: 0.0388 s/iter. Eval: 0.0559 s/iter. Total: 0.1014 s/iter. ETA=0:07:35
[03/11 13:15:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:48 d2.evaluation.evaluator]: Inference done 599/5050. Dataloading: 0.0065 s/iter. Inference: 0.0391 s/iter. Eval: 0.0571 s/iter. Total: 0.1029 s/iter. ETA=0:07:37
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:53 d2.evaluation.evaluator]: Inference done 648/5050. Dataloading: 0.0064 s/iter. Inference: 0.0392 s/iter. Eval: 0.0571 s/iter. Total: 0.1029 s/iter. ETA=0:07:32
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:15:59 d2.evaluation.evaluator]: Inference done 693/5050. Dataloading: 0.0064 s/iter. Inference: 0.0393 s/iter. Eval: 0.0578 s/iter. Total: 0.1036 s/iter. ETA=0:07:31
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:15:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:04 d2.evaluation.evaluator]: Inference done 741/5050. Dataloading: 0.0064 s/iter. Inference: 0.0394 s/iter. Eval: 0.0579 s/iter. Total: 0.1038 s/iter. ETA=0:07:27
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:09 d2.evaluation.evaluator]: Inference done 789/5050. Dataloading: 0.0064 s/iter. Inference: 0.0395 s/iter. Eval: 0.0579 s/iter. Total: 0.1040 s/iter. ETA=0:07:22
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:14 d2.evaluation.evaluator]: Inference done 836/5050. Dataloading: 0.0066 s/iter. Inference: 0.0395 s/iter. Eval: 0.0581 s/iter. Total: 0.1042 s/iter. ETA=0:07:19
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:19 d2.evaluation.evaluator]: Inference done 884/5050. Dataloading: 0.0065 s/iter. Inference: 0.0396 s/iter. Eval: 0.0580 s/iter. Total: 0.1043 s/iter. ETA=0:07:14
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:24 d2.evaluation.evaluator]: Inference done 934/5050. Dataloading: 0.0066 s/iter. Inference: 0.0395 s/iter. Eval: 0.0579 s/iter. Total: 0.1041 s/iter. ETA=0:07:08
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:29 d2.evaluation.evaluator]: Inference done 987/5050. Dataloading: 0.0065 s/iter. Inference: 0.0394 s/iter. Eval: 0.0576 s/iter. Total: 0.1037 s/iter. ETA=0:07:01
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:34 d2.evaluation.evaluator]: Inference done 1036/5050. Dataloading: 0.0066 s/iter. Inference: 0.0394 s/iter. Eval: 0.0576 s/iter. Total: 0.1036 s/iter. ETA=0:06:56
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:39 d2.evaluation.evaluator]: Inference done 1082/5050. Dataloading: 0.0066 s/iter. Inference: 0.0395 s/iter. Eval: 0.0577 s/iter. Total: 0.1039 s/iter. ETA=0:06:52
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:44 d2.evaluation.evaluator]: Inference done 1126/5050. Dataloading: 0.0067 s/iter. Inference: 0.0396 s/iter. Eval: 0.0578 s/iter. Total: 0.1043 s/iter. ETA=0:06:49
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:49 d2.evaluation.evaluator]: Inference done 1173/5050. Dataloading: 0.0068 s/iter. Inference: 0.0396 s/iter. Eval: 0.0578 s/iter. Total: 0.1044 s/iter. ETA=0:06:44
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:54 d2.evaluation.evaluator]: Inference done 1221/5050. Dataloading: 0.0068 s/iter. Inference: 0.0395 s/iter. Eval: 0.0580 s/iter. Total: 0.1044 s/iter. ETA=0:06:39
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:16:59 d2.evaluation.evaluator]: Inference done 1264/5050. Dataloading: 0.0068 s/iter. Inference: 0.0397 s/iter. Eval: 0.0582 s/iter. Total: 0.1049 s/iter. ETA=0:06:37
[03/11 13:16:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:04 d2.evaluation.evaluator]: Inference done 1312/5050. Dataloading: 0.0070 s/iter. Inference: 0.0397 s/iter. Eval: 0.0581 s/iter. Total: 0.1049 s/iter. ETA=0:06:32
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:09 d2.evaluation.evaluator]: Inference done 1365/5050. Dataloading: 0.0069 s/iter. Inference: 0.0396 s/iter. Eval: 0.0579 s/iter. Total: 0.1045 s/iter. ETA=0:06:25
[03/11 13:17:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:14 d2.evaluation.evaluator]: Inference done 1414/5050. Dataloading: 0.0069 s/iter. Inference: 0.0396 s/iter. Eval: 0.0579 s/iter. Total: 0.1045 s/iter. ETA=0:06:19
[03/11 13:17:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:20 d2.evaluation.evaluator]: Inference done 1454/5050. Dataloading: 0.0070 s/iter. Inference: 0.0398 s/iter. Eval: 0.0581 s/iter. Total: 0.1051 s/iter. ETA=0:06:17
[03/11 13:17:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:25 d2.evaluation.evaluator]: Inference done 1494/5050. Dataloading: 0.0072 s/iter. Inference: 0.0400 s/iter. Eval: 0.0584 s/iter. Total: 0.1057 s/iter. ETA=0:06:15
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:30 d2.evaluation.evaluator]: Inference done 1537/5050. Dataloading: 0.0072 s/iter. Inference: 0.0401 s/iter. Eval: 0.0586 s/iter. Total: 0.1060 s/iter. ETA=0:06:12
[03/11 13:17:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:35 d2.evaluation.evaluator]: Inference done 1580/5050. Dataloading: 0.0073 s/iter. Inference: 0.0402 s/iter. Eval: 0.0588 s/iter. Total: 0.1063 s/iter. ETA=0:06:08
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:40 d2.evaluation.evaluator]: Inference done 1625/5050. Dataloading: 0.0073 s/iter. Inference: 0.0402 s/iter. Eval: 0.0590 s/iter. Total: 0.1065 s/iter. ETA=0:06:04
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:45 d2.evaluation.evaluator]: Inference done 1670/5050. Dataloading: 0.0073 s/iter. Inference: 0.0402 s/iter. Eval: 0.0591 s/iter. Total: 0.1067 s/iter. ETA=0:06:00
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:50 d2.evaluation.evaluator]: Inference done 1716/5050. Dataloading: 0.0073 s/iter. Inference: 0.0403 s/iter. Eval: 0.0591 s/iter. Total: 0.1068 s/iter. ETA=0:05:55
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:55 d2.evaluation.evaluator]: Inference done 1768/5050. Dataloading: 0.0072 s/iter. Inference: 0.0402 s/iter. Eval: 0.0590 s/iter. Total: 0.1065 s/iter. ETA=0:05:49
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:17:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:00 d2.evaluation.evaluator]: Inference done 1816/5050. Dataloading: 0.0072 s/iter. Inference: 0.0402 s/iter. Eval: 0.0589 s/iter. Total: 0.1065 s/iter. ETA=0:05:44
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:05 d2.evaluation.evaluator]: Inference done 1861/5050. Dataloading: 0.0072 s/iter. Inference: 0.0403 s/iter. Eval: 0.0590 s/iter. Total: 0.1066 s/iter. ETA=0:05:39
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:10 d2.evaluation.evaluator]: Inference done 1907/5050. Dataloading: 0.0072 s/iter. Inference: 0.0402 s/iter. Eval: 0.0590 s/iter. Total: 0.1066 s/iter. ETA=0:05:35
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:15 d2.evaluation.evaluator]: Inference done 1958/5050. Dataloading: 0.0072 s/iter. Inference: 0.0402 s/iter. Eval: 0.0589 s/iter. Total: 0.1065 s/iter. ETA=0:05:29
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:20 d2.evaluation.evaluator]: Inference done 2000/5050. Dataloading: 0.0073 s/iter. Inference: 0.0402 s/iter. Eval: 0.0592 s/iter. Total: 0.1068 s/iter. ETA=0:05:25
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:25 d2.evaluation.evaluator]: Inference done 2043/5050. Dataloading: 0.0073 s/iter. Inference: 0.0403 s/iter. Eval: 0.0593 s/iter. Total: 0.1070 s/iter. ETA=0:05:21
[03/11 13:18:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:31 d2.evaluation.evaluator]: Inference done 2092/5050. Dataloading: 0.0073 s/iter. Inference: 0.0403 s/iter. Eval: 0.0592 s/iter. Total: 0.1070 s/iter. ETA=0:05:16
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:36 d2.evaluation.evaluator]: Inference done 2140/5050. Dataloading: 0.0074 s/iter. Inference: 0.0404 s/iter. Eval: 0.0591 s/iter. Total: 0.1069 s/iter. ETA=0:05:11
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:41 d2.evaluation.evaluator]: Inference done 2185/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0591 s/iter. Total: 0.1070 s/iter. ETA=0:05:06
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:46 d2.evaluation.evaluator]: Inference done 2228/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0592 s/iter. Total: 0.1072 s/iter. ETA=0:05:02
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:51 d2.evaluation.evaluator]: Inference done 2276/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0592 s/iter. Total: 0.1072 s/iter. ETA=0:04:57
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:56 d2.evaluation.evaluator]: Inference done 2318/5050. Dataloading: 0.0074 s/iter. Inference: 0.0406 s/iter. Eval: 0.0593 s/iter. Total: 0.1074 s/iter. ETA=0:04:53
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:18:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:01 d2.evaluation.evaluator]: Inference done 2370/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0591 s/iter. Total: 0.1072 s/iter. ETA=0:04:47
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:06 d2.evaluation.evaluator]: Inference done 2418/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0591 s/iter. Total: 0.1072 s/iter. ETA=0:04:42
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:11 d2.evaluation.evaluator]: Inference done 2465/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0591 s/iter. Total: 0.1072 s/iter. ETA=0:04:37
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:16 d2.evaluation.evaluator]: Inference done 2510/5050. Dataloading: 0.0074 s/iter. Inference: 0.0406 s/iter. Eval: 0.0592 s/iter. Total: 0.1073 s/iter. ETA=0:04:32
[03/11 13:19:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:21 d2.evaluation.evaluator]: Inference done 2560/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0592 s/iter. Total: 0.1072 s/iter. ETA=0:04:26
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:26 d2.evaluation.evaluator]: Inference done 2605/5050. Dataloading: 0.0074 s/iter. Inference: 0.0406 s/iter. Eval: 0.0592 s/iter. Total: 0.1073 s/iter. ETA=0:04:22
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:31 d2.evaluation.evaluator]: Inference done 2652/5050. Dataloading: 0.0074 s/iter. Inference: 0.0406 s/iter. Eval: 0.0593 s/iter. Total: 0.1073 s/iter. ETA=0:04:17
[03/11 13:19:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:36 d2.evaluation.evaluator]: Inference done 2701/5050. Dataloading: 0.0074 s/iter. Inference: 0.0405 s/iter. Eval: 0.0592 s/iter. Total: 0.1072 s/iter. ETA=0:04:11
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:41 d2.evaluation.evaluator]: Inference done 2744/5050. Dataloading: 0.0074 s/iter. Inference: 0.0406 s/iter. Eval: 0.0593 s/iter. Total: 0.1074 s/iter. ETA=0:04:07
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:46 d2.evaluation.evaluator]: Inference done 2788/5050. Dataloading: 0.0073 s/iter. Inference: 0.0407 s/iter. Eval: 0.0593 s/iter. Total: 0.1075 s/iter. ETA=0:04:03
[03/11 13:19:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:51 d2.evaluation.evaluator]: Inference done 2836/5050. Dataloading: 0.0073 s/iter. Inference: 0.0407 s/iter. Eval: 0.0593 s/iter. Total: 0.1075 s/iter. ETA=0:03:57
[03/11 13:19:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:57 d2.evaluation.evaluator]: Inference done 2882/5050. Dataloading: 0.0073 s/iter. Inference: 0.0407 s/iter. Eval: 0.0594 s/iter. Total: 0.1075 s/iter. ETA=0:03:53
[03/11 13:19:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:19:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:02 d2.evaluation.evaluator]: Inference done 2927/5050. Dataloading: 0.0073 s/iter. Inference: 0.0408 s/iter. Eval: 0.0594 s/iter. Total: 0.1076 s/iter. ETA=0:03:48
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:07 d2.evaluation.evaluator]: Inference done 2970/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1078 s/iter. ETA=0:03:44
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:12 d2.evaluation.evaluator]: Inference done 3019/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1077 s/iter. ETA=0:03:38
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:17 d2.evaluation.evaluator]: Inference done 3068/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0592 s/iter. Total: 0.1076 s/iter. ETA=0:03:33
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:22 d2.evaluation.evaluator]: Inference done 3111/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0593 s/iter. Total: 0.1078 s/iter. ETA=0:03:28
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:27 d2.evaluation.evaluator]: Inference done 3155/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0593 s/iter. Total: 0.1078 s/iter. ETA=0:03:24
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:32 d2.evaluation.evaluator]: Inference done 3200/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0593 s/iter. Total: 0.1079 s/iter. ETA=0:03:19
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:37 d2.evaluation.evaluator]: Inference done 3248/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0593 s/iter. Total: 0.1079 s/iter. ETA=0:03:14
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:42 d2.evaluation.evaluator]: Inference done 3297/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0593 s/iter. Total: 0.1078 s/iter. ETA=0:03:08
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:47 d2.evaluation.evaluator]: Inference done 3341/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0593 s/iter. Total: 0.1078 s/iter. ETA=0:03:04
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:52 d2.evaluation.evaluator]: Inference done 3382/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0595 s/iter. Total: 0.1080 s/iter. ETA=0:03:00
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:57 d2.evaluation.evaluator]: Inference done 3431/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0595 s/iter. Total: 0.1080 s/iter. ETA=0:02:54
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:20:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:02 d2.evaluation.evaluator]: Inference done 3473/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0596 s/iter. Total: 0.1081 s/iter. ETA=0:02:50
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:07 d2.evaluation.evaluator]: Inference done 3521/5050. Dataloading: 0.0073 s/iter. Inference: 0.0411 s/iter. Eval: 0.0596 s/iter. Total: 0.1081 s/iter. ETA=0:02:45
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:12 d2.evaluation.evaluator]: Inference done 3570/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0595 s/iter. Total: 0.1080 s/iter. ETA=0:02:39
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:17 d2.evaluation.evaluator]: Inference done 3620/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0595 s/iter. Total: 0.1079 s/iter. ETA=0:02:34
[03/11 13:21:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:22 d2.evaluation.evaluator]: Inference done 3671/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0595 s/iter. Total: 0.1078 s/iter. ETA=0:02:28
[03/11 13:21:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:27 d2.evaluation.evaluator]: Inference done 3719/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1078 s/iter. ETA=0:02:23
[03/11 13:21:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:33 d2.evaluation.evaluator]: Inference done 3767/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1077 s/iter. ETA=0:02:18
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:38 d2.evaluation.evaluator]: Inference done 3811/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0595 s/iter. Total: 0.1079 s/iter. ETA=0:02:13
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:43 d2.evaluation.evaluator]: Inference done 3862/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0594 s/iter. Total: 0.1077 s/iter. ETA=0:02:07
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:48 d2.evaluation.evaluator]: Inference done 3910/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0593 s/iter. Total: 0.1077 s/iter. ETA=0:02:02
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:53 d2.evaluation.evaluator]: Inference done 3954/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0594 s/iter. Total: 0.1078 s/iter. ETA=0:01:58
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:58 d2.evaluation.evaluator]: Inference done 3999/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0595 s/iter. Total: 0.1078 s/iter. ETA=0:01:53
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:21:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:21:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:03 d2.evaluation.evaluator]: Inference done 4047/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0595 s/iter. Total: 0.1078 s/iter. ETA=0:01:48
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:08 d2.evaluation.evaluator]: Inference done 4094/5050. Dataloading: 0.0073 s/iter. Inference: 0.0410 s/iter. Eval: 0.0595 s/iter. Total: 0.1078 s/iter. ETA=0:01:43
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:13 d2.evaluation.evaluator]: Inference done 4143/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1078 s/iter. ETA=0:01:37
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:18 d2.evaluation.evaluator]: Inference done 4195/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1076 s/iter. ETA=0:01:32
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:23 d2.evaluation.evaluator]: Inference done 4244/5050. Dataloading: 0.0073 s/iter. Inference: 0.0408 s/iter. Eval: 0.0594 s/iter. Total: 0.1076 s/iter. ETA=0:01:26
[03/11 13:22:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:28 d2.evaluation.evaluator]: Inference done 4290/5050. Dataloading: 0.0073 s/iter. Inference: 0.0408 s/iter. Eval: 0.0594 s/iter. Total: 0.1076 s/iter. ETA=0:01:21
[03/11 13:22:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:33 d2.evaluation.evaluator]: Inference done 4337/5050. Dataloading: 0.0073 s/iter. Inference: 0.0409 s/iter. Eval: 0.0594 s/iter. Total: 0.1076 s/iter. ETA=0:01:16
[03/11 13:22:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:38 d2.evaluation.evaluator]: Inference done 4392/5050. Dataloading: 0.0073 s/iter. Inference: 0.0408 s/iter. Eval: 0.0592 s/iter. Total: 0.1074 s/iter. ETA=0:01:10
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:44 d2.evaluation.evaluator]: Inference done 4440/5050. Dataloading: 0.0073 s/iter. Inference: 0.0408 s/iter. Eval: 0.0592 s/iter. Total: 0.1074 s/iter. ETA=0:01:05
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:49 d2.evaluation.evaluator]: Inference done 4486/5050. Dataloading: 0.0073 s/iter. Inference: 0.0408 s/iter. Eval: 0.0592 s/iter. Total: 0.1074 s/iter. ETA=0:01:00
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:54 d2.evaluation.evaluator]: Inference done 4538/5050. Dataloading: 0.0073 s/iter. Inference: 0.0407 s/iter. Eval: 0.0592 s/iter. Total: 0.1073 s/iter. ETA=0:00:54
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:59 d2.evaluation.evaluator]: Inference done 4593/5050. Dataloading: 0.0073 s/iter. Inference: 0.0406 s/iter. Eval: 0.0591 s/iter. Total: 0.1071 s/iter. ETA=0:00:48
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:22:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:04 d2.evaluation.evaluator]: Inference done 4639/5050. Dataloading: 0.0073 s/iter. Inference: 0.0406 s/iter. Eval: 0.0591 s/iter. Total: 0.1071 s/iter. ETA=0:00:44
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:09 d2.evaluation.evaluator]: Inference done 4691/5050. Dataloading: 0.0073 s/iter. Inference: 0.0406 s/iter. Eval: 0.0591 s/iter. Total: 0.1070 s/iter. ETA=0:00:38
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:14 d2.evaluation.evaluator]: Inference done 4740/5050. Dataloading: 0.0072 s/iter. Inference: 0.0406 s/iter. Eval: 0.0590 s/iter. Total: 0.1070 s/iter. ETA=0:00:33
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:19 d2.evaluation.evaluator]: Inference done 4794/5050. Dataloading: 0.0072 s/iter. Inference: 0.0405 s/iter. Eval: 0.0590 s/iter. Total: 0.1068 s/iter. ETA=0:00:27
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:24 d2.evaluation.evaluator]: Inference done 4840/5050. Dataloading: 0.0072 s/iter. Inference: 0.0406 s/iter. Eval: 0.0590 s/iter. Total: 0.1069 s/iter. ETA=0:00:22
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:29 d2.evaluation.evaluator]: Inference done 4893/5050. Dataloading: 0.0072 s/iter. Inference: 0.0405 s/iter. Eval: 0.0589 s/iter. Total: 0.1068 s/iter. ETA=0:00:16
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:34 d2.evaluation.evaluator]: Inference done 4945/5050. Dataloading: 0.0072 s/iter. Inference: 0.0405 s/iter. Eval: 0.0589 s/iter. Total: 0.1067 s/iter. ETA=0:00:11
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:39 d2.evaluation.evaluator]: Inference done 4993/5050. Dataloading: 0.0072 s/iter. Inference: 0.0405 s/iter. Eval: 0.0589 s/iter. Total: 0.1067 s/iter. ETA=0:00:06
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 564])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:44 d2.evaluation.evaluator]: Inference done 5038/5050. Dataloading: 0.0072 s/iter. Inference: 0.0405 s/iter. Eval: 0.0589 s/iter. Total: 0.1067 s/iter. ETA=0:00:01
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 684])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 592])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 732])
[03/11 13:23:46 d2.evaluation.evaluator]: Total inference time: 0:08:58.275098 (0.106695 s / iter per device, on 1 devices)
[03/11 13:23:46 d2.evaluation.evaluator]: Total inference pure compute time: 0:03:24 (0.040487 s / iter per device, on 1 devices)
[03/11 13:23:47 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 4.76627384964466, 'fwIoU': 30.888442476238886, 'IoU-bag': 0.0003553387725828894, 'BoundaryIoU-bag': 65.84742848006445, 'min(IoU, B-Iou)-bag': 0.0003553387725828894, 'IoU-wall': 50.5035012435142, 'BoundaryIoU-wall': 23.993667579380904, 'min(IoU, B-Iou)-wall': 23.993667579380904, 'IoU-floor': 55.32806634463891, 'BoundaryIoU-floor': 30.450380786382947, 'min(IoU, B-Iou)-floor': 30.450380786382947, 'IoU-cabinet': 0.015539653703625903, 'BoundaryIoU-cabinet': 4.579745402656464, 'min(IoU, B-Iou)-cabinet': 0.015539653703625903, 'IoU-bed': 6.5792284580977825, 'BoundaryIoU-bed': 2.8193386824986217, 'min(IoU, B-Iou)-bed': 2.8193386824986217, 'IoU-chair': 23.62037814252404, 'BoundaryIoU-chair': 6.762359761346276, 'min(IoU, B-Iou)-chair': 6.762359761346276, 'IoU-sofa': 0.14051068337240685, 'BoundaryIoU-sofa': 1.8704941072511687, 'min(IoU, B-Iou)-sofa': 0.14051068337240685, 'IoU-table': 13.081782255546548, 'BoundaryIoU-table': 0.0, 'min(IoU, B-Iou)-table': 0.0, 'IoU-door': 0.3990466319996034, 'BoundaryIoU-door': 0.0, 'min(IoU, B-Iou)-door': 0.0, 'IoU-window': 8.631591865762704, 'BoundaryIoU-window': 0.0, 'min(IoU, B-Iou)-window': 0.0, 'IoU-bookshelf': 2.356622621846309, 'BoundaryIoU-bookshelf': 0.0, 'min(IoU, B-Iou)-bookshelf': 0.0, 'IoU-picture': 0.00986377100658682, 'BoundaryIoU-picture': 0.0, 'min(IoU, B-Iou)-picture': 0.0, 'IoU-counter': 7.98161912930712e-05, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-blinds': 2.2845294634622637e-05, 'BoundaryIoU-blinds': 0.0, 'min(IoU, B-Iou)-blinds': 0.0, 'IoU-desk': 0.1410408255083525, 'BoundaryIoU-desk': 0.0, 'min(IoU, B-Iou)-desk': 0.0, 'IoU-shelves': 0.0, 'BoundaryIoU-shelves': 0.0, 'min(IoU, B-Iou)-shelves': 0.0, 'IoU-curtain': 0.00291496272192178, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-dresser': 0.0, 'BoundaryIoU-dresser': 0.0, 'min(IoU, B-Iou)-dresser': 0.0, 'IoU-pillow': 0.0010224310529041456, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-mirror': 0.0, 'BoundaryIoU-mirror': 0.0, 'min(IoU, B-Iou)-mirror': 0.0, 'IoU-floor mat': 0.0, 'BoundaryIoU-floor mat': 0.0, 'min(IoU, B-Iou)-floor mat': 0.0, 'IoU-clothes': 6.567278926784035e-05, 'BoundaryIoU-clothes': 0.0, 'min(IoU, B-Iou)-clothes': 0.0, 'IoU-ceiling': 10.233515977031695, 'BoundaryIoU-ceiling': 0.0, 'min(IoU, B-Iou)-ceiling': 0.0, 'IoU-books': 4.61155222455205, 'BoundaryIoU-books': 0.0, 'min(IoU, B-Iou)-books': 0.0, 'IoU-refridgerator': 0.0, 'BoundaryIoU-refridgerator': 0.0, 'min(IoU, B-Iou)-refridgerator': 0.0, 'IoU-television': 0.1345898275242848, 'BoundaryIoU-television': 0.0, 'min(IoU, B-Iou)-television': 0.0, 'IoU-paper': 0.055035081196654644, 'BoundaryIoU-paper': 0.0, 'min(IoU, B-Iou)-paper': 0.0, 'IoU-towel': 0.0024062836729321483, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-shower curtain': 0.0, 'BoundaryIoU-shower curtain': 0.0, 'min(IoU, B-Iou)-shower curtain': 0.0, 'IoU-box': 0.0026222838228895707, 'BoundaryIoU-box': 0.0, 'min(IoU, B-Iou)-box': 0.0, 'IoU-whiteboard': 0.0, 'BoundaryIoU-whiteboard': 0.0, 'min(IoU, B-Iou)-whiteboard': 0.0, 'IoU-person': 0.49980164480777783, 'BoundaryIoU-person': 0.0, 'min(IoU, B-Iou)-person': 0.0, 'IoU-night stand': 0.0, 'BoundaryIoU-night stand': 0.0, 'min(IoU, B-Iou)-night stand': 0.0, 'IoU-toilet': 0.0007770094557194452, 'BoundaryIoU-toilet': 0.0, 'min(IoU, B-Iou)-toilet': 0.0, 'IoU-sink': 7.443270185869621e-05, 'BoundaryIoU-sink': 0.0, 'min(IoU, B-Iou)-sink': 0.0, 'IoU-lamp': 0.00012410774289591767, 'BoundaryIoU-lamp': 0.0, 'min(IoU, B-Iou)-lamp': 0.0, 'IoU-bathtub': 0.0, 'BoundaryIoU-bathtub': 0.0, 'min(IoU, B-Iou)-bathtub': 0.0, 'mACC': 7.75569274638266, 'pACC': 49.78375289004415, 'ACC-bag': 0.00035571575939386034, 'ACC-wall': 84.33267488907373, 'ACC-floor': 80.08983706270627, 'ACC-cabinet': 0.015562200327845378, 'ACC-bed': 12.547945445534214, 'ACC-chair': 55.2247429135183, 'ACC-sofa': 0.1418386492670251, 'ACC-table': 15.854845439327553, 'ACC-door': 0.4086761873794741, 'ACC-window': 12.334228136655515, 'ACC-bookshelf': 2.534230043182331, 'ACC-picture': 0.009871832067028232, 'ACC-counter': 7.982491203793599e-05, 'ACC-blinds': 2.2850436580441303e-05, 'ACC-desk': 0.1428849656995879, 'ACC-shelves': 0.0, 'ACC-curtain': 0.0029154348543617052, 'ACC-dresser': 0.0, 'ACC-pillow': 0.001022662035763731, 'ACC-mirror': 0.0, 'ACC-floor mat': 0.0, 'ACC-clothes': 6.568532786831406e-05, 'ACC-ceiling': 13.71551109923674, 'ACC-books': 6.823314877578819, 'ACC-refridgerator': 0.0, 'ACC-television': 0.1450578667500782, 'ACC-paper': 0.05742045703272682, 'ACC-towel': 0.002411377069926077, 'ACC-shower curtain': 0.0, 'ACC-box': 0.0026249997841283072, 'ACC-whiteboard': 0.0, 'ACC-person': 2.571482174539585, 'ACC-night stand': 0.0, 'ACC-toilet': 0.0008102572490804213, 'ACC-sink': 7.443915678300762e-05, 'ACC-lamp': 0.0001241296956712251, 'ACC-bathtub': 0.0})])
[03/11 13:23:47 d2.engine.defaults]: Evaluation results for sunrgbd_sem_seg_val in csv format:
[03/11 13:23:47 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/11 13:23:47 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/11 13:23:47 d2.evaluation.testing]: copypaste: 4.7663,30.8884,7.7557,49.7838
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5211160>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5211a00>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5226190>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa52260a0>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa521a130>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa521a1c0>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa521a370>, RandomFlip()]
[03/11 13:23:47 mask2former.data.dataloader.DaliDataLoader]: evaluate bdd_sem_seg_val
[03/11 13:23:47 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/11 13:23:47 d2.data.common]: Serializing 1000 elements to byte tensors and concatenating them all ...
[03/11 13:23:47 d2.data.common]: Serialized dataset takes 0.19 MiB
[03/11 13:23:47 d2.evaluation.evaluator]: Start inference on 1000 batches
[03/11 13:23:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:50 d2.evaluation.evaluator]: Inference done 11/1000. Dataloading: 0.0095 s/iter. Inference: 0.0660 s/iter. Eval: 0.1257 s/iter. Total: 0.2012 s/iter. ETA=0:03:18
[03/11 13:23:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:55 d2.evaluation.evaluator]: Inference done 37/1000. Dataloading: 0.0078 s/iter. Inference: 0.0624 s/iter. Eval: 0.1243 s/iter. Total: 0.1946 s/iter. ETA=0:03:07
[03/11 13:23:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:23:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:00 d2.evaluation.evaluator]: Inference done 69/1000. Dataloading: 0.0071 s/iter. Inference: 0.0532 s/iter. Eval: 0.1157 s/iter. Total: 0.1761 s/iter. ETA=0:02:43
[03/11 13:24:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:06 d2.evaluation.evaluator]: Inference done 102/1000. Dataloading: 0.0081 s/iter. Inference: 0.0509 s/iter. Eval: 0.1099 s/iter. Total: 0.1690 s/iter. ETA=0:02:31
[03/11 13:24:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 d2.evaluation.evaluator]: Inference done 133/1000. Dataloading: 0.0082 s/iter. Inference: 0.0509 s/iter. Eval: 0.1085 s/iter. Total: 0.1677 s/iter. ETA=0:02:25
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:16 d2.evaluation.evaluator]: Inference done 164/1000. Dataloading: 0.0084 s/iter. Inference: 0.0496 s/iter. Eval: 0.1088 s/iter. Total: 0.1669 s/iter. ETA=0:02:19
[03/11 13:24:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:21 d2.evaluation.evaluator]: Inference done 194/1000. Dataloading: 0.0083 s/iter. Inference: 0.0494 s/iter. Eval: 0.1092 s/iter. Total: 0.1669 s/iter. ETA=0:02:14
[03/11 13:24:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 d2.evaluation.evaluator]: Inference done 226/1000. Dataloading: 0.0083 s/iter. Inference: 0.0489 s/iter. Eval: 0.1082 s/iter. Total: 0.1654 s/iter. ETA=0:02:08
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:31 d2.evaluation.evaluator]: Inference done 260/1000. Dataloading: 0.0079 s/iter. Inference: 0.0483 s/iter. Eval: 0.1074 s/iter. Total: 0.1637 s/iter. ETA=0:02:01
[03/11 13:24:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:36 d2.evaluation.evaluator]: Inference done 288/1000. Dataloading: 0.0081 s/iter. Inference: 0.0491 s/iter. Eval: 0.1086 s/iter. Total: 0.1659 s/iter. ETA=0:01:58
[03/11 13:24:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 d2.evaluation.evaluator]: Inference done 319/1000. Dataloading: 0.0082 s/iter. Inference: 0.0490 s/iter. Eval: 0.1085 s/iter. Total: 0.1658 s/iter. ETA=0:01:52
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:46 d2.evaluation.evaluator]: Inference done 352/1000. Dataloading: 0.0083 s/iter. Inference: 0.0485 s/iter. Eval: 0.1081 s/iter. Total: 0.1650 s/iter. ETA=0:01:46
[03/11 13:24:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:52 d2.evaluation.evaluator]: Inference done 383/1000. Dataloading: 0.0081 s/iter. Inference: 0.0483 s/iter. Eval: 0.1084 s/iter. Total: 0.1649 s/iter. ETA=0:01:41
[03/11 13:24:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:57 d2.evaluation.evaluator]: Inference done 416/1000. Dataloading: 0.0081 s/iter. Inference: 0.0479 s/iter. Eval: 0.1081 s/iter. Total: 0.1641 s/iter. ETA=0:01:35
[03/11 13:24:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:24:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:02 d2.evaluation.evaluator]: Inference done 445/1000. Dataloading: 0.0082 s/iter. Inference: 0.0483 s/iter. Eval: 0.1083 s/iter. Total: 0.1649 s/iter. ETA=0:01:31
[03/11 13:25:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:07 d2.evaluation.evaluator]: Inference done 478/1000. Dataloading: 0.0081 s/iter. Inference: 0.0480 s/iter. Eval: 0.1080 s/iter. Total: 0.1641 s/iter. ETA=0:01:25
[03/11 13:25:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:12 d2.evaluation.evaluator]: Inference done 511/1000. Dataloading: 0.0081 s/iter. Inference: 0.0476 s/iter. Eval: 0.1077 s/iter. Total: 0.1635 s/iter. ETA=0:01:19
[03/11 13:25:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 d2.evaluation.evaluator]: Inference done 540/1000. Dataloading: 0.0081 s/iter. Inference: 0.0478 s/iter. Eval: 0.1081 s/iter. Total: 0.1641 s/iter. ETA=0:01:15
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:22 d2.evaluation.evaluator]: Inference done 567/1000. Dataloading: 0.0080 s/iter. Inference: 0.0487 s/iter. Eval: 0.1084 s/iter. Total: 0.1653 s/iter. ETA=0:01:11
[03/11 13:25:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:27 d2.evaluation.evaluator]: Inference done 599/1000. Dataloading: 0.0079 s/iter. Inference: 0.0488 s/iter. Eval: 0.1083 s/iter. Total: 0.1651 s/iter. ETA=0:01:06
[03/11 13:25:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:32 d2.evaluation.evaluator]: Inference done 628/1000. Dataloading: 0.0079 s/iter. Inference: 0.0490 s/iter. Eval: 0.1085 s/iter. Total: 0.1655 s/iter. ETA=0:01:01
[03/11 13:25:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 d2.evaluation.evaluator]: Inference done 662/1000. Dataloading: 0.0078 s/iter. Inference: 0.0486 s/iter. Eval: 0.1080 s/iter. Total: 0.1645 s/iter. ETA=0:00:55
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:42 d2.evaluation.evaluator]: Inference done 692/1000. Dataloading: 0.0077 s/iter. Inference: 0.0486 s/iter. Eval: 0.1082 s/iter. Total: 0.1646 s/iter. ETA=0:00:50
[03/11 13:25:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:47 d2.evaluation.evaluator]: Inference done 724/1000. Dataloading: 0.0077 s/iter. Inference: 0.0485 s/iter. Eval: 0.1082 s/iter. Total: 0.1644 s/iter. ETA=0:00:45
[03/11 13:25:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:53 d2.evaluation.evaluator]: Inference done 760/1000. Dataloading: 0.0076 s/iter. Inference: 0.0481 s/iter. Eval: 0.1075 s/iter. Total: 0.1633 s/iter. ETA=0:00:39
[03/11 13:25:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 d2.evaluation.evaluator]: Inference done 788/1000. Dataloading: 0.0075 s/iter. Inference: 0.0480 s/iter. Eval: 0.1083 s/iter. Total: 0.1639 s/iter. ETA=0:00:34
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:25:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 d2.evaluation.evaluator]: Inference done 820/1000. Dataloading: 0.0076 s/iter. Inference: 0.0479 s/iter. Eval: 0.1082 s/iter. Total: 0.1638 s/iter. ETA=0:00:29
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:08 d2.evaluation.evaluator]: Inference done 849/1000. Dataloading: 0.0076 s/iter. Inference: 0.0481 s/iter. Eval: 0.1084 s/iter. Total: 0.1641 s/iter. ETA=0:00:24
[03/11 13:26:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:13 d2.evaluation.evaluator]: Inference done 881/1000. Dataloading: 0.0075 s/iter. Inference: 0.0480 s/iter. Eval: 0.1084 s/iter. Total: 0.1639 s/iter. ETA=0:00:19
[03/11 13:26:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:18 d2.evaluation.evaluator]: Inference done 912/1000. Dataloading: 0.0075 s/iter. Inference: 0.0477 s/iter. Eval: 0.1086 s/iter. Total: 0.1639 s/iter. ETA=0:00:14
[03/11 13:26:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 d2.evaluation.evaluator]: Inference done 944/1000. Dataloading: 0.0074 s/iter. Inference: 0.0477 s/iter. Eval: 0.1085 s/iter. Total: 0.1637 s/iter. ETA=0:00:09
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 d2.evaluation.evaluator]: Inference done 977/1000. Dataloading: 0.0074 s/iter. Inference: 0.0475 s/iter. Eval: 0.1084 s/iter. Total: 0.1634 s/iter. ETA=0:00:03
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:26:32 d2.evaluation.evaluator]: Total inference time: 0:02:42.363960 (0.163180 s / iter per device, on 1 devices)
[03/11 13:26:32 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:47 (0.047404 s / iter per device, on 1 devices)
[03/11 13:26:32 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 21.165996257431118, 'fwIoU': 68.81546416379014, 'IoU-road': 81.33950985156874, 'BoundaryIoU-road': 74.33608066536385, 'min(IoU, B-Iou)-road': 74.33608066536385, 'IoU-sidewalk': 12.555749845815836, 'BoundaryIoU-sidewalk': 9.86856208176045, 'min(IoU, B-Iou)-sidewalk': 9.86856208176045, 'IoU-building': 64.11065255592526, 'BoundaryIoU-building': 46.805172037148054, 'min(IoU, B-Iou)-building': 46.805172037148054, 'IoU-wall': 0.2659597196829869, 'BoundaryIoU-wall': 1.6669317652160633, 'min(IoU, B-Iou)-wall': 0.2659597196829869, 'IoU-fence': 0.8299644702269954, 'BoundaryIoU-fence': 0.08936807315715649, 'min(IoU, B-Iou)-fence': 0.08936807315715649, 'IoU-pole': 5.042791464654416, 'BoundaryIoU-pole': 11.809460145663495, 'min(IoU, B-Iou)-pole': 5.042791464654416, 'IoU-traffic light': 0.004809599961523201, 'BoundaryIoU-traffic light': 22.72913998733412, 'min(IoU, B-Iou)-traffic light': 0.004809599961523201, 'IoU-traffic sign': 0.004667854168767201, 'BoundaryIoU-traffic sign': 1.4699039150993853, 'min(IoU, B-Iou)-traffic sign': 0.004667854168767201, 'IoU-vegetation': 69.23778541349138, 'BoundaryIoU-vegetation': 39.12785372585234, 'min(IoU, B-Iou)-vegetation': 39.12785372585234, 'IoU-terrain': 20.368141471803998, 'BoundaryIoU-terrain': 6.480488506097018, 'min(IoU, B-Iou)-terrain': 6.480488506097018, 'IoU-sky': 88.17323048557564, 'BoundaryIoU-sky': 81.58626033225784, 'min(IoU, B-Iou)-sky': 81.58626033225784, 'IoU-person': 0.953725991153414, 'BoundaryIoU-person': 18.15864263607367, 'min(IoU, B-Iou)-person': 0.953725991153414, 'IoU-rider': 0.0, 'BoundaryIoU-rider': 0.5920323431338765, 'min(IoU, B-Iou)-rider': 0.0, 'IoU-car': 58.683281409899124, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-truck': 0.0030213322067927876, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-bus': 0.158681030460454, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-train': 0.0, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-motorcycle': 0.41666850188734095, 'BoundaryIoU-motorcycle': 0.0, 'min(IoU, B-Iou)-motorcycle': 0.0, 'IoU-bicycle': 0.005287892708656942, 'BoundaryIoU-bicycle': 0.0, 'min(IoU, B-Iou)-bicycle': 0.0, 'mACC': 25.323141391474806, 'pACC': 81.29266604976301, 'ACC-road': 95.58640691354103, 'ACC-sidewalk': 14.329111206014458, 'ACC-building': 80.65558261793348, 'ACC-wall': 0.40764851206160724, 'ACC-fence': 0.8521027623289255, 'ACC-pole': 5.298072580004907, 'ACC-traffic light': 0.004810294029222536, 'ACC-traffic sign': 0.0047075371907206905, 'ACC-vegetation': 85.9316584994332, 'ACC-terrain': 24.39371439911774, 'ACC-sky': 91.48819098760767, 'ACC-person': 0.9878475677527871, 'ACC-rider': 0.0, 'ACC-car': 80.59930316827042, 'ACC-truck': 0.003026149891513061, 'ACC-bus': 0.15897957648241162, 'ACC-train': 0.0, 'ACC-motorcycle': 0.43302923633966706, 'ACC-bicycle': 0.005494430021565638})])
[03/11 13:26:32 d2.engine.defaults]: Evaluation results for bdd_sem_seg_val in csv format:
[03/11 13:26:32 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/11 13:26:32 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/11 13:26:32 d2.evaluation.testing]: copypaste: 21.1660,68.8155,25.3231,81.2927
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa52414c0>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5241220>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5241cd0>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5246580>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5246760>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5246fa0>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520fd00>, RandomFlip()]
[03/11 13:26:32 mask2former.data.dataloader.DaliDataLoader]: evaluate idd_sem_seg_val
[03/11 13:26:32 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/11 13:26:32 d2.data.common]: Serializing 981 elements to byte tensors and concatenating them all ...
[03/11 13:26:32 d2.data.common]: Serialized dataset takes 0.18 MiB
[03/11 13:26:32 d2.evaluation.evaluator]: Start inference on 981 batches
[03/11 13:26:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:38 d2.evaluation.evaluator]: Inference done 11/981. Dataloading: 0.0068 s/iter. Inference: 0.0867 s/iter. Eval: 0.2763 s/iter. Total: 0.3698 s/iter. ETA=0:05:58
[03/11 13:26:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:43 d2.evaluation.evaluator]: Inference done 26/981. Dataloading: 0.0082 s/iter. Inference: 0.0803 s/iter. Eval: 0.2600 s/iter. Total: 0.3485 s/iter. ETA=0:05:32
[03/11 13:26:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:48 d2.evaluation.evaluator]: Inference done 40/981. Dataloading: 0.0089 s/iter. Inference: 0.0791 s/iter. Eval: 0.2674 s/iter. Total: 0.3556 s/iter. ETA=0:05:34
[03/11 13:26:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:53 d2.evaluation.evaluator]: Inference done 56/981. Dataloading: 0.0086 s/iter. Inference: 0.0765 s/iter. Eval: 0.2626 s/iter. Total: 0.3477 s/iter. ETA=0:05:21
[03/11 13:26:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:58 d2.evaluation.evaluator]: Inference done 71/981. Dataloading: 0.0086 s/iter. Inference: 0.0757 s/iter. Eval: 0.2618 s/iter. Total: 0.3462 s/iter. ETA=0:05:15
[03/11 13:26:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:26:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:03 d2.evaluation.evaluator]: Inference done 86/981. Dataloading: 0.0088 s/iter. Inference: 0.0767 s/iter. Eval: 0.2605 s/iter. Total: 0.3461 s/iter. ETA=0:05:09
[03/11 13:27:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:09 d2.evaluation.evaluator]: Inference done 102/981. Dataloading: 0.0088 s/iter. Inference: 0.0754 s/iter. Eval: 0.2614 s/iter. Total: 0.3457 s/iter. ETA=0:05:03
[03/11 13:27:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:14 d2.evaluation.evaluator]: Inference done 117/981. Dataloading: 0.0087 s/iter. Inference: 0.0741 s/iter. Eval: 0.2626 s/iter. Total: 0.3455 s/iter. ETA=0:04:58
[03/11 13:27:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:19 d2.evaluation.evaluator]: Inference done 132/981. Dataloading: 0.0088 s/iter. Inference: 0.0734 s/iter. Eval: 0.2623 s/iter. Total: 0.3445 s/iter. ETA=0:04:52
[03/11 13:27:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:24 d2.evaluation.evaluator]: Inference done 147/981. Dataloading: 0.0089 s/iter. Inference: 0.0745 s/iter. Eval: 0.2616 s/iter. Total: 0.3449 s/iter. ETA=0:04:47
[03/11 13:27:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:29 d2.evaluation.evaluator]: Inference done 162/981. Dataloading: 0.0088 s/iter. Inference: 0.0744 s/iter. Eval: 0.2609 s/iter. Total: 0.3442 s/iter. ETA=0:04:41
[03/11 13:27:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:34 d2.evaluation.evaluator]: Inference done 180/981. Dataloading: 0.0088 s/iter. Inference: 0.0750 s/iter. Eval: 0.2539 s/iter. Total: 0.3377 s/iter. ETA=0:04:30
[03/11 13:27:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:39 d2.evaluation.evaluator]: Inference done 206/981. Dataloading: 0.0088 s/iter. Inference: 0.0716 s/iter. Eval: 0.2386 s/iter. Total: 0.3190 s/iter. ETA=0:04:07
[03/11 13:27:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 964, 1280])
[03/11 13:27:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:44 d2.evaluation.evaluator]: Inference done 230/981. Dataloading: 0.0085 s/iter. Inference: 0.0687 s/iter. Eval: 0.2302 s/iter. Total: 0.3075 s/iter. ETA=0:03:50
[03/11 13:27:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 d2.evaluation.evaluator]: Inference done 256/981. Dataloading: 0.0083 s/iter. Inference: 0.0662 s/iter. Eval: 0.2210 s/iter. Total: 0.2956 s/iter. ETA=0:03:34
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:27:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:55 d2.evaluation.evaluator]: Inference done 280/981. Dataloading: 0.0083 s/iter. Inference: 0.0651 s/iter. Eval: 0.2151 s/iter. Total: 0.2885 s/iter. ETA=0:03:22
[03/11 13:27:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:27:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:00 d2.evaluation.evaluator]: Inference done 295/981. Dataloading: 0.0083 s/iter. Inference: 0.0665 s/iter. Eval: 0.2162 s/iter. Total: 0.2910 s/iter. ETA=0:03:19
[03/11 13:28:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:05 d2.evaluation.evaluator]: Inference done 310/981. Dataloading: 0.0083 s/iter. Inference: 0.0671 s/iter. Eval: 0.2175 s/iter. Total: 0.2938 s/iter. ETA=0:03:17
[03/11 13:28:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:10 d2.evaluation.evaluator]: Inference done 327/981. Dataloading: 0.0083 s/iter. Inference: 0.0679 s/iter. Eval: 0.2176 s/iter. Total: 0.2946 s/iter. ETA=0:03:12
[03/11 13:28:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:15 d2.evaluation.evaluator]: Inference done 345/981. Dataloading: 0.0082 s/iter. Inference: 0.0678 s/iter. Eval: 0.2167 s/iter. Total: 0.2937 s/iter. ETA=0:03:06
[03/11 13:28:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:20 d2.evaluation.evaluator]: Inference done 365/981. Dataloading: 0.0082 s/iter. Inference: 0.0677 s/iter. Eval: 0.2150 s/iter. Total: 0.2918 s/iter. ETA=0:02:59
[03/11 13:28:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:25 d2.evaluation.evaluator]: Inference done 392/981. Dataloading: 0.0081 s/iter. Inference: 0.0664 s/iter. Eval: 0.2094 s/iter. Total: 0.2847 s/iter. ETA=0:02:47
[03/11 13:28:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:31 d2.evaluation.evaluator]: Inference done 420/981. Dataloading: 0.0081 s/iter. Inference: 0.0652 s/iter. Eval: 0.2038 s/iter. Total: 0.2780 s/iter. ETA=0:02:35
[03/11 13:28:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:36 d2.evaluation.evaluator]: Inference done 449/981. Dataloading: 0.0081 s/iter. Inference: 0.0638 s/iter. Eval: 0.1987 s/iter. Total: 0.2714 s/iter. ETA=0:02:24
[03/11 13:28:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 d2.evaluation.evaluator]: Inference done 475/981. Dataloading: 0.0082 s/iter. Inference: 0.0632 s/iter. Eval: 0.1951 s/iter. Total: 0.2672 s/iter. ETA=0:02:15
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:46 d2.evaluation.evaluator]: Inference done 502/981. Dataloading: 0.0081 s/iter. Inference: 0.0626 s/iter. Eval: 0.1915 s/iter. Total: 0.2630 s/iter. ETA=0:02:05
[03/11 13:28:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:28:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:51 d2.evaluation.evaluator]: Inference done 523/981. Dataloading: 0.0080 s/iter. Inference: 0.0627 s/iter. Eval: 0.1909 s/iter. Total: 0.2623 s/iter. ETA=0:02:00
[03/11 13:28:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:56 d2.evaluation.evaluator]: Inference done 540/981. Dataloading: 0.0080 s/iter. Inference: 0.0632 s/iter. Eval: 0.1918 s/iter. Total: 0.2636 s/iter. ETA=0:01:56
[03/11 13:28:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:28:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:01 d2.evaluation.evaluator]: Inference done 557/981. Dataloading: 0.0080 s/iter. Inference: 0.0635 s/iter. Eval: 0.1925 s/iter. Total: 0.2646 s/iter. ETA=0:01:52
[03/11 13:29:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:07 d2.evaluation.evaluator]: Inference done 573/981. Dataloading: 0.0080 s/iter. Inference: 0.0639 s/iter. Eval: 0.1939 s/iter. Total: 0.2664 s/iter. ETA=0:01:48
[03/11 13:29:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:12 d2.evaluation.evaluator]: Inference done 590/981. Dataloading: 0.0080 s/iter. Inference: 0.0641 s/iter. Eval: 0.1947 s/iter. Total: 0.2674 s/iter. ETA=0:01:44
[03/11 13:29:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:17 d2.evaluation.evaluator]: Inference done 605/981. Dataloading: 0.0081 s/iter. Inference: 0.0647 s/iter. Eval: 0.1959 s/iter. Total: 0.2692 s/iter. ETA=0:01:41
[03/11 13:29:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:22 d2.evaluation.evaluator]: Inference done 620/981. Dataloading: 0.0080 s/iter. Inference: 0.0648 s/iter. Eval: 0.1976 s/iter. Total: 0.2711 s/iter. ETA=0:01:37
[03/11 13:29:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:27 d2.evaluation.evaluator]: Inference done 640/981. Dataloading: 0.0080 s/iter. Inference: 0.0650 s/iter. Eval: 0.1970 s/iter. Total: 0.2706 s/iter. ETA=0:01:32
[03/11 13:29:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:32 d2.evaluation.evaluator]: Inference done 668/981. Dataloading: 0.0080 s/iter. Inference: 0.0643 s/iter. Eval: 0.1941 s/iter. Total: 0.2669 s/iter. ETA=0:01:23
[03/11 13:29:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:37 d2.evaluation.evaluator]: Inference done 691/981. Dataloading: 0.0079 s/iter. Inference: 0.0639 s/iter. Eval: 0.1929 s/iter. Total: 0.2652 s/iter. ETA=0:01:16
[03/11 13:29:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:42 d2.evaluation.evaluator]: Inference done 716/981. Dataloading: 0.0079 s/iter. Inference: 0.0634 s/iter. Eval: 0.1915 s/iter. Total: 0.2632 s/iter. ETA=0:01:09
[03/11 13:29:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:47 d2.evaluation.evaluator]: Inference done 731/981. Dataloading: 0.0079 s/iter. Inference: 0.0634 s/iter. Eval: 0.1929 s/iter. Total: 0.2647 s/iter. ETA=0:01:06
[03/11 13:29:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:53 d2.evaluation.evaluator]: Inference done 753/981. Dataloading: 0.0079 s/iter. Inference: 0.0631 s/iter. Eval: 0.1922 s/iter. Total: 0.2637 s/iter. ETA=0:01:00
[03/11 13:29:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:29:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:58 d2.evaluation.evaluator]: Inference done 776/981. Dataloading: 0.0078 s/iter. Inference: 0.0629 s/iter. Eval: 0.1915 s/iter. Total: 0.2627 s/iter. ETA=0:00:53
[03/11 13:29:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:29:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:03 d2.evaluation.evaluator]: Inference done 791/981. Dataloading: 0.0079 s/iter. Inference: 0.0630 s/iter. Eval: 0.1929 s/iter. Total: 0.2642 s/iter. ETA=0:00:50
[03/11 13:30:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:08 d2.evaluation.evaluator]: Inference done 807/981. Dataloading: 0.0079 s/iter. Inference: 0.0631 s/iter. Eval: 0.1939 s/iter. Total: 0.2654 s/iter. ETA=0:00:46
[03/11 13:30:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:14 d2.evaluation.evaluator]: Inference done 824/981. Dataloading: 0.0079 s/iter. Inference: 0.0633 s/iter. Eval: 0.1948 s/iter. Total: 0.2664 s/iter. ETA=0:00:41
[03/11 13:30:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:19 d2.evaluation.evaluator]: Inference done 841/981. Dataloading: 0.0079 s/iter. Inference: 0.0636 s/iter. Eval: 0.1953 s/iter. Total: 0.2672 s/iter. ETA=0:00:37
[03/11 13:30:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:24 d2.evaluation.evaluator]: Inference done 867/981. Dataloading: 0.0078 s/iter. Inference: 0.0631 s/iter. Eval: 0.1937 s/iter. Total: 0.2650 s/iter. ETA=0:00:30
[03/11 13:30:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:29 d2.evaluation.evaluator]: Inference done 892/981. Dataloading: 0.0078 s/iter. Inference: 0.0628 s/iter. Eval: 0.1923 s/iter. Total: 0.2633 s/iter. ETA=0:00:23
[03/11 13:30:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:34 d2.evaluation.evaluator]: Inference done 915/981. Dataloading: 0.0077 s/iter. Inference: 0.0628 s/iter. Eval: 0.1914 s/iter. Total: 0.2623 s/iter. ETA=0:00:17
[03/11 13:30:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:39 d2.evaluation.evaluator]: Inference done 940/981. Dataloading: 0.0077 s/iter. Inference: 0.0626 s/iter. Eval: 0.1900 s/iter. Total: 0.2607 s/iter. ETA=0:00:10
[03/11 13:30:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 1280])
[03/11 13:30:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:44 d2.evaluation.evaluator]: Inference done 961/981. Dataloading: 0.0077 s/iter. Inference: 0.0626 s/iter. Eval: 0.1898 s/iter. Total: 0.2604 s/iter. ETA=0:00:05
[03/11 13:30:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:49 d2.evaluation.evaluator]: Inference done 977/981. Dataloading: 0.0077 s/iter. Inference: 0.0626 s/iter. Eval: 0.1908 s/iter. Total: 0.2614 s/iter. ETA=0:00:01
[03/11 13:30:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 1080, 1920])
[03/11 13:30:50 d2.evaluation.evaluator]: Total inference time: 0:04:15.077858 (0.261350 s / iter per device, on 1 devices)
[03/11 13:30:50 d2.evaluation.evaluator]: Total inference pure compute time: 0:01:01 (0.062534 s / iter per device, on 1 devices)
[03/11 13:30:51 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 16.17844802789271, 'fwIoU': 60.00263928530223, 'IoU-road': 83.29334298184263, 'BoundaryIoU-road': 75.24153047684369, 'min(IoU, B-Iou)-road': 75.24153047684369, 'IoU-drivable fallback or parking': 34.344583926694376, 'BoundaryIoU-drivable fallback or parking': 24.38589306967488, 'min(IoU, B-Iou)-drivable fallback or parking': 24.38589306967488, 'IoU-sidewalk': 2.408196127170469, 'BoundaryIoU-sidewalk': 7.3745776948145565, 'min(IoU, B-Iou)-sidewalk': 2.408196127170469, 'IoU-non-drivable fallback or rail track': 12.258134524650162, 'BoundaryIoU-non-drivable fallback or rail track': 4.792643800314436, 'min(IoU, B-Iou)-non-drivable fallback or rail track': 4.792643800314436, 'IoU-person or animal': 0.8047880491173581, 'BoundaryIoU-person or animal': 9.072715852821986, 'min(IoU, B-Iou)-person or animal': 0.8047880491173581, 'IoU-out of roi or rider': 3.9899824170117624, 'BoundaryIoU-out of roi or rider': 12.438553835756945, 'min(IoU, B-Iou)-out of roi or rider': 3.9899824170117624, 'IoU-motorcycle': 0.5862646948838113, 'BoundaryIoU-motorcycle': 3.033525617660856, 'min(IoU, B-Iou)-motorcycle': 0.5862646948838113, 'IoU-bicycle': 0.04577541137639434, 'BoundaryIoU-bicycle': 3.445404454988086, 'min(IoU, B-Iou)-bicycle': 0.04577541137639434, 'IoU-autorickshaw': 16.609040221506756, 'BoundaryIoU-autorickshaw': 4.5254098816917265, 'min(IoU, B-Iou)-autorickshaw': 4.5254098816917265, 'IoU-car': 26.97095734653061, 'BoundaryIoU-car': 16.411272048675013, 'min(IoU, B-Iou)-car': 16.411272048675013, 'IoU-truck': 0.451463796436433, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-bus': 0.8952287753164282, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-trailer or caravan or vehicle fallback': 7.762685392333882e-05, 'BoundaryIoU-trailer or caravan or vehicle fallback': 0.0, 'min(IoU, B-Iou)-trailer or caravan or vehicle fallback': 0.0, 'IoU-curb': 1.9125962188424601, 'BoundaryIoU-curb': 0.0, 'min(IoU, B-Iou)-curb': 0.0, 'IoU-wall': 1.1422168151770475, 'BoundaryIoU-wall': 0.0, 'min(IoU, B-Iou)-wall': 0.0, 'IoU-fence': 0.6501294979435741, 'BoundaryIoU-fence': 0.0, 'min(IoU, B-Iou)-fence': 0.0, 'IoU-guard rail': 0.0, 'BoundaryIoU-guard rail': 0.0, 'min(IoU, B-Iou)-guard rail': 0.0, 'IoU-billboard': 2.4939605974170984, 'BoundaryIoU-billboard': 0.0, 'min(IoU, B-Iou)-billboard': 0.0, 'IoU-traffic sign': 0.0698105486146217, 'BoundaryIoU-traffic sign': 0.0, 'min(IoU, B-Iou)-traffic sign': 0.0, 'IoU-traffic light': 0.0, 'BoundaryIoU-traffic light': 0.0, 'min(IoU, B-Iou)-traffic light': 0.0, 'IoU-polegroup or pole': 9.24358844460063, 'BoundaryIoU-polegroup or pole': 0.0, 'min(IoU, B-Iou)-polegroup or pole': 0.0, 'IoU-obs-str-bar-fallback': 7.00028031186385, 'BoundaryIoU-obs-str-bar-fallback': 0.0, 'min(IoU, B-Iou)-obs-str-bar-fallback': 0.0, 'IoU-building': 30.81799208359566, 'BoundaryIoU-building': 0.0, 'min(IoU, B-Iou)-building': 0.0, 'IoU-tunnel or bridge': 17.593246796018246, 'BoundaryIoU-tunnel or bridge': 0.0, 'min(IoU, B-Iou)-tunnel or bridge': 0.0, 'IoU-vegetation': 72.99950154832983, 'BoundaryIoU-vegetation': 0.0, 'min(IoU, B-Iou)-vegetation': 0.0, 'IoU-sky or fallback background': 94.05848996341633, 'BoundaryIoU-sky or fallback background': 0.0, 'min(IoU, B-Iou)-sky or fallback background': 0.0, 'mACC': 22.40244654905505, 'pACC': 72.54628672575727, 'ACC-road': 96.3938482270477, 'ACC-drivable fallback or parking': 54.58400535248885, 'ACC-sidewalk': 2.702647479342163, 'ACC-non-drivable fallback or rail track': 14.497438082863937, 'ACC-person or animal': 0.8292502023012386, 'ACC-out of roi or rider': 4.5600998428134805, 'ACC-motorcycle': 0.5913696650017954, 'ACC-bicycle': 0.047763655377684816, 'ACC-autorickshaw': 23.067303016499977, 'ACC-car': 80.767976697155, 'ACC-truck': 0.4520457550158099, 'ACC-bus': 0.907502538234446, 'ACC-trailer or caravan or vehicle fallback': 7.766631367327102e-05, 'ACC-curb': 2.0545233978853967, 'ACC-wall': 1.2957961998426024, 'ACC-fence': 0.7115347627688465, 'ACC-guard rail': 0.0, 'ACC-billboard': 2.642266619633166, 'ACC-traffic sign': 0.07131381356765795, 'ACC-traffic light': 0.0, 'ACC-polegroup or pole': 10.220217374965907, 'ACC-obs-str-bar-fallback': 8.755065660613162, 'ACC-building': 70.05129469268444, 'ACC-tunnel or bridge': 18.14900730122392, 'ACC-vegetation': 91.53245012987512, 'ACC-sky or fallback background': 97.57881214191525})])
[03/11 13:30:51 d2.engine.defaults]: Evaluation results for idd_sem_seg_val in csv format:
[03/11 13:30:51 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/11 13:30:51 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/11 13:30:51 d2.evaluation.testing]: copypaste: 16.1784,60.0026,22.4024,72.5463
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5239880>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5211130>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5211670>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa52269d0>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520bf70>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520b9d0>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5241250>, RandomFlip()]
[03/11 13:30:51 mask2former.data.dataloader.DaliDataLoader]: evaluate ade_sem_seg_val
[03/11 13:30:51 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/11 13:30:51 d2.data.common]: Serializing 2000 elements to byte tensors and concatenating them all ...
[03/11 13:30:51 d2.data.common]: Serialized dataset takes 0.43 MiB
[03/11 13:30:51 d2.evaluation.evaluator]: Start inference on 2000 batches
[03/11 13:30:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 500])
[03/11 13:30:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:30:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:30:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 500])
[03/11 13:30:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:30:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:30:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 500])
[03/11 13:30:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 480])
[03/11 13:30:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 568])
[03/11 13:30:55 d2.evaluation.evaluator]: Inference done 12/2000. Dataloading: 0.0021 s/iter. Inference: 0.1754 s/iter. Eval: 0.0353 s/iter. Total: 0.2128 s/iter. ETA=0:07:03
[03/11 13:30:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 432])
[03/11 13:30:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:30:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:30:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 204])
[03/11 13:30:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:30:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 600])
[03/11 13:30:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 400])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 268])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 500])
[03/11 13:30:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 528])
[03/11 13:30:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:30:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 324])
[03/11 13:30:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:30:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:30:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:30:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 916])
[03/11 13:30:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 400])
[03/11 13:30:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 284])
[03/11 13:31:00 d2.evaluation.evaluator]: Inference done 37/2000. Dataloading: 0.0032 s/iter. Inference: 0.1617 s/iter. Eval: 0.0447 s/iter. Total: 0.2101 s/iter. ETA=0:06:52
[03/11 13:31:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 336])
[03/11 13:31:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 316])
[03/11 13:31:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 260])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 432])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 560])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 680])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 644])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 352])
[03/11 13:31:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:31:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 504])
[03/11 13:31:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:31:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 624])
[03/11 13:31:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 360])
[03/11 13:31:05 d2.evaluation.evaluator]: Inference done 66/2000. Dataloading: 0.0033 s/iter. Inference: 0.1485 s/iter. Eval: 0.0422 s/iter. Total: 0.1943 s/iter. ETA=0:06:15
[03/11 13:31:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 272])
[03/11 13:31:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 580])
[03/11 13:31:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 252])
[03/11 13:31:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 200])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 220])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 696])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 400])
[03/11 13:31:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 300])
[03/11 13:31:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 296])
[03/11 13:31:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 660])
[03/11 13:31:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 236])
[03/11 13:31:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:31:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 284])
[03/11 13:31:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:31:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 764, 512])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 300])
[03/11 13:31:10 d2.evaluation.evaluator]: Inference done 95/2000. Dataloading: 0.0035 s/iter. Inference: 0.1404 s/iter. Eval: 0.0434 s/iter. Total: 0.1875 s/iter. ETA=0:05:57
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 692, 512])
[03/11 13:31:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 784, 512])
[03/11 13:31:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 400])
[03/11 13:31:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:31:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 712])
[03/11 13:31:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 688])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 348])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:31:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 276])
[03/11 13:31:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 728])
[03/11 13:31:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 788])
[03/11 13:31:15 d2.evaluation.evaluator]: Inference done 127/2000. Dataloading: 0.0039 s/iter. Inference: 0.1276 s/iter. Eval: 0.0480 s/iter. Total: 0.1797 s/iter. ETA=0:05:36
[03/11 13:31:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 752])
[03/11 13:31:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:31:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:31:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 776])
[03/11 13:31:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 452])
[03/11 13:31:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 752])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:31:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 784])
[03/11 13:31:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:31:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 1128])
[03/11 13:31:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 340])
[03/11 13:31:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 928])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:31:20 d2.evaluation.evaluator]: Inference done 160/2000. Dataloading: 0.0044 s/iter. Inference: 0.1183 s/iter. Eval: 0.0511 s/iter. Total: 0.1739 s/iter. ETA=0:05:20
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 740])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 632])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 748])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:31:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:31:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 744])
[03/11 13:31:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 804])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:31:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 180, 240])
[03/11 13:31:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 292])
[03/11 13:31:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 300])
[03/11 13:31:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 208, 300])
[03/11 13:31:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 568])
[03/11 13:31:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 228])
[03/11 13:31:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:31:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 532])
[03/11 13:31:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:25 d2.evaluation.evaluator]: Inference done 194/2000. Dataloading: 0.0046 s/iter. Inference: 0.1145 s/iter. Eval: 0.0502 s/iter. Total: 0.1694 s/iter. ETA=0:05:06
[03/11 13:31:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 616])
[03/11 13:31:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 916])
[03/11 13:31:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 352])
[03/11 13:31:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 1244])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 280])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 696])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 452])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 796])
[03/11 13:31:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 500])
[03/11 13:31:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 300])
[03/11 13:31:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 288])
[03/11 13:31:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:31:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 304])
[03/11 13:31:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 648])
[03/11 13:31:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:31:30 d2.evaluation.evaluator]: Inference done 227/2000. Dataloading: 0.0045 s/iter. Inference: 0.1155 s/iter. Eval: 0.0479 s/iter. Total: 0.1680 s/iter. ETA=0:04:57
[03/11 13:31:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:31:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 756, 512])
[03/11 13:31:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 400])
[03/11 13:31:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:31:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:31:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 740, 512])
[03/11 13:31:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 1172])
[03/11 13:31:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 352])
[03/11 13:31:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 536])
[03/11 13:31:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 756, 512])
[03/11 13:31:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 540])
[03/11 13:31:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:31:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 608, 512])
[03/11 13:31:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 536])
[03/11 13:31:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 260, 384])
[03/11 13:31:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 572])
[03/11 13:31:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 632])
[03/11 13:31:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 692])
[03/11 13:31:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 352])
[03/11 13:31:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 472])
[03/11 13:31:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 300])
[03/11 13:31:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 636])
[03/11 13:31:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:35 d2.evaluation.evaluator]: Inference done 254/2000. Dataloading: 0.0045 s/iter. Inference: 0.1182 s/iter. Eval: 0.0472 s/iter. Total: 0.1701 s/iter. ETA=0:04:56
[03/11 13:31:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 420])
[03/11 13:31:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 496])
[03/11 13:31:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 800])
[03/11 13:31:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 648])
[03/11 13:31:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 412])
[03/11 13:31:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 528])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 500])
[03/11 13:31:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 740])
[03/11 13:31:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 432])
[03/11 13:31:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 260])
[03/11 13:31:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:40 d2.evaluation.evaluator]: Inference done 282/2000. Dataloading: 0.0046 s/iter. Inference: 0.1192 s/iter. Eval: 0.0473 s/iter. Total: 0.1713 s/iter. ETA=0:04:54
[03/11 13:31:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 908])
[03/11 13:31:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:31:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 192, 212])
[03/11 13:31:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 512])
[03/11 13:31:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 740])
[03/11 13:31:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:31:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:31:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 888])
[03/11 13:31:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 472])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 380])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 676])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 848])
[03/11 13:31:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 368])
[03/11 13:31:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:31:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 664])
[03/11 13:31:45 d2.evaluation.evaluator]: Inference done 310/2000. Dataloading: 0.0046 s/iter. Inference: 0.1195 s/iter. Eval: 0.0477 s/iter. Total: 0.1720 s/iter. ETA=0:04:50
[03/11 13:31:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 612])
[03/11 13:31:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 512])
[03/11 13:31:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:31:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 708, 512])
[03/11 13:31:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 548, 512])
[03/11 13:31:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 656])
[03/11 13:31:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 680])
[03/11 13:31:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 540])
[03/11 13:31:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:31:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 200])
[03/11 13:31:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:31:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 292])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 712, 400])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 308])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 400])
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:50 d2.evaluation.evaluator]: Inference done 341/2000. Dataloading: 0.0045 s/iter. Inference: 0.1189 s/iter. Eval: 0.0475 s/iter. Total: 0.1710 s/iter. ETA=0:04:43
[03/11 13:31:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 272])
[03/11 13:31:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 280, 400])
[03/11 13:31:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:31:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:31:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 620, 512])
[03/11 13:31:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 400])
[03/11 13:31:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 260, 300])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 364])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 252])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 776])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:56 d2.evaluation.evaluator]: Inference done 373/2000. Dataloading: 0.0044 s/iter. Inference: 0.1185 s/iter. Eval: 0.0470 s/iter. Total: 0.1700 s/iter. ETA=0:04:36
[03/11 13:31:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 688])
[03/11 13:31:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 652])
[03/11 13:31:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:31:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:31:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 300])
[03/11 13:31:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 188, 252])
[03/11 13:31:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 864])
[03/11 13:31:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 300])
[03/11 13:31:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:31:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 288, 464])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 228])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:31:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 452])
[03/11 13:32:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 452])
[03/11 13:32:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 260])
[03/11 13:32:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 664])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 688])
[03/11 13:32:01 d2.evaluation.evaluator]: Inference done 403/2000. Dataloading: 0.0043 s/iter. Inference: 0.1184 s/iter. Eval: 0.0471 s/iter. Total: 0.1699 s/iter. ETA=0:04:31
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 976, 976])
[03/11 13:32:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 636])
[03/11 13:32:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 720])
[03/11 13:32:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 600])
[03/11 13:32:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 300])
[03/11 13:32:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 352])
[03/11 13:32:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 448])
[03/11 13:32:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:06 d2.evaluation.evaluator]: Inference done 434/2000. Dataloading: 0.0043 s/iter. Inference: 0.1182 s/iter. Eval: 0.0467 s/iter. Total: 0.1694 s/iter. ETA=0:04:25
[03/11 13:32:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 480])
[03/11 13:32:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 488])
[03/11 13:32:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 580])
[03/11 13:32:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 572])
[03/11 13:32:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 404])
[03/11 13:32:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 468])
[03/11 13:32:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 512])
[03/11 13:32:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 636])
[03/11 13:32:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 336])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 228])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 784])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 656])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:32:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 572, 512])
[03/11 13:32:11 d2.evaluation.evaluator]: Inference done 465/2000. Dataloading: 0.0044 s/iter. Inference: 0.1185 s/iter. Eval: 0.0463 s/iter. Total: 0.1693 s/iter. ETA=0:04:19
[03/11 13:32:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 740])
[03/11 13:32:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 512])
[03/11 13:32:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 512])
[03/11 13:32:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 228])
[03/11 13:32:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 512])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 664])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 576])
[03/11 13:32:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:32:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 300])
[03/11 13:32:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:32:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:16 d2.evaluation.evaluator]: Inference done 495/2000. Dataloading: 0.0044 s/iter. Inference: 0.1186 s/iter. Eval: 0.0460 s/iter. Total: 0.1692 s/iter. ETA=0:04:14
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 668])
[03/11 13:32:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:32:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:32:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 600])
[03/11 13:32:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:32:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 300])
[03/11 13:32:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:32:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:32:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:32:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:32:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 696])
[03/11 13:32:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 712])
[03/11 13:32:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:21 d2.evaluation.evaluator]: Inference done 522/2000. Dataloading: 0.0044 s/iter. Inference: 0.1184 s/iter. Eval: 0.0471 s/iter. Total: 0.1700 s/iter. ETA=0:04:11
[03/11 13:32:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:32:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 592])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 780])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 352])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 212])
[03/11 13:32:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 500])
[03/11 13:32:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 748])
[03/11 13:32:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 348])
[03/11 13:32:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 900, 512])
[03/11 13:32:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:32:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 680])
[03/11 13:32:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:26 d2.evaluation.evaluator]: Inference done 548/2000. Dataloading: 0.0044 s/iter. Inference: 0.1197 s/iter. Eval: 0.0471 s/iter. Total: 0.1713 s/iter. ETA=0:04:08
[03/11 13:32:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 300])
[03/11 13:32:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 612])
[03/11 13:32:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 500])
[03/11 13:32:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 600])
[03/11 13:32:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:31 d2.evaluation.evaluator]: Inference done 579/2000. Dataloading: 0.0044 s/iter. Inference: 0.1199 s/iter. Eval: 0.0469 s/iter. Total: 0.1713 s/iter. ETA=0:04:03
[03/11 13:32:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:32:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 784])
[03/11 13:32:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 440])
[03/11 13:32:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 500])
[03/11 13:32:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 700])
[03/11 13:32:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 624])
[03/11 13:32:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 496])
[03/11 13:32:37 d2.evaluation.evaluator]: Inference done 606/2000. Dataloading: 0.0045 s/iter. Inference: 0.1204 s/iter. Eval: 0.0473 s/iter. Total: 0.1723 s/iter. ETA=0:04:00
[03/11 13:32:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 680])
[03/11 13:32:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 400])
[03/11 13:32:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:32:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 600])
[03/11 13:32:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:32:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:32:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 512])
[03/11 13:32:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 296])
[03/11 13:32:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 320])
[03/11 13:32:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:32:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 276, 304])
[03/11 13:32:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:32:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 340])
[03/11 13:32:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 484])
[03/11 13:32:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 260])
[03/11 13:32:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 288])
[03/11 13:32:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:32:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 268])
[03/11 13:32:42 d2.evaluation.evaluator]: Inference done 633/2000. Dataloading: 0.0045 s/iter. Inference: 0.1216 s/iter. Eval: 0.0467 s/iter. Total: 0.1729 s/iter. ETA=0:03:56
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:32:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 360])
[03/11 13:32:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:32:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 552])
[03/11 13:32:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 280])
[03/11 13:32:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 600])
[03/11 13:32:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 600])
[03/11 13:32:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 180, 288])
[03/11 13:32:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 752])
[03/11 13:32:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 828])
[03/11 13:32:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 564, 384])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 372])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 400])
[03/11 13:32:47 d2.evaluation.evaluator]: Inference done 661/2000. Dataloading: 0.0045 s/iter. Inference: 0.1221 s/iter. Eval: 0.0466 s/iter. Total: 0.1732 s/iter. ETA=0:03:51
[03/11 13:32:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 704])
[03/11 13:32:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 720])
[03/11 13:32:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 256])
[03/11 13:32:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 352])
[03/11 13:32:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 508])
[03/11 13:32:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 324, 480])
[03/11 13:32:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 504])
[03/11 13:32:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 568])
[03/11 13:32:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 600])
[03/11 13:32:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 572])
[03/11 13:32:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:32:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:32:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:32:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 512])
[03/11 13:32:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 676])
[03/11 13:32:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:32:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 392])
[03/11 13:32:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:32:52 d2.evaluation.evaluator]: Inference done 683/2000. Dataloading: 0.0044 s/iter. Inference: 0.1243 s/iter. Eval: 0.0464 s/iter. Total: 0.1753 s/iter. ETA=0:03:50
[03/11 13:32:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:32:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 732])
[03/11 13:32:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:32:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 400])
[03/11 13:32:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 288, 360])
[03/11 13:32:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 420])
[03/11 13:32:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 564])
[03/11 13:32:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 400])
[03/11 13:32:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:32:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:32:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 352])
[03/11 13:32:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 352])
[03/11 13:32:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:32:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:57 d2.evaluation.evaluator]: Inference done 709/2000. Dataloading: 0.0044 s/iter. Inference: 0.1253 s/iter. Eval: 0.0462 s/iter. Total: 0.1760 s/iter. ETA=0:03:47
[03/11 13:32:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 364])
[03/11 13:32:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 316])
[03/11 13:32:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 600])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 288])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 452])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 312])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 744, 512])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:32:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 352])
[03/11 13:32:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 612])
[03/11 13:32:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 220, 284])
[03/11 13:32:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:32:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 300])
[03/11 13:32:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 400])
[03/11 13:33:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 356])
[03/11 13:33:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:33:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 352])
[03/11 13:33:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 320])
[03/11 13:33:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 748])
[03/11 13:33:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 360])
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:33:02 d2.evaluation.evaluator]: Inference done 738/2000. Dataloading: 0.0043 s/iter. Inference: 0.1257 s/iter. Eval: 0.0458 s/iter. Total: 0.1759 s/iter. ETA=0:03:41
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 980])
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 288, 384])
[03/11 13:33:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 404])
[03/11 13:33:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 740, 512])
[03/11 13:33:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 564, 512])
[03/11 13:33:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 532])
[03/11 13:33:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 360])
[03/11 13:33:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:33:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 320])
[03/11 13:33:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 356])
[03/11 13:33:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:33:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 584])
[03/11 13:33:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 696])
[03/11 13:33:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 792, 512])
[03/11 13:33:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:33:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:07 d2.evaluation.evaluator]: Inference done 764/2000. Dataloading: 0.0043 s/iter. Inference: 0.1270 s/iter. Eval: 0.0452 s/iter. Total: 0.1766 s/iter. ETA=0:03:38
[03/11 13:33:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 728])
[03/11 13:33:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 360])
[03/11 13:33:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 452])
[03/11 13:33:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 460])
[03/11 13:33:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 340])
[03/11 13:33:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:12 d2.evaluation.evaluator]: Inference done 789/2000. Dataloading: 0.0043 s/iter. Inference: 0.1279 s/iter. Eval: 0.0451 s/iter. Total: 0.1774 s/iter. ETA=0:03:34
[03/11 13:33:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:17 d2.evaluation.evaluator]: Inference done 819/2000. Dataloading: 0.0043 s/iter. Inference: 0.1276 s/iter. Eval: 0.0450 s/iter. Total: 0.1770 s/iter. ETA=0:03:29
[03/11 13:33:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:22 d2.evaluation.evaluator]: Inference done 844/2000. Dataloading: 0.0043 s/iter. Inference: 0.1278 s/iter. Eval: 0.0455 s/iter. Total: 0.1777 s/iter. ETA=0:03:25
[03/11 13:33:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 552])
[03/11 13:33:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:27 d2.evaluation.evaluator]: Inference done 875/2000. Dataloading: 0.0044 s/iter. Inference: 0.1276 s/iter. Eval: 0.0451 s/iter. Total: 0.1772 s/iter. ETA=0:03:19
[03/11 13:33:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 348])
[03/11 13:33:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:33:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 452])
[03/11 13:33:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 480])
[03/11 13:33:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 480])
[03/11 13:33:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 520])
[03/11 13:33:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 776])
[03/11 13:33:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 480])
[03/11 13:33:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 500])
[03/11 13:33:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 600])
[03/11 13:33:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:33:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:33:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 360])
[03/11 13:33:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:33:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:32 d2.evaluation.evaluator]: Inference done 900/2000. Dataloading: 0.0043 s/iter. Inference: 0.1288 s/iter. Eval: 0.0449 s/iter. Total: 0.1781 s/iter. ETA=0:03:15
[03/11 13:33:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 420])
[03/11 13:33:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:33:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 584, 512])
[03/11 13:33:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:33:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:33:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:33:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 220, 272])
[03/11 13:33:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:33:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 376])
[03/11 13:33:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 332])
[03/11 13:33:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 300])
[03/11 13:33:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 888])
[03/11 13:33:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 692])
[03/11 13:33:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 496])
[03/11 13:33:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 280, 400])
[03/11 13:33:37 d2.evaluation.evaluator]: Inference done 923/2000. Dataloading: 0.0043 s/iter. Inference: 0.1301 s/iter. Eval: 0.0446 s/iter. Total: 0.1791 s/iter. ETA=0:03:12
[03/11 13:33:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 524, 392])
[03/11 13:33:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 300])
[03/11 13:33:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 220, 320])
[03/11 13:33:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:33:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 648])
[03/11 13:33:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:33:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:33:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 320])
[03/11 13:33:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 780])
[03/11 13:33:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:33:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:33:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 308, 228])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 300])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:33:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 700])
[03/11 13:33:43 d2.evaluation.evaluator]: Inference done 950/2000. Dataloading: 0.0043 s/iter. Inference: 0.1304 s/iter. Eval: 0.0446 s/iter. Total: 0.1794 s/iter. ETA=0:03:08
[03/11 13:33:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 340])
[03/11 13:33:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 340])
[03/11 13:33:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 700, 500])
[03/11 13:33:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 512])
[03/11 13:33:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:48 d2.evaluation.evaluator]: Inference done 975/2000. Dataloading: 0.0043 s/iter. Inference: 0.1311 s/iter. Eval: 0.0446 s/iter. Total: 0.1801 s/iter. ETA=0:03:04
[03/11 13:33:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 468])
[03/11 13:33:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 328])
[03/11 13:33:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 704])
[03/11 13:33:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 296])
[03/11 13:33:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 556])
[03/11 13:33:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 892])
[03/11 13:33:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 176, 252])
[03/11 13:33:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 268])
[03/11 13:33:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:33:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 252])
[03/11 13:33:53 d2.evaluation.evaluator]: Inference done 1000/2000. Dataloading: 0.0043 s/iter. Inference: 0.1322 s/iter. Eval: 0.0441 s/iter. Total: 0.1807 s/iter. ETA=0:03:00
[03/11 13:33:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:33:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:33:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 552, 552])
[03/11 13:33:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 260])
[03/11 13:33:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:33:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 592, 400])
[03/11 13:33:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 260, 348])
[03/11 13:33:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:33:58 d2.evaluation.evaluator]: Inference done 1019/2000. Dataloading: 0.0043 s/iter. Inference: 0.1338 s/iter. Eval: 0.0442 s/iter. Total: 0.1824 s/iter. ETA=0:02:58
[03/11 13:33:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:33:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 372])
[03/11 13:33:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 280, 300])
[03/11 13:33:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:33:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:33:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 576])
[03/11 13:34:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 804])
[03/11 13:34:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 984])
[03/11 13:34:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:34:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:34:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 660])
[03/11 13:34:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:34:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:34:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 688])
[03/11 13:34:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 300])
[03/11 13:34:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 308])
[03/11 13:34:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 760, 512])
[03/11 13:34:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:03 d2.evaluation.evaluator]: Inference done 1045/2000. Dataloading: 0.0043 s/iter. Inference: 0.1344 s/iter. Eval: 0.0440 s/iter. Total: 0.1827 s/iter. ETA=0:02:54
[03/11 13:34:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 240])
[03/11 13:34:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 340])
[03/11 13:34:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 512])
[03/11 13:34:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 708])
[03/11 13:34:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:34:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 688])
[03/11 13:34:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 300])
[03/11 13:34:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 328])
[03/11 13:34:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:34:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 756])
[03/11 13:34:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:34:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 300])
[03/11 13:34:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 400])
[03/11 13:34:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 796])
[03/11 13:34:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 276, 436])
[03/11 13:34:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 300])
[03/11 13:34:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 568])
[03/11 13:34:08 d2.evaluation.evaluator]: Inference done 1069/2000. Dataloading: 0.0042 s/iter. Inference: 0.1354 s/iter. Eval: 0.0437 s/iter. Total: 0.1834 s/iter. ETA=0:02:50
[03/11 13:34:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:34:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:34:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:34:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 336])
[03/11 13:34:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 732, 512])
[03/11 13:34:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:34:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 204])
[03/11 13:34:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 288, 288])
[03/11 13:34:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 580])
[03/11 13:34:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 732, 512])
[03/11 13:34:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:13 d2.evaluation.evaluator]: Inference done 1092/2000. Dataloading: 0.0042 s/iter. Inference: 0.1363 s/iter. Eval: 0.0437 s/iter. Total: 0.1844 s/iter. ETA=0:02:47
[03/11 13:34:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 752, 500])
[03/11 13:34:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 500])
[03/11 13:34:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 420])
[03/11 13:34:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 536, 400])
[03/11 13:34:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 172, 288])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 432])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:34:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:19 d2.evaluation.evaluator]: Inference done 1117/2000. Dataloading: 0.0042 s/iter. Inference: 0.1370 s/iter. Eval: 0.0435 s/iter. Total: 0.1848 s/iter. ETA=0:02:43
[03/11 13:34:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:34:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 248, 240])
[03/11 13:34:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 748])
[03/11 13:34:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 752])
[03/11 13:34:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 660])
[03/11 13:34:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 400])
[03/11 13:34:24 d2.evaluation.evaluator]: Inference done 1135/2000. Dataloading: 0.0042 s/iter. Inference: 0.1384 s/iter. Eval: 0.0436 s/iter. Total: 0.1863 s/iter. ETA=0:02:41
[03/11 13:34:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:34:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 248, 352])
[03/11 13:34:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 672])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 192, 256])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:34:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:34:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 696])
[03/11 13:34:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 496])
[03/11 13:34:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 700])
[03/11 13:34:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:34:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 220, 328])
[03/11 13:34:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 1600, 1600])
[03/11 13:34:29 d2.evaluation.evaluator]: Inference done 1157/2000. Dataloading: 0.0042 s/iter. Inference: 0.1392 s/iter. Eval: 0.0437 s/iter. Total: 0.1872 s/iter. ETA=0:02:37
[03/11 13:34:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 512])
[03/11 13:34:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:34:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:34:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 512])
[03/11 13:34:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 644])
[03/11 13:34:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 512])
[03/11 13:34:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:34:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:34 d2.evaluation.evaluator]: Inference done 1182/2000. Dataloading: 0.0042 s/iter. Inference: 0.1394 s/iter. Eval: 0.0438 s/iter. Total: 0.1876 s/iter. ETA=0:02:33
[03/11 13:34:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:34:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 432])
[03/11 13:34:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:34:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 400])
[03/11 13:34:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 652])
[03/11 13:34:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:34:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:34:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 500])
[03/11 13:34:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 560])
[03/11 13:34:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 692])
[03/11 13:34:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 532])
[03/11 13:34:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 308, 400])
[03/11 13:34:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:39 d2.evaluation.evaluator]: Inference done 1205/2000. Dataloading: 0.0042 s/iter. Inference: 0.1403 s/iter. Eval: 0.0435 s/iter. Total: 0.1882 s/iter. ETA=0:02:29
[03/11 13:34:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 512])
[03/11 13:34:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:34:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 428])
[03/11 13:34:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 352])
[03/11 13:34:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 376])
[03/11 13:34:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 500])
[03/11 13:34:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 500])
[03/11 13:34:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 700])
[03/11 13:34:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 480])
[03/11 13:34:44 d2.evaluation.evaluator]: Inference done 1228/2000. Dataloading: 0.0041 s/iter. Inference: 0.1413 s/iter. Eval: 0.0432 s/iter. Total: 0.1887 s/iter. ETA=0:02:25
[03/11 13:34:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 400])
[03/11 13:34:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 216])
[03/11 13:34:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:34:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 508])
[03/11 13:34:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:34:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 456])
[03/11 13:34:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:34:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:34:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 440])
[03/11 13:34:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 620])
[03/11 13:34:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 692])
[03/11 13:34:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 688])
[03/11 13:34:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 236])
[03/11 13:34:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:34:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:49 d2.evaluation.evaluator]: Inference done 1250/2000. Dataloading: 0.0041 s/iter. Inference: 0.1421 s/iter. Eval: 0.0431 s/iter. Total: 0.1894 s/iter. ETA=0:02:22
[03/11 13:34:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 284])
[03/11 13:34:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 680])
[03/11 13:34:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 308, 396])
[03/11 13:34:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:34:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:34:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:34:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:34:54 d2.evaluation.evaluator]: Inference done 1275/2000. Dataloading: 0.0041 s/iter. Inference: 0.1425 s/iter. Eval: 0.0430 s/iter. Total: 0.1897 s/iter. ETA=0:02:17
[03/11 13:34:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 208, 288])
[03/11 13:34:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 452])
[03/11 13:34:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 360])
[03/11 13:34:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 552])
[03/11 13:34:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:34:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:34:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 300])
[03/11 13:34:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 424])
[03/11 13:34:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 336])
[03/11 13:34:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:34:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:34:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:34:59 d2.evaluation.evaluator]: Inference done 1300/2000. Dataloading: 0.0041 s/iter. Inference: 0.1431 s/iter. Eval: 0.0429 s/iter. Total: 0.1902 s/iter. ETA=0:02:13
[03/11 13:34:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 276])
[03/11 13:35:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 300])
[03/11 13:35:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:35:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 236])
[03/11 13:35:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:35:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 584])
[03/11 13:35:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 520, 512])
[03/11 13:35:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:35:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:35:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 588])
[03/11 13:35:04 d2.evaluation.evaluator]: Inference done 1325/2000. Dataloading: 0.0041 s/iter. Inference: 0.1435 s/iter. Eval: 0.0427 s/iter. Total: 0.1904 s/iter. ETA=0:02:08
[03/11 13:35:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 288, 252])
[03/11 13:35:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 300])
[03/11 13:35:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 256])
[03/11 13:35:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:35:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:35:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:35:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 428])
[03/11 13:35:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 212])
[03/11 13:35:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 692])
[03/11 13:35:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 664])
[03/11 13:35:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 636])
[03/11 13:35:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:09 d2.evaluation.evaluator]: Inference done 1348/2000. Dataloading: 0.0041 s/iter. Inference: 0.1440 s/iter. Eval: 0.0427 s/iter. Total: 0.1909 s/iter. ETA=0:02:04
[03/11 13:35:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 212])
[03/11 13:35:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:35:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:35:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 320])
[03/11 13:35:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 220, 300])
[03/11 13:35:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 744, 472])
[03/11 13:35:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 308])
[03/11 13:35:15 d2.evaluation.evaluator]: Inference done 1371/2000. Dataloading: 0.0041 s/iter. Inference: 0.1448 s/iter. Eval: 0.0425 s/iter. Total: 0.1914 s/iter. ETA=0:02:00
[03/11 13:35:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 288, 400])
[03/11 13:35:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 692])
[03/11 13:35:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 304])
[03/11 13:35:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 780, 512])
[03/11 13:35:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 484])
[03/11 13:35:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 440])
[03/11 13:35:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 208, 312])
[03/11 13:35:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 196, 252])
[03/11 13:35:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 452])
[03/11 13:35:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 448])
[03/11 13:35:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 480])
[03/11 13:35:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 480])
[03/11 13:35:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:20 d2.evaluation.evaluator]: Inference done 1395/2000. Dataloading: 0.0041 s/iter. Inference: 0.1453 s/iter. Eval: 0.0424 s/iter. Total: 0.1918 s/iter. ETA=0:01:56
[03/11 13:35:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 432])
[03/11 13:35:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 704])
[03/11 13:35:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 312])
[03/11 13:35:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:35:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 356])
[03/11 13:35:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:25 d2.evaluation.evaluator]: Inference done 1413/2000. Dataloading: 0.0040 s/iter. Inference: 0.1464 s/iter. Eval: 0.0424 s/iter. Total: 0.1929 s/iter. ETA=0:01:53
[03/11 13:35:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 500])
[03/11 13:35:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:35:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 384])
[03/11 13:35:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 572, 400])
[03/11 13:35:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 488])
[03/11 13:35:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 252])
[03/11 13:35:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 356])
[03/11 13:35:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 352])
[03/11 13:35:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 888])
[03/11 13:35:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:30 d2.evaluation.evaluator]: Inference done 1434/2000. Dataloading: 0.0040 s/iter. Inference: 0.1472 s/iter. Eval: 0.0423 s/iter. Total: 0.1937 s/iter. ETA=0:01:49
[03/11 13:35:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 680])
[03/11 13:35:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 404])
[03/11 13:35:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 500])
[03/11 13:35:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:35:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 636])
[03/11 13:35:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:35:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 360])
[03/11 13:35:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 544])
[03/11 13:35:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:35:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 248])
[03/11 13:35:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 232])
[03/11 13:35:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:35:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:35:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:35 d2.evaluation.evaluator]: Inference done 1457/2000. Dataloading: 0.0040 s/iter. Inference: 0.1479 s/iter. Eval: 0.0421 s/iter. Total: 0.1941 s/iter. ETA=0:01:45
[03/11 13:35:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 300])
[03/11 13:35:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 672])
[03/11 13:35:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 576])
[03/11 13:35:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 512])
[03/11 13:35:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:40 d2.evaluation.evaluator]: Inference done 1478/2000. Dataloading: 0.0040 s/iter. Inference: 0.1486 s/iter. Eval: 0.0421 s/iter. Total: 0.1948 s/iter. ETA=0:01:41
[03/11 13:35:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 228])
[03/11 13:35:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 228])
[03/11 13:35:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:35:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:35:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 228])
[03/11 13:35:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 500])
[03/11 13:35:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:35:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 360])
[03/11 13:35:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:35:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 868])
[03/11 13:35:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:35:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:35:45 d2.evaluation.evaluator]: Inference done 1504/2000. Dataloading: 0.0040 s/iter. Inference: 0.1488 s/iter. Eval: 0.0419 s/iter. Total: 0.1948 s/iter. ETA=0:01:36
[03/11 13:35:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 700])
[03/11 13:35:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:35:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:35:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 788])
[03/11 13:35:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 808])
[03/11 13:35:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 720])
[03/11 13:35:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 656])
[03/11 13:35:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 680])
[03/11 13:35:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:35:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 736])
[03/11 13:35:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:35:50 d2.evaluation.evaluator]: Inference done 1526/2000. Dataloading: 0.0040 s/iter. Inference: 0.1492 s/iter. Eval: 0.0421 s/iter. Total: 0.1954 s/iter. ETA=0:01:32
[03/11 13:35:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:35:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:35:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 816])
[03/11 13:35:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:35:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 352])
[03/11 13:35:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:35:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 344])
[03/11 13:35:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:35:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:35:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:35:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 252])
[03/11 13:35:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:35:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 376])
[03/11 13:35:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:35:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:35:55 d2.evaluation.evaluator]: Inference done 1548/2000. Dataloading: 0.0040 s/iter. Inference: 0.1497 s/iter. Eval: 0.0422 s/iter. Total: 0.1960 s/iter. ETA=0:01:28
[03/11 13:35:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 448])
[03/11 13:35:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 388])
[03/11 13:35:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 716])
[03/11 13:35:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:35:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 336])
[03/11 13:35:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:35:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:35:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:35:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:35:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:00 d2.evaluation.evaluator]: Inference done 1570/2000. Dataloading: 0.0040 s/iter. Inference: 0.1501 s/iter. Eval: 0.0422 s/iter. Total: 0.1964 s/iter. ETA=0:01:24
[03/11 13:36:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:36:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:36:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 512])
[03/11 13:36:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:36:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:06 d2.evaluation.evaluator]: Inference done 1592/2000. Dataloading: 0.0040 s/iter. Inference: 0.1506 s/iter. Eval: 0.0423 s/iter. Total: 0.1970 s/iter. ETA=0:01:20
[03/11 13:36:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 756])
[03/11 13:36:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 296])
[03/11 13:36:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 400])
[03/11 13:36:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 452])
[03/11 13:36:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 392])
[03/11 13:36:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 620])
[03/11 13:36:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 460])
[03/11 13:36:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:36:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:36:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 276, 368])
[03/11 13:36:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:11 d2.evaluation.evaluator]: Inference done 1616/2000. Dataloading: 0.0040 s/iter. Inference: 0.1510 s/iter. Eval: 0.0422 s/iter. Total: 0.1973 s/iter. ETA=0:01:15
[03/11 13:36:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 280])
[03/11 13:36:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 704])
[03/11 13:36:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 680, 512])
[03/11 13:36:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:36:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 700])
[03/11 13:36:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:36:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 680])
[03/11 13:36:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 896, 512])
[03/11 13:36:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 400])
[03/11 13:36:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 384])
[03/11 13:36:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 300])
[03/11 13:36:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:36:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:16 d2.evaluation.evaluator]: Inference done 1638/2000. Dataloading: 0.0040 s/iter. Inference: 0.1515 s/iter. Eval: 0.0421 s/iter. Total: 0.1977 s/iter. ETA=0:01:11
[03/11 13:36:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 628, 512])
[03/11 13:36:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 400])
[03/11 13:36:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 352])
[03/11 13:36:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:36:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 336])
[03/11 13:36:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 344])
[03/11 13:36:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 652])
[03/11 13:36:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:36:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:36:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 280, 200])
[03/11 13:36:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 200])
[03/11 13:36:21 d2.evaluation.evaluator]: Inference done 1659/2000. Dataloading: 0.0040 s/iter. Inference: 0.1522 s/iter. Eval: 0.0421 s/iter. Total: 0.1983 s/iter. ETA=0:01:07
[03/11 13:36:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:36:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 444])
[03/11 13:36:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 500])
[03/11 13:36:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 592])
[03/11 13:36:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 356])
[03/11 13:36:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 296])
[03/11 13:36:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:36:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 260, 200])
[03/11 13:36:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 676])
[03/11 13:36:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 280])
[03/11 13:36:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 264])
[03/11 13:36:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:36:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 588])
[03/11 13:36:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:36:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:36:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 416])
[03/11 13:36:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:36:26 d2.evaluation.evaluator]: Inference done 1680/2000. Dataloading: 0.0040 s/iter. Inference: 0.1529 s/iter. Eval: 0.0419 s/iter. Total: 0.1989 s/iter. ETA=0:01:03
[03/11 13:36:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 200])
[03/11 13:36:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 296])
[03/11 13:36:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 216])
[03/11 13:36:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 252, 336])
[03/11 13:36:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 748, 512])
[03/11 13:36:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 616])
[03/11 13:36:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 460])
[03/11 13:36:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 400])
[03/11 13:36:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 760])
[03/11 13:36:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:36:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 740])
[03/11 13:36:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:31 d2.evaluation.evaluator]: Inference done 1702/2000. Dataloading: 0.0040 s/iter. Inference: 0.1534 s/iter. Eval: 0.0419 s/iter. Total: 0.1994 s/iter. ETA=0:00:59
[03/11 13:36:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 600])
[03/11 13:36:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 800])
[03/11 13:36:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 300])
[03/11 13:36:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 676, 512])
[03/11 13:36:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:36:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 596])
[03/11 13:36:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:36:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 444])
[03/11 13:36:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 688])
[03/11 13:36:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 432])
[03/11 13:36:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 292])
[03/11 13:36:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 480])
[03/11 13:36:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:36:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 352])
[03/11 13:36:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:36:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:37 d2.evaluation.evaluator]: Inference done 1725/2000. Dataloading: 0.0040 s/iter. Inference: 0.1538 s/iter. Eval: 0.0418 s/iter. Total: 0.1997 s/iter. ETA=0:00:54
[03/11 13:36:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 556])
[03/11 13:36:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 548])
[03/11 13:36:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:36:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 844])
[03/11 13:36:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 780])
[03/11 13:36:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 360])
[03/11 13:36:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 292])
[03/11 13:36:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 512])
[03/11 13:36:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 664])
[03/11 13:36:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 360])
[03/11 13:36:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:36:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 408])
[03/11 13:36:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:36:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 540])
[03/11 13:36:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:36:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:42 d2.evaluation.evaluator]: Inference done 1748/2000. Dataloading: 0.0040 s/iter. Inference: 0.1543 s/iter. Eval: 0.0416 s/iter. Total: 0.2000 s/iter. ETA=0:00:50
[03/11 13:36:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:36:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 632])
[03/11 13:36:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:36:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 252])
[03/11 13:36:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:36:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 200])
[03/11 13:36:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:36:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 772])
[03/11 13:36:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 560])
[03/11 13:36:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 576])
[03/11 13:36:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:36:47 d2.evaluation.evaluator]: Inference done 1772/2000. Dataloading: 0.0039 s/iter. Inference: 0.1547 s/iter. Eval: 0.0414 s/iter. Total: 0.2001 s/iter. ETA=0:00:45
[03/11 13:36:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:36:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 784, 512])
[03/11 13:36:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 252])
[03/11 13:36:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:36:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:52 d2.evaluation.evaluator]: Inference done 1794/2000. Dataloading: 0.0039 s/iter. Inference: 0.1550 s/iter. Eval: 0.0415 s/iter. Total: 0.2005 s/iter. ETA=0:00:41
[03/11 13:36:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:36:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:57 d2.evaluation.evaluator]: Inference done 1816/2000. Dataloading: 0.0039 s/iter. Inference: 0.1553 s/iter. Eval: 0.0415 s/iter. Total: 0.2008 s/iter. ETA=0:00:36
[03/11 13:36:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:36:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:36:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:37:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:37:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:02 d2.evaluation.evaluator]: Inference done 1841/2000. Dataloading: 0.0039 s/iter. Inference: 0.1553 s/iter. Eval: 0.0416 s/iter. Total: 0.2009 s/iter. ETA=0:00:31
[03/11 13:37:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:07 d2.evaluation.evaluator]: Inference done 1864/2000. Dataloading: 0.0039 s/iter. Inference: 0.1555 s/iter. Eval: 0.0416 s/iter. Total: 0.2011 s/iter. ETA=0:00:27
[03/11 13:37:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 352])
[03/11 13:37:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:37:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:37:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 408])
[03/11 13:37:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:37:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 204, 252])
[03/11 13:37:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 384])
[03/11 13:37:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 864])
[03/11 13:37:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:12 d2.evaluation.evaluator]: Inference done 1887/2000. Dataloading: 0.0039 s/iter. Inference: 0.1559 s/iter. Eval: 0.0414 s/iter. Total: 0.2013 s/iter. ETA=0:00:22
[03/11 13:37:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 432])
[03/11 13:37:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 948, 512])
[03/11 13:37:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 404])
[03/11 13:37:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 576])
[03/11 13:37:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 220, 292])
[03/11 13:37:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 572])
[03/11 13:37:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 292])
[03/11 13:37:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 776, 512])
[03/11 13:37:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 440])
[03/11 13:37:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 600])
[03/11 13:37:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 280, 280])
[03/11 13:37:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 480])
[03/11 13:37:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 208, 260])
[03/11 13:37:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:37:17 d2.evaluation.evaluator]: Inference done 1912/2000. Dataloading: 0.0039 s/iter. Inference: 0.1561 s/iter. Eval: 0.0413 s/iter. Total: 0.2014 s/iter. ETA=0:00:17
[03/11 13:37:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 224, 536])
[03/11 13:37:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 692, 512])
[03/11 13:37:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 260, 400])
[03/11 13:37:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 672, 504])
[03/11 13:37:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 252])
[03/11 13:37:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 312])
[03/11 13:37:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:37:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:37:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:37:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 300])
[03/11 13:37:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 508])
[03/11 13:37:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 472])
[03/11 13:37:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 720])
[03/11 13:37:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 236])
[03/11 13:37:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:37:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:22 d2.evaluation.evaluator]: Inference done 1934/2000. Dataloading: 0.0039 s/iter. Inference: 0.1566 s/iter. Eval: 0.0411 s/iter. Total: 0.2017 s/iter. ETA=0:00:13
[03/11 13:37:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 768, 512])
[03/11 13:37:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:37:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 300])
[03/11 13:37:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 300])
[03/11 13:37:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:37:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:37:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 684, 512])
[03/11 13:37:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 452])
[03/11 13:37:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 304])
[03/11 13:37:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 212, 240])
[03/11 13:37:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 228])
[03/11 13:37:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:37:27 d2.evaluation.evaluator]: Inference done 1959/2000. Dataloading: 0.0039 s/iter. Inference: 0.1568 s/iter. Eval: 0.0410 s/iter. Total: 0.2017 s/iter. ETA=0:00:08
[03/11 13:37:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:37:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 720, 512])
[03/11 13:37:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 724])
[03/11 13:37:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:37:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 712])
[03/11 13:37:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 688])
[03/11 13:37:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 764])
[03/11 13:37:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 768])
[03/11 13:37:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 176, 240])
[03/11 13:37:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 604])
[03/11 13:37:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:32 d2.evaluation.evaluator]: Inference done 1982/2000. Dataloading: 0.0038 s/iter. Inference: 0.1571 s/iter. Eval: 0.0409 s/iter. Total: 0.2020 s/iter. ETA=0:00:03
[03/11 13:37:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 776])
[03/11 13:37:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 384])
[03/11 13:37:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 400])
[03/11 13:37:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 772, 512])
[03/11 13:37:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 236])
[03/11 13:37:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 800])
[03/11 13:37:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 684])
[03/11 13:37:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:37:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 260])
[03/11 13:37:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 256])
[03/11 13:37:37 d2.evaluation.evaluator]: Total inference time: 0:06:43.812952 (0.202413 s / iter per device, on 1 devices)
[03/11 13:37:37 d2.evaluation.evaluator]: Total inference pure compute time: 0:05:14 (0.157572 s / iter per device, on 1 devices)
[03/11 13:37:38 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 0.06400976139002842, 'fwIoU': 0.5533640205306564, 'IoU-flag': 0.0, 'BoundaryIoU-flag': 58.82425985470583, 'min(IoU, B-Iou)-flag': 0.0, 'IoU-wall': 2.872107922174709, 'BoundaryIoU-wall': 2.2749523260412996, 'min(IoU, B-Iou)-wall': 2.2749523260412996, 'IoU-building, edifice': 0.6868250711124845, 'BoundaryIoU-building, edifice': 0.0, 'min(IoU, B-Iou)-building, edifice': 0.0, 'IoU-sky': 0.06100584252931062, 'BoundaryIoU-sky': 0.0, 'min(IoU, B-Iou)-sky': 0.0, 'IoU-floor, flooring': 0.2398331186175235, 'BoundaryIoU-floor, flooring': 0.0, 'min(IoU, B-Iou)-floor, flooring': 0.0, 'IoU-tree': 1.5028380177660905, 'BoundaryIoU-tree': 0.0, 'min(IoU, B-Iou)-tree': 0.0, 'IoU-ceiling': 2.9599829544448262e-05, 'BoundaryIoU-ceiling': 0.0, 'min(IoU, B-Iou)-ceiling': 0.0, 'IoU-road, route': 1.6177382664553943, 'BoundaryIoU-road, route': 0.0, 'min(IoU, B-Iou)-road, route': 0.0, 'IoU-bed ': 0.06350063412618949, 'BoundaryIoU-bed ': 0.0, 'min(IoU, B-Iou)-bed ': 0.0, 'IoU-windowpane, window ': 0.00039430788675400556, 'BoundaryIoU-windowpane, window ': 0.0, 'min(IoU, B-Iou)-windowpane, window ': 0.0, 'IoU-grass': 0.06487537324431385, 'BoundaryIoU-grass': 0.0, 'min(IoU, B-Iou)-grass': 0.0, 'IoU-cabinet': 0.0, 'BoundaryIoU-cabinet': 0.0, 'min(IoU, B-Iou)-cabinet': 0.0, 'IoU-sidewalk, pavement': 0.4405193616620374, 'BoundaryIoU-sidewalk, pavement': 0.0, 'min(IoU, B-Iou)-sidewalk, pavement': 0.0, 'IoU-person, individual, someone, somebody, mortal, soul': 0.3507356042643929, 'BoundaryIoU-person, individual, someone, somebody, mortal, soul': 0.0, 'min(IoU, B-Iou)-person, individual, someone, somebody, mortal, soul': 0.0, 'IoU-earth, ground': 0.010494824444685698, 'BoundaryIoU-earth, ground': 0.0, 'min(IoU, B-Iou)-earth, ground': 0.0, 'IoU-door, double door': 0.0040388383630830076, 'BoundaryIoU-door, double door': 0.0, 'min(IoU, B-Iou)-door, double door': 0.0, 'IoU-table': 0.05075636539724468, 'BoundaryIoU-table': 0.0, 'min(IoU, B-Iou)-table': 0.0, 'IoU-mountain, mount': 0.06025404386040653, 'BoundaryIoU-mountain, mount': 0.0, 'min(IoU, B-Iou)-mountain, mount': 0.0, 'IoU-plant, flora, plant life': 0.09818220459016747, 'BoundaryIoU-plant, flora, plant life': 0.0, 'min(IoU, B-Iou)-plant, flora, plant life': 0.0, 'IoU-curtain, drape, drapery, mantle, pall': 0.002806068317317579, 'BoundaryIoU-curtain, drape, drapery, mantle, pall': 0.0, 'min(IoU, B-Iou)-curtain, drape, drapery, mantle, pall': 0.0, 'IoU-chair': 0.5981089021175778, 'BoundaryIoU-chair': 0.0, 'min(IoU, B-Iou)-chair': 0.0, 'IoU-car, auto, automobile, machine, motorcar': 0.5377329308206091, 'BoundaryIoU-car, auto, automobile, machine, motorcar': 0.0, 'min(IoU, B-Iou)-car, auto, automobile, machine, motorcar': 0.0, 'IoU-water': 0.0005550096034005438, 'BoundaryIoU-water': 0.0, 'min(IoU, B-Iou)-water': 0.0, 'IoU-painting, picture': 0.002889024087663187, 'BoundaryIoU-painting, picture': 0.0, 'min(IoU, B-Iou)-painting, picture': 0.0, 'IoU-sofa, couch, lounge': 0.0, 'BoundaryIoU-sofa, couch, lounge': 0.0, 'min(IoU, B-Iou)-sofa, couch, lounge': 0.0, 'IoU-shelf': 0.020969153698485215, 'BoundaryIoU-shelf': 0.0, 'min(IoU, B-Iou)-shelf': 0.0, 'IoU-house': 0.0, 'BoundaryIoU-house': 0.0, 'min(IoU, B-Iou)-house': 0.0, 'IoU-sea': 0.0, 'BoundaryIoU-sea': 0.0, 'min(IoU, B-Iou)-sea': 0.0, 'IoU-mirror': 0.0, 'BoundaryIoU-mirror': 0.0, 'min(IoU, B-Iou)-mirror': 0.0, 'IoU-rug, carpet, carpeting': 0.0, 'BoundaryIoU-rug, carpet, carpeting': 0.0, 'min(IoU, B-Iou)-rug, carpet, carpeting': 0.0, 'IoU-field': 0.2506483578197889, 'BoundaryIoU-field': 0.0, 'min(IoU, B-Iou)-field': 0.0, 'IoU-armchair': 0.0, 'BoundaryIoU-armchair': 0.0, 'min(IoU, B-Iou)-armchair': 0.0, 'IoU-seat': 0.016889625697146252, 'BoundaryIoU-seat': 0.0, 'min(IoU, B-Iou)-seat': 0.0, 'IoU-fence, fencing': 0.0019008241213060333, 'BoundaryIoU-fence, fencing': 0.0, 'min(IoU, B-Iou)-fence, fencing': 0.0, 'IoU-desk': 0.0001217678994245858, 'BoundaryIoU-desk': 0.0, 'min(IoU, B-Iou)-desk': 0.0, 'IoU-rock, stone': 0.0, 'BoundaryIoU-rock, stone': 0.0, 'min(IoU, B-Iou)-rock, stone': 0.0, 'IoU-wardrobe, closet, press': 0.0, 'BoundaryIoU-wardrobe, closet, press': 0.0, 'min(IoU, B-Iou)-wardrobe, closet, press': 0.0, 'IoU-lamp': 0.0, 'BoundaryIoU-lamp': 0.0, 'min(IoU, B-Iou)-lamp': 0.0, 'IoU-bathtub, bathing tub, bath, tub': 0.0, 'BoundaryIoU-bathtub, bathing tub, bath, tub': 0.0, 'min(IoU, B-Iou)-bathtub, bathing tub, bath, tub': 0.0, 'IoU-railing, rail': 0.0, 'BoundaryIoU-railing, rail': 0.0, 'min(IoU, B-Iou)-railing, rail': 0.0, 'IoU-cushion': 0.0, 'BoundaryIoU-cushion': 0.0, 'min(IoU, B-Iou)-cushion': 0.0, 'IoU-base, pedestal, stand': 0.0, 'BoundaryIoU-base, pedestal, stand': 0.0, 'min(IoU, B-Iou)-base, pedestal, stand': 0.0, 'IoU-box': 0.0, 'BoundaryIoU-box': 0.0, 'min(IoU, B-Iou)-box': 0.0, 'IoU-column, pillar': 0.0, 'BoundaryIoU-column, pillar': 0.0, 'min(IoU, B-Iou)-column, pillar': 0.0, 'IoU-signboard, sign': 0.0, 'BoundaryIoU-signboard, sign': 0.0, 'min(IoU, B-Iou)-signboard, sign': 0.0, 'IoU-chest of drawers, chest, bureau, dresser': 0.00011774360858256711, 'BoundaryIoU-chest of drawers, chest, bureau, dresser': 0.0, 'min(IoU, B-Iou)-chest of drawers, chest, bureau, dresser': 0.0, 'IoU-counter': 0.0, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-sand': 0.023493665391606307, 'BoundaryIoU-sand': 0.0, 'min(IoU, B-Iou)-sand': 0.0, 'IoU-sink': 0.0, 'BoundaryIoU-sink': 0.0, 'min(IoU, B-Iou)-sink': 0.0, 'IoU-skyscraper': 0.0, 'BoundaryIoU-skyscraper': 0.0, 'min(IoU, B-Iou)-skyscraper': 0.0, 'IoU-fireplace, hearth, open fireplace': 0.0, 'BoundaryIoU-fireplace, hearth, open fireplace': 0.0, 'min(IoU, B-Iou)-fireplace, hearth, open fireplace': 0.0, 'IoU-refrigerator, icebox': 0.0, 'BoundaryIoU-refrigerator, icebox': 0.0, 'min(IoU, B-Iou)-refrigerator, icebox': 0.0, 'IoU-grandstand, covered stand': 0.0, 'BoundaryIoU-grandstand, covered stand': 0.0, 'min(IoU, B-Iou)-grandstand, covered stand': 0.0, 'IoU-path': 0.0, 'BoundaryIoU-path': 0.0, 'min(IoU, B-Iou)-path': 0.0, 'IoU-stairs, steps': 0.0, 'BoundaryIoU-stairs, steps': 0.0, 'min(IoU, B-Iou)-stairs, steps': 0.0, 'IoU-runway': 0.0, 'BoundaryIoU-runway': 0.0, 'min(IoU, B-Iou)-runway': 0.0, 'IoU-case, display case, showcase, vitrine': 0.0, 'BoundaryIoU-case, display case, showcase, vitrine': 0.0, 'min(IoU, B-Iou)-case, display case, showcase, vitrine': 0.0, 'IoU-pool table, billiard table, snooker table': 0.0, 'BoundaryIoU-pool table, billiard table, snooker table': 0.0, 'min(IoU, B-Iou)-pool table, billiard table, snooker table': 0.0, 'IoU-pillow': 0.0, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-screen door, screen': 0.0, 'BoundaryIoU-screen door, screen': 0.0, 'min(IoU, B-Iou)-screen door, screen': 0.0, 'IoU-stairway, staircase': 0.0, 'BoundaryIoU-stairway, staircase': 0.0, 'min(IoU, B-Iou)-stairway, staircase': 0.0, 'IoU-river': 0.018670282805652184, 'BoundaryIoU-river': 0.0, 'min(IoU, B-Iou)-river': 0.0, 'IoU-bridge, span': 0.0, 'BoundaryIoU-bridge, span': 0.0, 'min(IoU, B-Iou)-bridge, span': 0.0, 'IoU-bookcase': 7.828180824714505e-05, 'BoundaryIoU-bookcase': 0.0, 'min(IoU, B-Iou)-bookcase': 0.0, 'IoU-blind, screen': 0.0, 'BoundaryIoU-blind, screen': 0.0, 'min(IoU, B-Iou)-blind, screen': 0.0, 'IoU-coffee table, cocktail table': 0.0, 'BoundaryIoU-coffee table, cocktail table': 0.0, 'min(IoU, B-Iou)-coffee table, cocktail table': 0.0, 'IoU-toilet, can, commode, crapper, pot, potty, stool, throne': 0.0, 'BoundaryIoU-toilet, can, commode, crapper, pot, potty, stool, throne': 0.0, 'min(IoU, B-Iou)-toilet, can, commode, crapper, pot, potty, stool, throne': 0.0, 'IoU-flower': 0.000356860554953849, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-book': 0.0, 'BoundaryIoU-book': 0.0, 'min(IoU, B-Iou)-book': 0.0, 'IoU-hill': 0.0, 'BoundaryIoU-hill': 0.0, 'min(IoU, B-Iou)-hill': 0.0, 'IoU-bench': 0.0, 'BoundaryIoU-bench': 0.0, 'min(IoU, B-Iou)-bench': 0.0, 'IoU-countertop': 0.0, 'BoundaryIoU-countertop': 0.0, 'min(IoU, B-Iou)-countertop': 0.0, 'IoU-stove, kitchen stove, range, kitchen range, cooking stove': 0.0, 'BoundaryIoU-stove, kitchen stove, range, kitchen range, cooking stove': 0.0, 'min(IoU, B-Iou)-stove, kitchen stove, range, kitchen range, cooking stove': 0.0, 'IoU-palm, palm tree': 0.0, 'BoundaryIoU-palm, palm tree': 0.0, 'min(IoU, B-Iou)-palm, palm tree': 0.0, 'IoU-kitchen island': 0.0, 'BoundaryIoU-kitchen island': 0.0, 'min(IoU, B-Iou)-kitchen island': 0.0, 'IoU-computer, computing machine, computing device, data processor, electronic computer, information processing system': 0.0, 'BoundaryIoU-computer, computing machine, computing device, data processor, electronic computer, information processing system': 0.0, 'min(IoU, B-Iou)-computer, computing machine, computing device, data processor, electronic computer, information processing system': 0.0, 'IoU-swivel chair': 0.0, 'BoundaryIoU-swivel chair': 0.0, 'min(IoU, B-Iou)-swivel chair': 0.0, 'IoU-boat': 0.0, 'BoundaryIoU-boat': 0.0, 'min(IoU, B-Iou)-boat': 0.0, 'IoU-bar': 0.0, 'BoundaryIoU-bar': 0.0, 'min(IoU, B-Iou)-bar': 0.0, 'IoU-arcade machine': 0.0, 'BoundaryIoU-arcade machine': 0.0, 'min(IoU, B-Iou)-arcade machine': 0.0, 'IoU-hovel, hut, hutch, shack, shanty': 0.000941728212529223, 'BoundaryIoU-hovel, hut, hutch, shack, shanty': 0.0, 'min(IoU, B-Iou)-hovel, hut, hutch, shack, shanty': 0.0, 'IoU-bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle': 0.0, 'BoundaryIoU-bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle': 0.0, 'min(IoU, B-Iou)-bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle': 0.0, 'IoU-towel': 0.0, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-light, light source': 0.0, 'BoundaryIoU-light, light source': 0.0, 'min(IoU, B-Iou)-light, light source': 0.0, 'IoU-truck, motortruck': 0.0, 'BoundaryIoU-truck, motortruck': 0.0, 'min(IoU, B-Iou)-truck, motortruck': 0.0, 'IoU-tower': 0.0, 'BoundaryIoU-tower': 0.0, 'min(IoU, B-Iou)-tower': 0.0, 'IoU-chandelier, pendant, pendent': 0.0, 'BoundaryIoU-chandelier, pendant, pendent': 0.0, 'min(IoU, B-Iou)-chandelier, pendant, pendent': 0.0, 'IoU-awning, sunshade, sunblind': 0.0, 'BoundaryIoU-awning, sunshade, sunblind': 0.0, 'min(IoU, B-Iou)-awning, sunshade, sunblind': 0.0, 'IoU-streetlight, street lamp': 0.0, 'BoundaryIoU-streetlight, street lamp': 0.0, 'min(IoU, B-Iou)-streetlight, street lamp': 0.0, 'IoU-booth, cubicle, stall, kiosk': 0.0, 'BoundaryIoU-booth, cubicle, stall, kiosk': 0.0, 'min(IoU, B-Iou)-booth, cubicle, stall, kiosk': 0.0, 'IoU-television receiver, television, television set, tv, tv set, idiot box, boob tube, telly, goggle box': 0.0, 'BoundaryIoU-television receiver, television, television set, tv, tv set, idiot box, boob tube, telly, goggle box': 0.0, 'min(IoU, B-Iou)-television receiver, television, television set, tv, tv set, idiot box, boob tube, telly, goggle box': 0.0, 'IoU-airplane, aeroplane, plane': 0.0, 'BoundaryIoU-airplane, aeroplane, plane': 0.0, 'min(IoU, B-Iou)-airplane, aeroplane, plane': 0.0, 'IoU-dirt track': 0.0, 'BoundaryIoU-dirt track': 0.0, 'min(IoU, B-Iou)-dirt track': 0.0, 'IoU-apparel, wearing apparel, dress, clothes': 0.0, 'BoundaryIoU-apparel, wearing apparel, dress, clothes': 0.0, 'min(IoU, B-Iou)-apparel, wearing apparel, dress, clothes': 0.0, 'IoU-pole': 0.0006492384027761434, 'BoundaryIoU-pole': 0.0, 'min(IoU, B-Iou)-pole': 0.0, 'IoU-land, ground, soil': 0.0, 'BoundaryIoU-land, ground, soil': 0.0, 'min(IoU, B-Iou)-land, ground, soil': 0.0, 'IoU-bannister, banister, balustrade, balusters, handrail': 0.0, 'BoundaryIoU-bannister, banister, balustrade, balusters, handrail': 0.0, 'min(IoU, B-Iou)-bannister, banister, balustrade, balusters, handrail': 0.0, 'IoU-escalator, moving staircase, moving stairway': 0.0, 'BoundaryIoU-escalator, moving staircase, moving stairway': 0.0, 'min(IoU, B-Iou)-escalator, moving staircase, moving stairway': 0.0, 'IoU-ottoman, pouf, pouffe, puff, hassock': 0.0, 'BoundaryIoU-ottoman, pouf, pouffe, puff, hassock': 0.0, 'min(IoU, B-Iou)-ottoman, pouf, pouffe, puff, hassock': 0.0, 'IoU-bottle': 0.0, 'BoundaryIoU-bottle': 0.0, 'min(IoU, B-Iou)-bottle': 0.0, 'IoU-buffet, counter, sideboard': 0.0, 'BoundaryIoU-buffet, counter, sideboard': 0.0, 'min(IoU, B-Iou)-buffet, counter, sideboard': 0.0, 'IoU-poster, posting, placard, notice, bill, card': 0.0, 'BoundaryIoU-poster, posting, placard, notice, bill, card': 0.0, 'min(IoU, B-Iou)-poster, posting, placard, notice, bill, card': 0.0, 'IoU-stage': 0.0, 'BoundaryIoU-stage': 0.0, 'min(IoU, B-Iou)-stage': 0.0, 'IoU-van': 0.0, 'BoundaryIoU-van': 0.0, 'min(IoU, B-Iou)-van': 0.0, 'IoU-ship': 0.0, 'BoundaryIoU-ship': 0.0, 'min(IoU, B-Iou)-ship': 0.0, 'IoU-fountain': 0.0, 'BoundaryIoU-fountain': 0.0, 'min(IoU, B-Iou)-fountain': 0.0, 'IoU-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'BoundaryIoU-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'min(IoU, B-Iou)-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'IoU-canopy': 0.0002117742232650926, 'BoundaryIoU-canopy': 0.0, 'min(IoU, B-Iou)-canopy': 0.0, 'IoU-washer, automatic washer, washing machine': 0.0, 'BoundaryIoU-washer, automatic washer, washing machine': 0.0, 'min(IoU, B-Iou)-washer, automatic washer, washing machine': 0.0, 'IoU-plaything, toy': 0.0, 'BoundaryIoU-plaything, toy': 0.0, 'min(IoU, B-Iou)-plaything, toy': 0.0, 'IoU-swimming pool, swimming bath, natatorium': 0.0, 'BoundaryIoU-swimming pool, swimming bath, natatorium': 0.0, 'min(IoU, B-Iou)-swimming pool, swimming bath, natatorium': 0.0, 'IoU-stool': 0.0, 'BoundaryIoU-stool': 0.0, 'min(IoU, B-Iou)-stool': 0.0, 'IoU-barrel, cask': 0.0, 'BoundaryIoU-barrel, cask': 0.0, 'min(IoU, B-Iou)-barrel, cask': 0.0, 'IoU-basket, handbasket': 0.0, 'BoundaryIoU-basket, handbasket': 0.0, 'min(IoU, B-Iou)-basket, handbasket': 0.0, 'IoU-waterfall, falls': 0.0, 'BoundaryIoU-waterfall, falls': 0.0, 'min(IoU, B-Iou)-waterfall, falls': 0.0, 'IoU-tent, collapsible shelter': 0.0, 'BoundaryIoU-tent, collapsible shelter': 0.0, 'min(IoU, B-Iou)-tent, collapsible shelter': 0.0, 'IoU-bag': 0.0, 'BoundaryIoU-bag': 0.0, 'min(IoU, B-Iou)-bag': 0.0, 'IoU-minibike, motorbike': 0.0, 'BoundaryIoU-minibike, motorbike': 0.0, 'min(IoU, B-Iou)-minibike, motorbike': 0.0, 'IoU-cradle': 0.0, 'BoundaryIoU-cradle': 0.0, 'min(IoU, B-Iou)-cradle': 0.0, 'IoU-oven': 0.0, 'BoundaryIoU-oven': 0.0, 'min(IoU, B-Iou)-oven': 0.0, 'IoU-ball': 0.00019357298959932326, 'BoundaryIoU-ball': 0.0, 'min(IoU, B-Iou)-ball': 0.0, 'IoU-food, solid food': 0.0, 'BoundaryIoU-food, solid food': 0.0, 'min(IoU, B-Iou)-food, solid food': 0.0, 'IoU-step, stair': 0.0, 'BoundaryIoU-step, stair': 0.0, 'min(IoU, B-Iou)-step, stair': 0.0, 'IoU-tank, storage tank': 0.0, 'BoundaryIoU-tank, storage tank': 0.0, 'min(IoU, B-Iou)-tank, storage tank': 0.0, 'IoU-trade name, brand name, brand, marque': 0.0, 'BoundaryIoU-trade name, brand name, brand, marque': 0.0, 'min(IoU, B-Iou)-trade name, brand name, brand, marque': 0.0, 'IoU-microwave, microwave oven': 0.0, 'BoundaryIoU-microwave, microwave oven': 0.0, 'min(IoU, B-Iou)-microwave, microwave oven': 0.0, 'IoU-pot, flowerpot': 0.0, 'BoundaryIoU-pot, flowerpot': 0.0, 'min(IoU, B-Iou)-pot, flowerpot': 0.0, 'IoU-animal, animate being, beast, brute, creature, fauna': 0.0, 'BoundaryIoU-animal, animate being, beast, brute, creature, fauna': 0.0, 'min(IoU, B-Iou)-animal, animate being, beast, brute, creature, fauna': 0.0, 'IoU-bicycle, bike, wheel, cycle ': 0.0, 'BoundaryIoU-bicycle, bike, wheel, cycle ': 0.0, 'min(IoU, B-Iou)-bicycle, bike, wheel, cycle ': 0.0, 'IoU-lake': 0.0, 'BoundaryIoU-lake': 0.0, 'min(IoU, B-Iou)-lake': 0.0, 'IoU-dishwasher, dish washer, dishwashing machine': 0.0, 'BoundaryIoU-dishwasher, dish washer, dishwashing machine': 0.0, 'min(IoU, B-Iou)-dishwasher, dish washer, dishwashing machine': 0.0, 'IoU-screen, silver screen, projection screen': 0.0, 'BoundaryIoU-screen, silver screen, projection screen': 0.0, 'min(IoU, B-Iou)-screen, silver screen, projection screen': 0.0, 'IoU-blanket, cover': 0.0, 'BoundaryIoU-blanket, cover': 0.0, 'min(IoU, B-Iou)-blanket, cover': 0.0, 'IoU-sculpture': 0.0, 'BoundaryIoU-sculpture': 0.0, 'min(IoU, B-Iou)-sculpture': 0.0, 'IoU-hood, exhaust hood': 0.0, 'BoundaryIoU-hood, exhaust hood': 0.0, 'min(IoU, B-Iou)-hood, exhaust hood': 0.0, 'IoU-sconce': 0.0, 'BoundaryIoU-sconce': 0.0, 'min(IoU, B-Iou)-sconce': 0.0, 'IoU-vase': 0.0, 'BoundaryIoU-vase': 0.0, 'min(IoU, B-Iou)-vase': 0.0, 'IoU-traffic light, traffic signal, stoplight': 0.0, 'BoundaryIoU-traffic light, traffic signal, stoplight': 0.0, 'min(IoU, B-Iou)-traffic light, traffic signal, stoplight': 0.0, 'IoU-tray': 0.0, 'BoundaryIoU-tray': 0.0, 'min(IoU, B-Iou)-tray': 0.0, 'IoU-ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin': 0.0, 'BoundaryIoU-ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin': 0.0, 'min(IoU, B-Iou)-ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin': 0.0, 'IoU-fan': 0.0, 'BoundaryIoU-fan': 0.0, 'min(IoU, B-Iou)-fan': 0.0, 'IoU-pier, wharf, wharfage, dock': 0.0, 'BoundaryIoU-pier, wharf, wharfage, dock': 0.0, 'min(IoU, B-Iou)-pier, wharf, wharfage, dock': 0.0, 'IoU-crt screen': 0.0, 'BoundaryIoU-crt screen': 0.0, 'min(IoU, B-Iou)-crt screen': 0.0, 'IoU-plate': 0.0, 'BoundaryIoU-plate': 0.0, 'min(IoU, B-Iou)-plate': 0.0, 'IoU-monitor, monitoring device': 0.0, 'BoundaryIoU-monitor, monitoring device': 0.0, 'min(IoU, B-Iou)-monitor, monitoring device': 0.0, 'IoU-bulletin board, notice board': 0.0, 'BoundaryIoU-bulletin board, notice board': 0.0, 'min(IoU, B-Iou)-bulletin board, notice board': 0.0, 'IoU-shower': 0.0, 'BoundaryIoU-shower': 0.0, 'min(IoU, B-Iou)-shower': 0.0, 'IoU-radiator': 0.0, 'BoundaryIoU-radiator': 0.0, 'min(IoU, B-Iou)-radiator': 0.0, 'IoU-glass, drinking glass': 0.0, 'BoundaryIoU-glass, drinking glass': 0.0, 'min(IoU, B-Iou)-glass, drinking glass': 0.0, 'IoU-clock': 0.0, 'BoundaryIoU-clock': 0.0, 'min(IoU, B-Iou)-clock': 0.0, 'mACC': 0.19113889989980287, 'pACC': 1.6654078776316945, 'ACC-flag': 0.0, 'ACC-wall': 8.49769926228659, 'ACC-building, edifice': 2.570255357178493, 'ACC-sky': 0.16339765109477103, 'ACC-floor, flooring': 0.8237739170659052, 'ACC-tree': 3.7601589421027706, 'ACC-ceiling': 3.0649086350735885e-05, 'ACC-road, route': 5.801188883107348, 'ACC-bed ': 0.07689251908934755, 'ACC-windowpane, window ': 0.00042795743639717455, 'ACC-grass': 0.12149534950670708, 'ACC-cabinet': 0.0, 'ACC-sidewalk, pavement': 0.660370951185429, 'ACC-person, individual, someone, somebody, mortal, soul': 0.5532649749095531, 'ACC-earth, ground': 0.018251869157327794, 'ACC-door, double door': 0.004169977507102894, 'ACC-table': 0.056541871023554, 'ACC-mountain, mount': 0.07154598108872541, 'ACC-plant, flora, plant life': 0.23213923357809957, 'ACC-curtain, drape, drapery, mantle, pall': 0.002811321540694495, 'ACC-chair': 1.8321898792483, 'ACC-car, auto, automobile, machine, motorcar': 2.7127341676642107, 'ACC-water': 0.0005626256896999764, 'ACC-painting, picture': 0.0028945905891070768, 'ACC-sofa, couch, lounge': 0.0, 'ACC-shelf': 0.02286107875531013, 'ACC-house': 0.0, 'ACC-sea': 0.0, 'ACC-mirror': 0.0, 'ACC-rug, carpet, carpeting': 0.0, 'ACC-field': 0.5645156210902899, 'ACC-armchair': 0.0, 'ACC-seat': 0.017422937482546173, 'ACC-fence, fencing': 0.0019508327714934952, 'ACC-desk': 0.0001226842579534671, 'ACC-rock, stone': 0.0, 'ACC-wardrobe, closet, press': 0.0, 'ACC-lamp': 0.0, 'ACC-bathtub, bathing tub, bath, tub': 0.0, 'ACC-railing, rail': 0.0, 'ACC-cushion': 0.0, 'ACC-base, pedestal, stand': 0.0, 'ACC-box': 0.0, 'ACC-column, pillar': 0.0, 'ACC-signboard, sign': 0.0, 'ACC-chest of drawers, chest, bureau, dresser': 0.00011775206595999728, 'ACC-counter': 0.0, 'ACC-sand': 0.05560756725240827, 'ACC-sink': 0.0, 'ACC-skyscraper': 0.0, 'ACC-fireplace, hearth, open fireplace': 0.0, 'ACC-refrigerator, icebox': 0.0, 'ACC-grandstand, covered stand': 0.0, 'ACC-path': 0.0, 'ACC-stairs, steps': 0.0, 'ACC-runway': 0.0, 'ACC-case, display case, showcase, vitrine': 0.0, 'ACC-pool table, billiard table, snooker table': 0.0, 'ACC-pillow': 0.0, 'ACC-screen door, screen': 0.0, 'ACC-stairway, staircase': 0.0, 'ACC-river': 0.03950918501908744, 'ACC-bridge, span': 0.0, 'ACC-bookcase': 7.829854137647269e-05, 'ACC-blind, screen': 0.0, 'ACC-coffee table, cocktail table': 0.0, 'ACC-toilet, can, commode, crapper, pot, potty, stool, throne': 0.0, 'ACC-flower': 0.0003585475954005515, 'ACC-book': 0.0, 'ACC-hill': 0.0, 'ACC-bench': 0.0, 'ACC-countertop': 0.0, 'ACC-stove, kitchen stove, range, kitchen range, cooking stove': 0.0, 'ACC-palm, palm tree': 0.0, 'ACC-kitchen island': 0.0, 'ACC-computer, computing machine, computing device, data processor, electronic computer, information processing system': 0.0, 'ACC-swivel chair': 0.0, 'ACC-boat': 0.0, 'ACC-bar': 0.0, 'ACC-arcade machine': 0.0, 'ACC-hovel, hut, hutch, shack, shanty': 0.0009447264190381268, 'ACC-bus, autobus, coach, charabanc, double-decker, jitney, motorbus, motorcoach, omnibus, passenger vehicle': 0.0, 'ACC-towel': 0.0, 'ACC-light, light source': 0.0, 'ACC-truck, motortruck': 0.0, 'ACC-tower': 0.0, 'ACC-chandelier, pendant, pendent': 0.0, 'ACC-awning, sunshade, sunblind': 0.0, 'ACC-streetlight, street lamp': 0.0, 'ACC-booth, cubicle, stall, kiosk': 0.0, 'ACC-television receiver, television, television set, tv, tv set, idiot box, boob tube, telly, goggle box': 0.0, 'ACC-airplane, aeroplane, plane': 0.0, 'ACC-dirt track': 0.0, 'ACC-apparel, wearing apparel, dress, clothes': 0.0, 'ACC-pole': 0.004141687116246803, 'ACC-land, ground, soil': 0.0, 'ACC-bannister, banister, balustrade, balusters, handrail': 0.0, 'ACC-escalator, moving staircase, moving stairway': 0.0, 'ACC-ottoman, pouf, pouffe, puff, hassock': 0.0, 'ACC-bottle': 0.0, 'ACC-buffet, counter, sideboard': 0.0, 'ACC-poster, posting, placard, notice, bill, card': 0.0, 'ACC-stage': 0.0, 'ACC-van': 0.0, 'ACC-ship': 0.0, 'ACC-fountain': 0.0, 'ACC-conveyer belt, conveyor belt, conveyer, conveyor, transporter': 0.0, 'ACC-canopy': 0.00021237193972034862, 'ACC-washer, automatic washer, washing machine': 0.0, 'ACC-plaything, toy': 0.0, 'ACC-swimming pool, swimming bath, natatorium': 0.0, 'ACC-stool': 0.0, 'ACC-barrel, cask': 0.0, 'ACC-basket, handbasket': 0.0, 'ACC-waterfall, falls': 0.0, 'ACC-tent, collapsible shelter': 0.0, 'ACC-bag': 0.0, 'ACC-minibike, motorbike': 0.0, 'ACC-cradle': 0.0, 'ACC-oven': 0.0, 'ACC-ball': 0.00019376352711623682, 'ACC-food, solid food': 0.0, 'ACC-step, stair': 0.0, 'ACC-tank, storage tank': 0.0, 'ACC-trade name, brand name, brand, marque': 0.0, 'ACC-microwave, microwave oven': 0.0, 'ACC-pot, flowerpot': 0.0, 'ACC-animal, animate being, beast, brute, creature, fauna': 0.0, 'ACC-bicycle, bike, wheel, cycle ': 0.0, 'ACC-lake': 0.0, 'ACC-dishwasher, dish washer, dishwashing machine': 0.0, 'ACC-screen, silver screen, projection screen': 0.0, 'ACC-blanket, cover': 0.0, 'ACC-sculpture': 0.0, 'ACC-hood, exhaust hood': 0.0, 'ACC-sconce': 0.0, 'ACC-vase': 0.0, 'ACC-traffic light, traffic signal, stoplight': 0.0, 'ACC-tray': 0.0, 'ACC-ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin': 0.0, 'ACC-fan': 0.0, 'ACC-pier, wharf, wharfage, dock': 0.0, 'ACC-crt screen': 0.0, 'ACC-plate': 0.0, 'ACC-monitor, monitoring device': 0.0, 'ACC-bulletin board, notice board': 0.0, 'ACC-shower': 0.0, 'ACC-radiator': 0.0, 'ACC-glass, drinking glass': 0.0, 'ACC-clock': 0.0})])
[03/11 13:37:38 d2.engine.defaults]: Evaluation results for ade_sem_seg_val in csv format:
[03/11 13:37:38 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/11 13:37:38 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/11 13:37:38 d2.evaluation.testing]: copypaste: 0.0640,0.5534,0.1911,1.6654
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa52414c0>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5241cd0>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa52460a0>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5246760>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa5246c10>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520f280>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataset_mappers.semantic_dataset_mapper]: [SemanticDatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=..., max_size=4096, sample_style='choice'), RandomCrop_CategoryAreaConstraint(crop_type='absolute', crop_size=[768, 768], single_category_max_area=1.0, ignored_category=255), <detectron2.projects.point_rend.color_augmentation.ColorAugSSDTransform object at 0x7feaa520f550>, RandomFlip()]
[03/11 13:37:38 mask2former.data.dataloader.DaliDataLoader]: evaluate coco_sem_seg_val
[03/11 13:37:38 d2.data.common]: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/11 13:37:38 d2.data.common]: Serializing 5000 elements to byte tensors and concatenating them all ...
[03/11 13:37:38 d2.data.common]: Serialized dataset takes 0.90 MiB
[03/11 13:37:38 d2.evaluation.evaluator]: Start inference on 5000 batches
[03/11 13:37:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:37:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 416])
[03/11 13:37:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:37:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:37:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 592])
[03/11 13:37:42 d2.evaluation.evaluator]: Inference done 11/5000. Dataloading: 0.0017 s/iter. Inference: 0.1851 s/iter. Eval: 0.0523 s/iter. Total: 0.2392 s/iter. ETA=0:19:53
[03/11 13:37:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:37:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:37:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:37:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:37:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:37:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:37:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:37:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:37:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:37:47 d2.evaluation.evaluator]: Inference done 33/5000. Dataloading: 0.0025 s/iter. Inference: 0.1909 s/iter. Eval: 0.0411 s/iter. Total: 0.2346 s/iter. ETA=0:19:25
[03/11 13:37:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:37:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:37:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 624])
[03/11 13:37:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:37:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:37:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:37:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:37:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:37:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:52 d2.evaluation.evaluator]: Inference done 53/5000. Dataloading: 0.0028 s/iter. Inference: 0.1964 s/iter. Eval: 0.0438 s/iter. Total: 0.2430 s/iter. ETA=0:20:02
[03/11 13:37:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:37:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 464])
[03/11 13:37:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:37:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:37:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:37:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 352])
[03/11 13:37:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:57 d2.evaluation.evaluator]: Inference done 75/5000. Dataloading: 0.0031 s/iter. Inference: 0.1902 s/iter. Eval: 0.0457 s/iter. Total: 0.2390 s/iter. ETA=0:19:37
[03/11 13:37:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:37:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:37:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:37:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:37:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:37:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:37:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:38:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 416])
[03/11 13:38:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:38:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:38:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:38:02 d2.evaluation.evaluator]: Inference done 96/5000. Dataloading: 0.0031 s/iter. Inference: 0.1922 s/iter. Eval: 0.0437 s/iter. Total: 0.2391 s/iter. ETA=0:19:32
[03/11 13:38:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:38:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 600])
[03/11 13:38:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 500])
[03/11 13:38:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:38:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:38:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:38:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:38:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:38:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 556])
[03/11 13:38:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:07 d2.evaluation.evaluator]: Inference done 118/5000. Dataloading: 0.0033 s/iter. Inference: 0.1906 s/iter. Eval: 0.0448 s/iter. Total: 0.2388 s/iter. ETA=0:19:25
[03/11 13:38:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 540, 640])
[03/11 13:38:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:38:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:38:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 616])
[03/11 13:38:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:38:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 556, 640])
[03/11 13:38:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:38:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:13 d2.evaluation.evaluator]: Inference done 140/5000. Dataloading: 0.0033 s/iter. Inference: 0.1903 s/iter. Eval: 0.0449 s/iter. Total: 0.2387 s/iter. ETA=0:19:19
[03/11 13:38:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 624, 640])
[03/11 13:38:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:38:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:38:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:38:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:18 d2.evaluation.evaluator]: Inference done 161/5000. Dataloading: 0.0033 s/iter. Inference: 0.1911 s/iter. Eval: 0.0443 s/iter. Total: 0.2389 s/iter. ETA=0:19:15
[03/11 13:38:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 640])
[03/11 13:38:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 500])
[03/11 13:38:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 640])
[03/11 13:38:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:38:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 500])
[03/11 13:38:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:38:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:38:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:38:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 388])
[03/11 13:38:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:23 d2.evaluation.evaluator]: Inference done 184/5000. Dataloading: 0.0033 s/iter. Inference: 0.1891 s/iter. Eval: 0.0441 s/iter. Total: 0.2366 s/iter. ETA=0:18:59
[03/11 13:38:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 500])
[03/11 13:38:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 564, 640])
[03/11 13:38:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:38:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 448])
[03/11 13:38:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:38:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 412])
[03/11 13:38:28 d2.evaluation.evaluator]: Inference done 204/5000. Dataloading: 0.0034 s/iter. Inference: 0.1907 s/iter. Eval: 0.0444 s/iter. Total: 0.2386 s/iter. ETA=0:19:04
[03/11 13:38:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:38:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 588])
[03/11 13:38:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 588])
[03/11 13:38:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:38:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:38:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:38:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 308, 288])
[03/11 13:38:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 500])
[03/11 13:38:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:38:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:33 d2.evaluation.evaluator]: Inference done 225/5000. Dataloading: 0.0034 s/iter. Inference: 0.1898 s/iter. Eval: 0.0456 s/iter. Total: 0.2389 s/iter. ETA=0:19:00
[03/11 13:38:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:38:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:38:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 500])
[03/11 13:38:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:38:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:38:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:38 d2.evaluation.evaluator]: Inference done 247/5000. Dataloading: 0.0034 s/iter. Inference: 0.1897 s/iter. Eval: 0.0455 s/iter. Total: 0.2387 s/iter. ETA=0:18:54
[03/11 13:38:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:38:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:38:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:38:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:38:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 640])
[03/11 13:38:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 556, 640])
[03/11 13:38:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:38:43 d2.evaluation.evaluator]: Inference done 270/5000. Dataloading: 0.0035 s/iter. Inference: 0.1879 s/iter. Eval: 0.0454 s/iter. Total: 0.2370 s/iter. ETA=0:18:40
[03/11 13:38:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:38:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:38:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:38:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:38:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 496])
[03/11 13:38:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:48 d2.evaluation.evaluator]: Inference done 291/5000. Dataloading: 0.0035 s/iter. Inference: 0.1883 s/iter. Eval: 0.0457 s/iter. Total: 0.2376 s/iter. ETA=0:18:38
[03/11 13:38:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:38:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:38:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 524])
[03/11 13:38:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:38:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:38:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:38:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:38:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:38:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:38:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:38:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:53 d2.evaluation.evaluator]: Inference done 314/5000. Dataloading: 0.0036 s/iter. Inference: 0.1871 s/iter. Eval: 0.0457 s/iter. Total: 0.2365 s/iter. ETA=0:18:28
[03/11 13:38:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:38:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:38:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:38:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:38:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:38:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:38:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 440])
[03/11 13:38:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:38:59 d2.evaluation.evaluator]: Inference done 339/5000. Dataloading: 0.0037 s/iter. Inference: 0.1850 s/iter. Eval: 0.0454 s/iter. Total: 0.2342 s/iter. ETA=0:18:11
[03/11 13:38:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:38:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:38:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:38:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:38:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:39:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:39:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:39:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:39:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 640])
[03/11 13:39:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:39:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:39:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:39:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:39:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:39:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 508])
[03/11 13:39:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:39:04 d2.evaluation.evaluator]: Inference done 359/5000. Dataloading: 0.0038 s/iter. Inference: 0.1858 s/iter. Eval: 0.0455 s/iter. Total: 0.2352 s/iter. ETA=0:18:11
[03/11 13:39:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:39:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:39:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:39:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 632])
[03/11 13:39:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:39:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 352])
[03/11 13:39:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:39:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:39:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:09 d2.evaluation.evaluator]: Inference done 382/5000. Dataloading: 0.0038 s/iter. Inference: 0.1851 s/iter. Eval: 0.0452 s/iter. Total: 0.2342 s/iter. ETA=0:18:01
[03/11 13:39:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 464])
[03/11 13:39:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 476])
[03/11 13:39:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:14 d2.evaluation.evaluator]: Inference done 404/5000. Dataloading: 0.0038 s/iter. Inference: 0.1850 s/iter. Eval: 0.0453 s/iter. Total: 0.2341 s/iter. ETA=0:17:56
[03/11 13:39:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:39:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:39:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:39:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:39:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 500])
[03/11 13:39:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 500])
[03/11 13:39:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:39:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:39:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:39:19 d2.evaluation.evaluator]: Inference done 427/5000. Dataloading: 0.0038 s/iter. Inference: 0.1848 s/iter. Eval: 0.0450 s/iter. Total: 0.2337 s/iter. ETA=0:17:48
[03/11 13:39:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:39:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:39:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 328])
[03/11 13:39:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 588])
[03/11 13:39:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 388])
[03/11 13:39:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 640])
[03/11 13:39:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:39:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:24 d2.evaluation.evaluator]: Inference done 450/5000. Dataloading: 0.0038 s/iter. Inference: 0.1850 s/iter. Eval: 0.0449 s/iter. Total: 0.2338 s/iter. ETA=0:17:43
[03/11 13:39:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:39:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:39:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:39:29 d2.evaluation.evaluator]: Inference done 475/5000. Dataloading: 0.0038 s/iter. Inference: 0.1836 s/iter. Eval: 0.0448 s/iter. Total: 0.2323 s/iter. ETA=0:17:31
[03/11 13:39:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:39:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:39:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:35 d2.evaluation.evaluator]: Inference done 498/5000. Dataloading: 0.0038 s/iter. Inference: 0.1829 s/iter. Eval: 0.0448 s/iter. Total: 0.2317 s/iter. ETA=0:17:23
[03/11 13:39:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:39:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:39:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:39:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 308, 388])
[03/11 13:39:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 388])
[03/11 13:39:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 500])
[03/11 13:39:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 504])
[03/11 13:39:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:40 d2.evaluation.evaluator]: Inference done 520/5000. Dataloading: 0.0038 s/iter. Inference: 0.1829 s/iter. Eval: 0.0447 s/iter. Total: 0.2316 s/iter. ETA=0:17:17
[03/11 13:39:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 600])
[03/11 13:39:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:39:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:39:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:39:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 524, 640])
[03/11 13:39:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 556, 640])
[03/11 13:39:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:39:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 500])
[03/11 13:39:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 308])
[03/11 13:39:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:39:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:39:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:39:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:39:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 528])
[03/11 13:39:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:39:45 d2.evaluation.evaluator]: Inference done 543/5000. Dataloading: 0.0038 s/iter. Inference: 0.1828 s/iter. Eval: 0.0444 s/iter. Total: 0.2311 s/iter. ETA=0:17:09
[03/11 13:39:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:39:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 640])
[03/11 13:39:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:39:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:39:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:39:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 500])
[03/11 13:39:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:39:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:50 d2.evaluation.evaluator]: Inference done 566/5000. Dataloading: 0.0038 s/iter. Inference: 0.1827 s/iter. Eval: 0.0442 s/iter. Total: 0.2308 s/iter. ETA=0:17:03
[03/11 13:39:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:39:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:39:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:39:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:39:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:39:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:39:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:39:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:55 d2.evaluation.evaluator]: Inference done 591/5000. Dataloading: 0.0038 s/iter. Inference: 0.1818 s/iter. Eval: 0.0441 s/iter. Total: 0.2298 s/iter. ETA=0:16:53
[03/11 13:39:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:39:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 176, 220])
[03/11 13:39:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:39:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:39:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:39:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:39:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:39:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:39:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:39:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 436])
[03/11 13:40:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:40:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:00 d2.evaluation.evaluator]: Inference done 614/5000. Dataloading: 0.0038 s/iter. Inference: 0.1813 s/iter. Eval: 0.0442 s/iter. Total: 0.2294 s/iter. ETA=0:16:46
[03/11 13:40:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 408])
[03/11 13:40:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:40:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 500])
[03/11 13:40:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 524])
[03/11 13:40:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:40:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 308])
[03/11 13:40:05 d2.evaluation.evaluator]: Inference done 633/5000. Dataloading: 0.0038 s/iter. Inference: 0.1822 s/iter. Eval: 0.0444 s/iter. Total: 0.2304 s/iter. ETA=0:16:46
[03/11 13:40:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 520])
[03/11 13:40:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:40:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 308])
[03/11 13:40:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 580])
[03/11 13:40:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:40:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:40:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 552, 640])
[03/11 13:40:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:10 d2.evaluation.evaluator]: Inference done 655/5000. Dataloading: 0.0039 s/iter. Inference: 0.1820 s/iter. Eval: 0.0447 s/iter. Total: 0.2306 s/iter. ETA=0:16:42
[03/11 13:40:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:40:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 604])
[03/11 13:40:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:40:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:40:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 200, 256])
[03/11 13:40:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:40:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:40:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:40:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:40:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:15 d2.evaluation.evaluator]: Inference done 677/5000. Dataloading: 0.0039 s/iter. Inference: 0.1822 s/iter. Eval: 0.0445 s/iter. Total: 0.2306 s/iter. ETA=0:16:37
[03/11 13:40:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:40:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:40:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:40:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:40:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:40:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:40:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:40:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:40:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 540, 640])
[03/11 13:40:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:40:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:40:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:40:20 d2.evaluation.evaluator]: Inference done 700/5000. Dataloading: 0.0039 s/iter. Inference: 0.1816 s/iter. Eval: 0.0447 s/iter. Total: 0.2303 s/iter. ETA=0:16:30
[03/11 13:40:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:40:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:40:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 500])
[03/11 13:40:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:40:26 d2.evaluation.evaluator]: Inference done 723/5000. Dataloading: 0.0039 s/iter. Inference: 0.1813 s/iter. Eval: 0.0448 s/iter. Total: 0.2301 s/iter. ETA=0:16:24
[03/11 13:40:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:40:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:40:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 304])
[03/11 13:40:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:40:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:40:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:40:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:40:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:40:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 640])
[03/11 13:40:31 d2.evaluation.evaluator]: Inference done 746/5000. Dataloading: 0.0039 s/iter. Inference: 0.1807 s/iter. Eval: 0.0450 s/iter. Total: 0.2297 s/iter. ETA=0:16:17
[03/11 13:40:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:40:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 500])
[03/11 13:40:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:40:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 588, 640])
[03/11 13:40:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:40:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 236, 500])
[03/11 13:40:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 500])
[03/11 13:40:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:40:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:40:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 296])
[03/11 13:40:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 436])
[03/11 13:40:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:40:36 d2.evaluation.evaluator]: Inference done 769/5000. Dataloading: 0.0040 s/iter. Inference: 0.1809 s/iter. Eval: 0.0447 s/iter. Total: 0.2297 s/iter. ETA=0:16:11
[03/11 13:40:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:40:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:40:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:40:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:40:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:40:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:40:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 324, 432])
[03/11 13:40:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:40:41 d2.evaluation.evaluator]: Inference done 792/5000. Dataloading: 0.0039 s/iter. Inference: 0.1810 s/iter. Eval: 0.0444 s/iter. Total: 0.2295 s/iter. ETA=0:16:05
[03/11 13:40:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:40:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:40:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:40:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 316])
[03/11 13:40:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:40:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:40:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:40:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 640])
[03/11 13:40:46 d2.evaluation.evaluator]: Inference done 815/5000. Dataloading: 0.0039 s/iter. Inference: 0.1807 s/iter. Eval: 0.0446 s/iter. Total: 0.2293 s/iter. ETA=0:15:59
[03/11 13:40:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:40:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:40:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:40:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 640])
[03/11 13:40:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:40:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:40:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 500])
[03/11 13:40:51 d2.evaluation.evaluator]: Inference done 839/5000. Dataloading: 0.0039 s/iter. Inference: 0.1801 s/iter. Eval: 0.0446 s/iter. Total: 0.2287 s/iter. ETA=0:15:51
[03/11 13:40:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:40:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:40:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 328])
[03/11 13:40:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:40:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:40:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:40:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:40:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:40:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:56 d2.evaluation.evaluator]: Inference done 861/5000. Dataloading: 0.0039 s/iter. Inference: 0.1802 s/iter. Eval: 0.0445 s/iter. Total: 0.2287 s/iter. ETA=0:15:46
[03/11 13:40:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:40:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:40:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:40:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:40:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:40:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:40:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:40:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 500])
[03/11 13:40:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:40:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:40:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:40:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 624])
[03/11 13:40:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:41:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:41:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:41:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:41:01 d2.evaluation.evaluator]: Inference done 887/5000. Dataloading: 0.0039 s/iter. Inference: 0.1795 s/iter. Eval: 0.0442 s/iter. Total: 0.2277 s/iter. ETA=0:15:36
[03/11 13:41:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:41:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 456])
[03/11 13:41:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:41:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:41:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:41:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:06 d2.evaluation.evaluator]: Inference done 909/5000. Dataloading: 0.0039 s/iter. Inference: 0.1797 s/iter. Eval: 0.0443 s/iter. Total: 0.2279 s/iter. ETA=0:15:32
[03/11 13:41:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:41:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:41:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:41:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 564])
[03/11 13:41:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:41:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 396])
[03/11 13:41:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:41:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:41:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:41:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 364])
[03/11 13:41:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:41:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:41:12 d2.evaluation.evaluator]: Inference done 933/5000. Dataloading: 0.0039 s/iter. Inference: 0.1792 s/iter. Eval: 0.0444 s/iter. Total: 0.2276 s/iter. ETA=0:15:25
[03/11 13:41:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:41:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:41:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:41:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:41:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:41:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:41:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:41:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:41:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:41:17 d2.evaluation.evaluator]: Inference done 958/5000. Dataloading: 0.0039 s/iter. Inference: 0.1787 s/iter. Eval: 0.0443 s/iter. Total: 0.2270 s/iter. ETA=0:15:17
[03/11 13:41:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 500])
[03/11 13:41:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:41:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 556, 640])
[03/11 13:41:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:41:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 500])
[03/11 13:41:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:41:22 d2.evaluation.evaluator]: Inference done 979/5000. Dataloading: 0.0039 s/iter. Inference: 0.1788 s/iter. Eval: 0.0445 s/iter. Total: 0.2273 s/iter. ETA=0:15:13
[03/11 13:41:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 500])
[03/11 13:41:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 492])
[03/11 13:41:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:41:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 352])
[03/11 13:41:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 628, 416])
[03/11 13:41:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 640])
[03/11 13:41:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:41:27 d2.evaluation.evaluator]: Inference done 1001/5000. Dataloading: 0.0039 s/iter. Inference: 0.1790 s/iter. Eval: 0.0445 s/iter. Total: 0.2275 s/iter. ETA=0:15:09
[03/11 13:41:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:41:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:41:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:41:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:32 d2.evaluation.evaluator]: Inference done 1023/5000. Dataloading: 0.0039 s/iter. Inference: 0.1792 s/iter. Eval: 0.0446 s/iter. Total: 0.2278 s/iter. ETA=0:15:05
[03/11 13:41:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:41:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:41:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:41:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:41:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:37 d2.evaluation.evaluator]: Inference done 1045/5000. Dataloading: 0.0039 s/iter. Inference: 0.1793 s/iter. Eval: 0.0446 s/iter. Total: 0.2279 s/iter. ETA=0:15:01
[03/11 13:41:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:41:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:41:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:41:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:41:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:41:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:41:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:42 d2.evaluation.evaluator]: Inference done 1071/5000. Dataloading: 0.0039 s/iter. Inference: 0.1786 s/iter. Eval: 0.0444 s/iter. Total: 0.2270 s/iter. ETA=0:14:52
[03/11 13:41:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:41:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:41:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:41:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:41:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:41:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 500])
[03/11 13:41:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 640])
[03/11 13:41:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:41:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:41:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:47 d2.evaluation.evaluator]: Inference done 1095/5000. Dataloading: 0.0039 s/iter. Inference: 0.1783 s/iter. Eval: 0.0445 s/iter. Total: 0.2268 s/iter. ETA=0:14:45
[03/11 13:41:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:41:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 640])
[03/11 13:41:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 364])
[03/11 13:41:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:41:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:41:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 500])
[03/11 13:41:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:41:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:41:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:41:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:53 d2.evaluation.evaluator]: Inference done 1119/5000. Dataloading: 0.0039 s/iter. Inference: 0.1782 s/iter. Eval: 0.0442 s/iter. Total: 0.2264 s/iter. ETA=0:14:38
[03/11 13:41:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 268, 444])
[03/11 13:41:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:41:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 500])
[03/11 13:41:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:41:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 388])
[03/11 13:41:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:41:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:41:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:41:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 608, 640])
[03/11 13:41:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:41:58 d2.evaluation.evaluator]: Inference done 1139/5000. Dataloading: 0.0039 s/iter. Inference: 0.1786 s/iter. Eval: 0.0443 s/iter. Total: 0.2269 s/iter. ETA=0:14:36
[03/11 13:41:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:41:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:41:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:41:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:41:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:41:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 640])
[03/11 13:41:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:42:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 372])
[03/11 13:42:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:42:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:42:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:42:03 d2.evaluation.evaluator]: Inference done 1161/5000. Dataloading: 0.0039 s/iter. Inference: 0.1788 s/iter. Eval: 0.0442 s/iter. Total: 0.2270 s/iter. ETA=0:14:31
[03/11 13:42:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:42:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:42:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:42:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 508])
[03/11 13:42:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:42:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:42:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:42:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:08 d2.evaluation.evaluator]: Inference done 1187/5000. Dataloading: 0.0040 s/iter. Inference: 0.1782 s/iter. Eval: 0.0442 s/iter. Total: 0.2265 s/iter. ETA=0:14:23
[03/11 13:42:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:42:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:42:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:42:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:42:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:42:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:42:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:42:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:42:13 d2.evaluation.evaluator]: Inference done 1213/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0441 s/iter. Total: 0.2259 s/iter. ETA=0:14:15
[03/11 13:42:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:42:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:42:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:42:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:42:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:42:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:42:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:42:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:42:18 d2.evaluation.evaluator]: Inference done 1236/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0442 s/iter. Total: 0.2258 s/iter. ETA=0:14:09
[03/11 13:42:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:42:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:42:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:42:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:42:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:42:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:42:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:23 d2.evaluation.evaluator]: Inference done 1259/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0441 s/iter. Total: 0.2256 s/iter. ETA=0:14:04
[03/11 13:42:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:42:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:42:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:42:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 640])
[03/11 13:42:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 324, 500])
[03/11 13:42:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 548, 640])
[03/11 13:42:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:42:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:42:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:42:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:28 d2.evaluation.evaluator]: Inference done 1282/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0441 s/iter. Total: 0.2256 s/iter. ETA=0:13:58
[03/11 13:42:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:42:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:42:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 444])
[03/11 13:42:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:42:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:42:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:42:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:42:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:42:33 d2.evaluation.evaluator]: Inference done 1302/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0443 s/iter. Total: 0.2260 s/iter. ETA=0:13:55
[03/11 13:42:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:42:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 336])
[03/11 13:42:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:42:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:42:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 608, 640])
[03/11 13:42:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:42:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:42:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:39 d2.evaluation.evaluator]: Inference done 1325/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0442 s/iter. Total: 0.2260 s/iter. ETA=0:13:50
[03/11 13:42:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 416])
[03/11 13:42:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:42:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 400])
[03/11 13:42:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:42:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:42:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:42:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:42:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 500])
[03/11 13:42:44 d2.evaluation.evaluator]: Inference done 1346/5000. Dataloading: 0.0040 s/iter. Inference: 0.1779 s/iter. Eval: 0.0442 s/iter. Total: 0.2262 s/iter. ETA=0:13:46
[03/11 13:42:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:42:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 640])
[03/11 13:42:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:42:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 340])
[03/11 13:42:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:42:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:42:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:49 d2.evaluation.evaluator]: Inference done 1367/5000. Dataloading: 0.0040 s/iter. Inference: 0.1782 s/iter. Eval: 0.0443 s/iter. Total: 0.2265 s/iter. ETA=0:13:42
[03/11 13:42:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:42:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:42:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 360])
[03/11 13:42:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 460])
[03/11 13:42:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 440])
[03/11 13:42:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:54 d2.evaluation.evaluator]: Inference done 1389/5000. Dataloading: 0.0039 s/iter. Inference: 0.1783 s/iter. Eval: 0.0442 s/iter. Total: 0.2266 s/iter. ETA=0:13:38
[03/11 13:42:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:42:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:42:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:42:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:42:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 448])
[03/11 13:42:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:42:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:42:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:42:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 500])
[03/11 13:42:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:42:59 d2.evaluation.evaluator]: Inference done 1411/5000. Dataloading: 0.0039 s/iter. Inference: 0.1784 s/iter. Eval: 0.0442 s/iter. Total: 0.2266 s/iter. ETA=0:13:33
[03/11 13:42:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:42:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:42:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:43:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:43:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 560])
[03/11 13:43:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:43:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:43:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 572])
[03/11 13:43:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 640])
[03/11 13:43:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:43:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:43:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 164, 640])
[03/11 13:43:04 d2.evaluation.evaluator]: Inference done 1435/5000. Dataloading: 0.0039 s/iter. Inference: 0.1782 s/iter. Eval: 0.0442 s/iter. Total: 0.2265 s/iter. ETA=0:13:27
[03/11 13:43:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:43:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:43:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 640])
[03/11 13:43:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:43:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:43:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 640])
[03/11 13:43:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 640])
[03/11 13:43:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:43:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:43:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:09 d2.evaluation.evaluator]: Inference done 1458/5000. Dataloading: 0.0039 s/iter. Inference: 0.1782 s/iter. Eval: 0.0442 s/iter. Total: 0.2265 s/iter. ETA=0:13:22
[03/11 13:43:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:43:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 416])
[03/11 13:43:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 640])
[03/11 13:43:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:14 d2.evaluation.evaluator]: Inference done 1481/5000. Dataloading: 0.0039 s/iter. Inference: 0.1781 s/iter. Eval: 0.0442 s/iter. Total: 0.2264 s/iter. ETA=0:13:16
[03/11 13:43:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 544, 640])
[03/11 13:43:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:43:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:43:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 640])
[03/11 13:43:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 560, 640])
[03/11 13:43:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:43:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:43:20 d2.evaluation.evaluator]: Inference done 1501/5000. Dataloading: 0.0039 s/iter. Inference: 0.1784 s/iter. Eval: 0.0443 s/iter. Total: 0.2268 s/iter. ETA=0:13:13
[03/11 13:43:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 272])
[03/11 13:43:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 500])
[03/11 13:43:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 580])
[03/11 13:43:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:43:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:43:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:43:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:25 d2.evaluation.evaluator]: Inference done 1523/5000. Dataloading: 0.0039 s/iter. Inference: 0.1786 s/iter. Eval: 0.0443 s/iter. Total: 0.2269 s/iter. ETA=0:13:08
[03/11 13:43:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:43:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:43:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:43:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:43:30 d2.evaluation.evaluator]: Inference done 1545/5000. Dataloading: 0.0039 s/iter. Inference: 0.1786 s/iter. Eval: 0.0443 s/iter. Total: 0.2269 s/iter. ETA=0:13:03
[03/11 13:43:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 500])
[03/11 13:43:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:43:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:43:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:43:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:43:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:43:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:43:35 d2.evaluation.evaluator]: Inference done 1569/5000. Dataloading: 0.0039 s/iter. Inference: 0.1785 s/iter. Eval: 0.0442 s/iter. Total: 0.2267 s/iter. ETA=0:12:57
[03/11 13:43:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 500])
[03/11 13:43:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:43:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 640])
[03/11 13:43:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 496])
[03/11 13:43:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:43:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:43:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:43:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:43:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:43:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:43:40 d2.evaluation.evaluator]: Inference done 1592/5000. Dataloading: 0.0039 s/iter. Inference: 0.1785 s/iter. Eval: 0.0441 s/iter. Total: 0.2266 s/iter. ETA=0:12:52
[03/11 13:43:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:43:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 640])
[03/11 13:43:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:43:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:43:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:43:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:43:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 640])
[03/11 13:43:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:43:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:43:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:45 d2.evaluation.evaluator]: Inference done 1616/5000. Dataloading: 0.0039 s/iter. Inference: 0.1781 s/iter. Eval: 0.0442 s/iter. Total: 0.2264 s/iter. ETA=0:12:46
[03/11 13:43:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:43:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 632])
[03/11 13:43:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 276, 500])
[03/11 13:43:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:43:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 500])
[03/11 13:43:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:43:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 564, 640])
[03/11 13:43:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:43:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:43:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:50 d2.evaluation.evaluator]: Inference done 1638/5000. Dataloading: 0.0040 s/iter. Inference: 0.1783 s/iter. Eval: 0.0442 s/iter. Total: 0.2265 s/iter. ETA=0:12:41
[03/11 13:43:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 520])
[03/11 13:43:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:43:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:43:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:43:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 436])
[03/11 13:43:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 604, 400])
[03/11 13:43:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 568])
[03/11 13:43:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:43:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:43:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:43:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:55 d2.evaluation.evaluator]: Inference done 1661/5000. Dataloading: 0.0040 s/iter. Inference: 0.1782 s/iter. Eval: 0.0441 s/iter. Total: 0.2264 s/iter. ETA=0:12:35
[03/11 13:43:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:43:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:43:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:43:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:43:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 580, 640])
[03/11 13:43:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:43:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 488])
[03/11 13:43:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:43:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:43:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:43:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:44:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:00 d2.evaluation.evaluator]: Inference done 1684/5000. Dataloading: 0.0040 s/iter. Inference: 0.1782 s/iter. Eval: 0.0440 s/iter. Total: 0.2263 s/iter. ETA=0:12:30
[03/11 13:44:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:44:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:44:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:44:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:44:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:44:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:44:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:44:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:44:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:05 d2.evaluation.evaluator]: Inference done 1706/5000. Dataloading: 0.0040 s/iter. Inference: 0.1782 s/iter. Eval: 0.0442 s/iter. Total: 0.2264 s/iter. ETA=0:12:25
[03/11 13:44:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:44:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:44:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 500])
[03/11 13:44:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 500])
[03/11 13:44:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:44:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 348])
[03/11 13:44:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 640])
[03/11 13:44:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:44:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:44:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:11 d2.evaluation.evaluator]: Inference done 1732/5000. Dataloading: 0.0040 s/iter. Inference: 0.1779 s/iter. Eval: 0.0440 s/iter. Total: 0.2260 s/iter. ETA=0:12:18
[03/11 13:44:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:44:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:44:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:44:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 500])
[03/11 13:44:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:44:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:16 d2.evaluation.evaluator]: Inference done 1756/5000. Dataloading: 0.0040 s/iter. Inference: 0.1778 s/iter. Eval: 0.0439 s/iter. Total: 0.2258 s/iter. ETA=0:12:12
[03/11 13:44:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:44:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 464])
[03/11 13:44:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 400])
[03/11 13:44:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:44:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:44:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:44:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:44:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:44:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:21 d2.evaluation.evaluator]: Inference done 1780/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0439 s/iter. Total: 0.2256 s/iter. ETA=0:12:06
[03/11 13:44:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 640])
[03/11 13:44:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 640])
[03/11 13:44:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:44:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:44:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 172, 640])
[03/11 13:44:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:44:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:26 d2.evaluation.evaluator]: Inference done 1805/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0437 s/iter. Total: 0.2254 s/iter. ETA=0:12:00
[03/11 13:44:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:44:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:44:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 596])
[03/11 13:44:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:44:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 500])
[03/11 13:44:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:44:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 300])
[03/11 13:44:31 d2.evaluation.evaluator]: Inference done 1831/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0436 s/iter. Total: 0.2250 s/iter. ETA=0:11:53
[03/11 13:44:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 640])
[03/11 13:44:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 400])
[03/11 13:44:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 524])
[03/11 13:44:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:44:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:44:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:44:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:36 d2.evaluation.evaluator]: Inference done 1856/5000. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0436 s/iter. Total: 0.2248 s/iter. ETA=0:11:46
[03/11 13:44:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 324, 500])
[03/11 13:44:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:44:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:44:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:44:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:44:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:44:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:41 d2.evaluation.evaluator]: Inference done 1879/5000. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0436 s/iter. Total: 0.2247 s/iter. ETA=0:11:41
[03/11 13:44:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 420])
[03/11 13:44:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 640])
[03/11 13:44:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:44:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 500])
[03/11 13:44:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:44:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:44:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:44:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:44:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:44:46 d2.evaluation.evaluator]: Inference done 1904/5000. Dataloading: 0.0040 s/iter. Inference: 0.1768 s/iter. Eval: 0.0435 s/iter. Total: 0.2244 s/iter. ETA=0:11:34
[03/11 13:44:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:44:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:44:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:44:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 640])
[03/11 13:44:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:52 d2.evaluation.evaluator]: Inference done 1924/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0435 s/iter. Total: 0.2248 s/iter. ETA=0:11:31
[03/11 13:44:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:44:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 348, 500])
[03/11 13:44:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:44:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:44:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:44:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:44:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:44:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:44:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:44:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:44:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:44:57 d2.evaluation.evaluator]: Inference done 1945/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0434 s/iter. Total: 0.2249 s/iter. ETA=0:11:27
[03/11 13:44:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:44:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:44:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:44:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:44:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:44:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:02 d2.evaluation.evaluator]: Inference done 1969/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0434 s/iter. Total: 0.2248 s/iter. ETA=0:11:21
[03/11 13:45:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 400])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 396])
[03/11 13:45:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:45:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:45:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:45:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 544])
[03/11 13:45:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:45:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:07 d2.evaluation.evaluator]: Inference done 1991/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:11:16
[03/11 13:45:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 640])
[03/11 13:45:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:45:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:45:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 196, 640])
[03/11 13:45:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 244, 640])
[03/11 13:45:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:12 d2.evaluation.evaluator]: Inference done 2011/5000. Dataloading: 0.0040 s/iter. Inference: 0.1779 s/iter. Eval: 0.0432 s/iter. Total: 0.2252 s/iter. ETA=0:11:13
[03/11 13:45:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 536, 640])
[03/11 13:45:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:45:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:45:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:45:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:45:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 224])
[03/11 13:45:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:45:17 d2.evaluation.evaluator]: Inference done 2034/5000. Dataloading: 0.0040 s/iter. Inference: 0.1779 s/iter. Eval: 0.0432 s/iter. Total: 0.2252 s/iter. ETA=0:11:07
[03/11 13:45:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 508])
[03/11 13:45:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:45:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:45:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:45:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:45:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 296])
[03/11 13:45:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:45:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 640])
[03/11 13:45:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 552])
[03/11 13:45:22 d2.evaluation.evaluator]: Inference done 2058/5000. Dataloading: 0.0040 s/iter. Inference: 0.1779 s/iter. Eval: 0.0431 s/iter. Total: 0.2251 s/iter. ETA=0:11:02
[03/11 13:45:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 640])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 408])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:45:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 640])
[03/11 13:45:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 372])
[03/11 13:45:27 d2.evaluation.evaluator]: Inference done 2082/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0431 s/iter. Total: 0.2249 s/iter. ETA=0:10:56
[03/11 13:45:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 524])
[03/11 13:45:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:45:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:45:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:45:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:45:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:45:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:45:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:45:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 364])
[03/11 13:45:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:32 d2.evaluation.evaluator]: Inference done 2104/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0432 s/iter. Total: 0.2250 s/iter. ETA=0:10:51
[03/11 13:45:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:45:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:45:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:45:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:45:38 d2.evaluation.evaluator]: Inference done 2128/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0431 s/iter. Total: 0.2248 s/iter. ETA=0:10:45
[03/11 13:45:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:45:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:45:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:45:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:45:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 564])
[03/11 13:45:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:45:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 640])
[03/11 13:45:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:45:43 d2.evaluation.evaluator]: Inference done 2150/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0432 s/iter. Total: 0.2250 s/iter. ETA=0:10:41
[03/11 13:45:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:45:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:45:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:45:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 640])
[03/11 13:45:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:45:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:48 d2.evaluation.evaluator]: Inference done 2174/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0431 s/iter. Total: 0.2248 s/iter. ETA=0:10:35
[03/11 13:45:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 640])
[03/11 13:45:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 640])
[03/11 13:45:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 500])
[03/11 13:45:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:45:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:45:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:53 d2.evaluation.evaluator]: Inference done 2197/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:10:29
[03/11 13:45:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:45:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 568, 640])
[03/11 13:45:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:45:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:45:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 536])
[03/11 13:45:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:45:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:45:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:45:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:45:58 d2.evaluation.evaluator]: Inference done 2218/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:10:25
[03/11 13:45:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:45:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:45:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:45:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:45:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:46:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 448])
[03/11 13:46:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:46:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 544])
[03/11 13:46:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 596])
[03/11 13:46:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:46:03 d2.evaluation.evaluator]: Inference done 2243/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:10:19
[03/11 13:46:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:46:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 324])
[03/11 13:46:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 640])
[03/11 13:46:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:46:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:46:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:46:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 420])
[03/11 13:46:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 500])
[03/11 13:46:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 148, 200])
[03/11 13:46:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:46:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:08 d2.evaluation.evaluator]: Inference done 2265/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0432 s/iter. Total: 0.2249 s/iter. ETA=0:10:14
[03/11 13:46:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:46:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:46:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:46:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 640])
[03/11 13:46:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:46:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:46:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:46:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:46:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:46:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 444])
[03/11 13:46:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:46:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:14 d2.evaluation.evaluator]: Inference done 2289/5000. Dataloading: 0.0041 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:10:09
[03/11 13:46:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:46:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:46:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 520, 640])
[03/11 13:46:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 392])
[03/11 13:46:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 528])
[03/11 13:46:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 500])
[03/11 13:46:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 640])
[03/11 13:46:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 324, 500])
[03/11 13:46:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 588])
[03/11 13:46:19 d2.evaluation.evaluator]: Inference done 2311/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2248 s/iter. ETA=0:10:04
[03/11 13:46:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:46:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:46:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 524, 640])
[03/11 13:46:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 444])
[03/11 13:46:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:46:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:24 d2.evaluation.evaluator]: Inference done 2334/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:09:59
[03/11 13:46:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 640])
[03/11 13:46:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 640])
[03/11 13:46:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 556, 640])
[03/11 13:46:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:46:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:29 d2.evaluation.evaluator]: Inference done 2357/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:09:53
[03/11 13:46:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:46:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:46:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 420])
[03/11 13:46:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:46:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:46:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:46:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:34 d2.evaluation.evaluator]: Inference done 2381/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0432 s/iter. Total: 0.2246 s/iter. ETA=0:09:48
[03/11 13:46:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:46:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 428])
[03/11 13:46:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:46:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:46:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:46:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:39 d2.evaluation.evaluator]: Inference done 2403/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:09:43
[03/11 13:46:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:46:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:46:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 372])
[03/11 13:46:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:46:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:46:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:46:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:46:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:46:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:46:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:44 d2.evaluation.evaluator]: Inference done 2425/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:09:38
[03/11 13:46:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:46:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:46:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:46:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 640])
[03/11 13:46:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 540, 640])
[03/11 13:46:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:46:49 d2.evaluation.evaluator]: Inference done 2448/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0434 s/iter. Total: 0.2247 s/iter. ETA=0:09:33
[03/11 13:46:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:46:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 528])
[03/11 13:46:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:46:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 412])
[03/11 13:46:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:46:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 552])
[03/11 13:46:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:46:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:54 d2.evaluation.evaluator]: Inference done 2471/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0434 s/iter. Total: 0.2246 s/iter. ETA=0:09:28
[03/11 13:46:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:46:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 604, 640])
[03/11 13:46:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:46:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:46:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:46:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:46:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 364])
[03/11 13:46:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:46:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:46:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 624, 448])
[03/11 13:46:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:46:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 564, 640])
[03/11 13:46:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:46:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:46:59 d2.evaluation.evaluator]: Inference done 2491/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0434 s/iter. Total: 0.2249 s/iter. ETA=0:09:24
[03/11 13:46:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 500])
[03/11 13:47:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:47:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:47:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 640])
[03/11 13:47:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:47:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:47:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:04 d2.evaluation.evaluator]: Inference done 2512/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:09:19
[03/11 13:47:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:47:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:47:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:47:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 408])
[03/11 13:47:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:47:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:47:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:47:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:47:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:47:10 d2.evaluation.evaluator]: Inference done 2536/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0433 s/iter. Total: 0.2250 s/iter. ETA=0:09:14
[03/11 13:47:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:47:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 580])
[03/11 13:47:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:47:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:47:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:47:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:15 d2.evaluation.evaluator]: Inference done 2558/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0433 s/iter. Total: 0.2251 s/iter. ETA=0:09:09
[03/11 13:47:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:47:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:47:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:47:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:47:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:47:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 500])
[03/11 13:47:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:47:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 444])
[03/11 13:47:20 d2.evaluation.evaluator]: Inference done 2581/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0433 s/iter. Total: 0.2250 s/iter. ETA=0:09:04
[03/11 13:47:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:47:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:47:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:47:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 464])
[03/11 13:47:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 400])
[03/11 13:47:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:47:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 640])
[03/11 13:47:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:47:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:47:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:47:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:47:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:25 d2.evaluation.evaluator]: Inference done 2604/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0433 s/iter. Total: 0.2250 s/iter. ETA=0:08:59
[03/11 13:47:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:47:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 248])
[03/11 13:47:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:47:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:47:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 576])
[03/11 13:47:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:47:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 516])
[03/11 13:47:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 532])
[03/11 13:47:30 d2.evaluation.evaluator]: Inference done 2628/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0432 s/iter. Total: 0.2249 s/iter. ETA=0:08:53
[03/11 13:47:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:47:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 416])
[03/11 13:47:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:47:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:47:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:47:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 500])
[03/11 13:47:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:35 d2.evaluation.evaluator]: Inference done 2652/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0432 s/iter. Total: 0.2248 s/iter. ETA=0:08:47
[03/11 13:47:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:47:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:47:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:47:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:47:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 508, 640])
[03/11 13:47:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:47:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 536, 640])
[03/11 13:47:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:47:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:47:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:41 d2.evaluation.evaluator]: Inference done 2676/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:08:42
[03/11 13:47:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 572, 640])
[03/11 13:47:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:47:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 640])
[03/11 13:47:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:47:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 332])
[03/11 13:47:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:47:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 640])
[03/11 13:47:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:47:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 596, 640])
[03/11 13:47:46 d2.evaluation.evaluator]: Inference done 2699/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2247 s/iter. ETA=0:08:37
[03/11 13:47:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:47:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:47:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:47:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:47:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:47:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:47:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:47:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 532])
[03/11 13:47:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 468])
[03/11 13:47:51 d2.evaluation.evaluator]: Inference done 2721/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0432 s/iter. Total: 0.2248 s/iter. ETA=0:08:32
[03/11 13:47:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:47:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:47:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:47:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:47:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:47:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:47:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:47:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:47:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:47:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:47:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:47:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:56 d2.evaluation.evaluator]: Inference done 2744/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0432 s/iter. Total: 0.2248 s/iter. ETA=0:08:27
[03/11 13:47:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:47:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 628])
[03/11 13:47:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:47:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:47:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 500])
[03/11 13:47:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:47:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:47:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:47:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:48:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:48:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:01 d2.evaluation.evaluator]: Inference done 2766/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0432 s/iter. Total: 0.2248 s/iter. ETA=0:08:22
[03/11 13:48:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:48:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:48:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:48:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:48:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:48:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:48:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:06 d2.evaluation.evaluator]: Inference done 2789/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0432 s/iter. Total: 0.2248 s/iter. ETA=0:08:17
[03/11 13:48:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:48:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:48:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 524, 640])
[03/11 13:48:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:48:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:48:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 640])
[03/11 13:48:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 352, 500])
[03/11 13:48:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:11 d2.evaluation.evaluator]: Inference done 2811/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:08:12
[03/11 13:48:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 380])
[03/11 13:48:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:48:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 488])
[03/11 13:48:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:48:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:48:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:48:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 540])
[03/11 13:48:17 d2.evaluation.evaluator]: Inference done 2834/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:08:07
[03/11 13:48:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 624, 640])
[03/11 13:48:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:48:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:48:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 640])
[03/11 13:48:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 288])
[03/11 13:48:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:48:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:48:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:48:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:22 d2.evaluation.evaluator]: Inference done 2858/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:08:01
[03/11 13:48:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:48:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 448])
[03/11 13:48:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:48:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:48:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:48:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 584])
[03/11 13:48:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:27 d2.evaluation.evaluator]: Inference done 2880/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:07:56
[03/11 13:48:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:48:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:48:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:48:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 508, 640])
[03/11 13:48:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:48:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 324, 480])
[03/11 13:48:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 404])
[03/11 13:48:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:48:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:48:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:48:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 416])
[03/11 13:48:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:32 d2.evaluation.evaluator]: Inference done 2906/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:07:50
[03/11 13:48:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:48:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:48:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:48:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:48:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:48:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:48:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:48:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 572, 640])
[03/11 13:48:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:48:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:48:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:37 d2.evaluation.evaluator]: Inference done 2930/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0434 s/iter. Total: 0.2246 s/iter. ETA=0:07:44
[03/11 13:48:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:48:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:48:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:48:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:48:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 640])
[03/11 13:48:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:48:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:48:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:48:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:48:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:48:42 d2.evaluation.evaluator]: Inference done 2953/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:07:39
[03/11 13:48:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:48:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 500])
[03/11 13:48:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:47 d2.evaluation.evaluator]: Inference done 2975/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:07:34
[03/11 13:48:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 500])
[03/11 13:48:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:48:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:48:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:48:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 548])
[03/11 13:48:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:48:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:48:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:48:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:48:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:48:52 d2.evaluation.evaluator]: Inference done 2996/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:07:30
[03/11 13:48:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 240])
[03/11 13:48:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:48:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 476])
[03/11 13:48:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:48:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:48:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 500])
[03/11 13:48:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:48:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:48:57 d2.evaluation.evaluator]: Inference done 3019/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:07:24
[03/11 13:48:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:48:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:48:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:48:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:48:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 500])
[03/11 13:48:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:48:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:49:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:49:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:49:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 640])
[03/11 13:49:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:49:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:49:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:02 d2.evaluation.evaluator]: Inference done 3041/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:07:20
[03/11 13:49:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:49:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 380])
[03/11 13:49:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:49:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:49:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:49:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:49:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:49:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:49:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:49:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 600])
[03/11 13:49:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:49:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:49:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:08 d2.evaluation.evaluator]: Inference done 3063/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:07:15
[03/11 13:49:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:49:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:49:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 536, 640])
[03/11 13:49:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:49:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:49:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 232, 352])
[03/11 13:49:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 500])
[03/11 13:49:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 352])
[03/11 13:49:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:13 d2.evaluation.evaluator]: Inference done 3088/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:07:09
[03/11 13:49:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:49:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 604, 640])
[03/11 13:49:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:49:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:49:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:49:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 208, 500])
[03/11 13:49:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:49:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 400])
[03/11 13:49:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:18 d2.evaluation.evaluator]: Inference done 3111/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0434 s/iter. Total: 0.2247 s/iter. ETA=0:07:04
[03/11 13:49:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:49:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:49:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:49:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:49:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:49:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:23 d2.evaluation.evaluator]: Inference done 3135/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0434 s/iter. Total: 0.2245 s/iter. ETA=0:06:58
[03/11 13:49:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:49:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 300])
[03/11 13:49:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 500])
[03/11 13:49:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:49:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:49:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 396])
[03/11 13:49:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:49:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 448])
[03/11 13:49:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:28 d2.evaluation.evaluator]: Inference done 3158/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0434 s/iter. Total: 0.2245 s/iter. ETA=0:06:53
[03/11 13:49:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:49:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:49:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:49:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 624])
[03/11 13:49:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:49:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:49:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:49:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:33 d2.evaluation.evaluator]: Inference done 3183/5000. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0434 s/iter. Total: 0.2244 s/iter. ETA=0:06:47
[03/11 13:49:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 524, 640])
[03/11 13:49:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:49:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:49:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:49:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:49:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:49:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:39 d2.evaluation.evaluator]: Inference done 3204/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0434 s/iter. Total: 0.2245 s/iter. ETA=0:06:43
[03/11 13:49:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 640])
[03/11 13:49:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:49:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:49:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:49:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 416])
[03/11 13:49:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 468])
[03/11 13:49:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:49:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:49:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:49:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:49:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:49:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 508, 640])
[03/11 13:49:44 d2.evaluation.evaluator]: Inference done 3230/5000. Dataloading: 0.0040 s/iter. Inference: 0.1769 s/iter. Eval: 0.0433 s/iter. Total: 0.2243 s/iter. ETA=0:06:37
[03/11 13:49:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:49:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 640])
[03/11 13:49:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:49:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:49:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:49:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:49:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:49:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:49:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:49:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:49:49 d2.evaluation.evaluator]: Inference done 3255/5000. Dataloading: 0.0040 s/iter. Inference: 0.1768 s/iter. Eval: 0.0433 s/iter. Total: 0.2241 s/iter. ETA=0:06:31
[03/11 13:49:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 584])
[03/11 13:49:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 500])
[03/11 13:49:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:49:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:49:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:49:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:49:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:54 d2.evaluation.evaluator]: Inference done 3279/5000. Dataloading: 0.0040 s/iter. Inference: 0.1767 s/iter. Eval: 0.0433 s/iter. Total: 0.2240 s/iter. ETA=0:06:25
[03/11 13:49:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 608, 640])
[03/11 13:49:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 500])
[03/11 13:49:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:49:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:49:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:49:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:49:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:49:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:49:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:49:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:49:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:49:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 448])
[03/11 13:49:59 d2.evaluation.evaluator]: Inference done 3301/5000. Dataloading: 0.0040 s/iter. Inference: 0.1767 s/iter. Eval: 0.0433 s/iter. Total: 0.2241 s/iter. ETA=0:06:20
[03/11 13:49:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:49:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:49:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 480])
[03/11 13:50:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:50:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:50:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 248, 640])
[03/11 13:50:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:50:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:50:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:50:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:04 d2.evaluation.evaluator]: Inference done 3323/5000. Dataloading: 0.0040 s/iter. Inference: 0.1768 s/iter. Eval: 0.0433 s/iter. Total: 0.2242 s/iter. ETA=0:06:15
[03/11 13:50:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 476])
[03/11 13:50:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:50:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:50:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:50:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:50:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 336])
[03/11 13:50:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:50:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:50:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 500])
[03/11 13:50:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:50:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 552])
[03/11 13:50:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:09 d2.evaluation.evaluator]: Inference done 3345/5000. Dataloading: 0.0040 s/iter. Inference: 0.1769 s/iter. Eval: 0.0433 s/iter. Total: 0.2243 s/iter. ETA=0:06:11
[03/11 13:50:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 296, 640])
[03/11 13:50:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:50:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 500])
[03/11 13:50:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:50:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 508, 640])
[03/11 13:50:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:50:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:50:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 324])
[03/11 13:50:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:14 d2.evaluation.evaluator]: Inference done 3367/5000. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2243 s/iter. ETA=0:06:06
[03/11 13:50:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:50:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:50:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:50:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 476])
[03/11 13:50:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 552])
[03/11 13:50:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 500])
[03/11 13:50:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 404])
[03/11 13:50:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:50:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:50:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:50:20 d2.evaluation.evaluator]: Inference done 3391/5000. Dataloading: 0.0040 s/iter. Inference: 0.1769 s/iter. Eval: 0.0433 s/iter. Total: 0.2242 s/iter. ETA=0:06:00
[03/11 13:50:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:50:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 640])
[03/11 13:50:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 500])
[03/11 13:50:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 476])
[03/11 13:50:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:50:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:25 d2.evaluation.evaluator]: Inference done 3415/5000. Dataloading: 0.0040 s/iter. Inference: 0.1768 s/iter. Eval: 0.0432 s/iter. Total: 0.2241 s/iter. ETA=0:05:55
[03/11 13:50:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 368])
[03/11 13:50:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:50:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 340])
[03/11 13:50:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 452])
[03/11 13:50:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:50:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:50:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:30 d2.evaluation.evaluator]: Inference done 3436/5000. Dataloading: 0.0040 s/iter. Inference: 0.1769 s/iter. Eval: 0.0432 s/iter. Total: 0.2243 s/iter. ETA=0:05:50
[03/11 13:50:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:50:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 436])
[03/11 13:50:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:50:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 492])
[03/11 13:50:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:50:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:50:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:50:35 d2.evaluation.evaluator]: Inference done 3457/5000. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2244 s/iter. ETA=0:05:46
[03/11 13:50:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 500])
[03/11 13:50:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 640])
[03/11 13:50:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:50:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:40 d2.evaluation.evaluator]: Inference done 3479/5000. Dataloading: 0.0040 s/iter. Inference: 0.1770 s/iter. Eval: 0.0434 s/iter. Total: 0.2244 s/iter. ETA=0:05:41
[03/11 13:50:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:50:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 608, 640])
[03/11 13:50:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:50:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 160, 288])
[03/11 13:50:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:50:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:45 d2.evaluation.evaluator]: Inference done 3499/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:05:37
[03/11 13:50:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:50:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:50:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:50:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:50:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 440])
[03/11 13:50:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:50:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:50 d2.evaluation.evaluator]: Inference done 3525/5000. Dataloading: 0.0041 s/iter. Inference: 0.1769 s/iter. Eval: 0.0433 s/iter. Total: 0.2244 s/iter. ETA=0:05:31
[03/11 13:50:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 180, 240])
[03/11 13:50:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:50:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:50:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 420])
[03/11 13:50:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:50:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 464])
[03/11 13:50:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 468])
[03/11 13:50:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:50:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 600, 452])
[03/11 13:50:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:55 d2.evaluation.evaluator]: Inference done 3548/5000. Dataloading: 0.0041 s/iter. Inference: 0.1769 s/iter. Eval: 0.0433 s/iter. Total: 0.2244 s/iter. ETA=0:05:25
[03/11 13:50:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:50:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 300, 396])
[03/11 13:50:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:50:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:50:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:50:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:50:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:50:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:50:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:50:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 596, 640])
[03/11 13:51:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:01 d2.evaluation.evaluator]: Inference done 3572/5000. Dataloading: 0.0041 s/iter. Inference: 0.1769 s/iter. Eval: 0.0433 s/iter. Total: 0.2244 s/iter. ETA=0:05:20
[03/11 13:51:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:51:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:51:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:51:06 d2.evaluation.evaluator]: Inference done 3593/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:05:15
[03/11 13:51:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 228, 500])
[03/11 13:51:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 292])
[03/11 13:51:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 500])
[03/11 13:51:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:51:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:51:11 d2.evaluation.evaluator]: Inference done 3616/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0432 s/iter. Total: 0.2244 s/iter. ETA=0:05:10
[03/11 13:51:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:51:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 500])
[03/11 13:51:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:51:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 444])
[03/11 13:51:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:51:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:16 d2.evaluation.evaluator]: Inference done 3638/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:05:05
[03/11 13:51:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 464])
[03/11 13:51:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:51:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:51:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:51:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:51:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:51:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:51:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 452])
[03/11 13:51:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:51:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:21 d2.evaluation.evaluator]: Inference done 3659/5000. Dataloading: 0.0041 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:05:01
[03/11 13:51:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:51:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:51:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 420])
[03/11 13:51:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 488])
[03/11 13:51:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 584])
[03/11 13:51:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:51:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:26 d2.evaluation.evaluator]: Inference done 3682/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:04:55
[03/11 13:51:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:51:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:51:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 500])
[03/11 13:51:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:51:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 464])
[03/11 13:51:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:51:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 420])
[03/11 13:51:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:31 d2.evaluation.evaluator]: Inference done 3704/5000. Dataloading: 0.0041 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:04:51
[03/11 13:51:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:51:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:51:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:51:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:51:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:51:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:51:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 488, 640])
[03/11 13:51:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:36 d2.evaluation.evaluator]: Inference done 3728/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:04:45
[03/11 13:51:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:51:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:51:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:51:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 500])
[03/11 13:51:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:51:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:51:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 192, 640])
[03/11 13:51:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:51:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 500])
[03/11 13:51:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 640])
[03/11 13:51:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:51:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:51:41 d2.evaluation.evaluator]: Inference done 3752/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:04:40
[03/11 13:51:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:51:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:51:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:51:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 416])
[03/11 13:51:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:47 d2.evaluation.evaluator]: Inference done 3773/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:04:35
[03/11 13:51:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 368])
[03/11 13:51:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:51:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 380])
[03/11 13:51:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 428])
[03/11 13:51:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:51:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:52 d2.evaluation.evaluator]: Inference done 3798/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:04:29
[03/11 13:51:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:51:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:51:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 640])
[03/11 13:51:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:51:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:51:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:51:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:51:57 d2.evaluation.evaluator]: Inference done 3819/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0434 s/iter. Total: 0.2246 s/iter. ETA=0:04:25
[03/11 13:51:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:51:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:51:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:51:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 372])
[03/11 13:51:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 416])
[03/11 13:51:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:51:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:51:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:51:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:51:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:51:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 588])
[03/11 13:52:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:52:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 640])
[03/11 13:52:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:02 d2.evaluation.evaluator]: Inference done 3843/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:04:19
[03/11 13:52:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:52:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:52:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:52:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:52:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:52:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 460])
[03/11 13:52:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 640])
[03/11 13:52:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 520, 640])
[03/11 13:52:07 d2.evaluation.evaluator]: Inference done 3866/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:04:14
[03/11 13:52:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 544, 640])
[03/11 13:52:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:52:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 380])
[03/11 13:52:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:52:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 408])
[03/11 13:52:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 500])
[03/11 13:52:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:52:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:12 d2.evaluation.evaluator]: Inference done 3888/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:04:09
[03/11 13:52:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:52:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 172, 500])
[03/11 13:52:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 640])
[03/11 13:52:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:52:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 452])
[03/11 13:52:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:52:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:52:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 396])
[03/11 13:52:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:52:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 500])
[03/11 13:52:17 d2.evaluation.evaluator]: Inference done 3911/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0432 s/iter. Total: 0.2245 s/iter. ETA=0:04:04
[03/11 13:52:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 348])
[03/11 13:52:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:52:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:52:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 640])
[03/11 13:52:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 356])
[03/11 13:52:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:52:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:52:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 520, 372])
[03/11 13:52:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 468])
[03/11 13:52:22 d2.evaluation.evaluator]: Inference done 3932/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:03:59
[03/11 13:52:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:52:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:52:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 500])
[03/11 13:52:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:27 d2.evaluation.evaluator]: Inference done 3955/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:03:54
[03/11 13:52:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:52:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:52:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:52:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 404])
[03/11 13:52:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 640])
[03/11 13:52:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:52:32 d2.evaluation.evaluator]: Inference done 3978/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:03:49
[03/11 13:52:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:52:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 176, 640])
[03/11 13:52:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 492])
[03/11 13:52:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:52:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:52:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 540])
[03/11 13:52:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:38 d2.evaluation.evaluator]: Inference done 4002/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:03:44
[03/11 13:52:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 256, 640])
[03/11 13:52:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 392])
[03/11 13:52:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:52:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:52:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:52:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:52:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:52:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:52:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:43 d2.evaluation.evaluator]: Inference done 4024/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:03:39
[03/11 13:52:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:52:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:52:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 544, 640])
[03/11 13:52:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:52:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:52:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:52:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:52:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 340])
[03/11 13:52:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:52:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:52:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:48 d2.evaluation.evaluator]: Inference done 4047/5000. Dataloading: 0.0041 s/iter. Inference: 0.1770 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:03:33
[03/11 13:52:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 160, 640])
[03/11 13:52:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:52:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:52:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:52:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 544])
[03/11 13:52:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:52:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:52:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:52:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:52:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:53 d2.evaluation.evaluator]: Inference done 4070/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2245 s/iter. ETA=0:03:28
[03/11 13:52:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:52:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:52:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:52:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 592, 640])
[03/11 13:52:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 500])
[03/11 13:52:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:52:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:52:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:52:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:52:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:52:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:52:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:58 d2.evaluation.evaluator]: Inference done 4092/5000. Dataloading: 0.0041 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:03:23
[03/11 13:52:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:52:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 336])
[03/11 13:52:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:52:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:52:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 640])
[03/11 13:53:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:53:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:53:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:03 d2.evaluation.evaluator]: Inference done 4114/5000. Dataloading: 0.0040 s/iter. Inference: 0.1771 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:03:19
[03/11 13:53:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:53:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:53:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 176, 264])
[03/11 13:53:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:53:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 368, 640])
[03/11 13:53:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:53:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 520, 640])
[03/11 13:53:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:53:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:53:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:08 d2.evaluation.evaluator]: Inference done 4134/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0434 s/iter. Total: 0.2248 s/iter. ETA=0:03:14
[03/11 13:53:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:53:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:53:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:53:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:53:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:53:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:53:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 640])
[03/11 13:53:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:53:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:13 d2.evaluation.evaluator]: Inference done 4157/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:03:09
[03/11 13:53:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 500])
[03/11 13:53:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 540, 640])
[03/11 13:53:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:53:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:53:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 448])
[03/11 13:53:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 260, 500])
[03/11 13:53:19 d2.evaluation.evaluator]: Inference done 4183/5000. Dataloading: 0.0041 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:03:03
[03/11 13:53:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:53:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:24 d2.evaluation.evaluator]: Inference done 4206/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:02:58
[03/11 13:53:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 640])
[03/11 13:53:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 516, 640])
[03/11 13:53:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 480])
[03/11 13:53:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:53:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:53:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:53:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:53:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 640])
[03/11 13:53:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:53:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 412])
[03/11 13:53:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 540])
[03/11 13:53:29 d2.evaluation.evaluator]: Inference done 4229/5000. Dataloading: 0.0040 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2246 s/iter. ETA=0:02:53
[03/11 13:53:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 320])
[03/11 13:53:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 364, 640])
[03/11 13:53:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:53:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:53:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:53:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:53:34 d2.evaluation.evaluator]: Inference done 4250/5000. Dataloading: 0.0041 s/iter. Inference: 0.1772 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:02:48
[03/11 13:53:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:53:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 500])
[03/11 13:53:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:53:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 456, 640])
[03/11 13:53:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:53:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:53:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:53:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:39 d2.evaluation.evaluator]: Inference done 4272/5000. Dataloading: 0.0041 s/iter. Inference: 0.1772 s/iter. Eval: 0.0434 s/iter. Total: 0.2247 s/iter. ETA=0:02:43
[03/11 13:53:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:53:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:53:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 500])
[03/11 13:53:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:53:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 600])
[03/11 13:53:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:53:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:53:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:53:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:53:44 d2.evaluation.evaluator]: Inference done 4295/5000. Dataloading: 0.0041 s/iter. Inference: 0.1773 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:02:38
[03/11 13:53:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:53:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 436])
[03/11 13:53:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:53:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 264, 640])
[03/11 13:53:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 476, 640])
[03/11 13:53:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:53:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:50 d2.evaluation.evaluator]: Inference done 4316/5000. Dataloading: 0.0041 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:02:33
[03/11 13:53:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:53:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:53:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 348])
[03/11 13:53:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:53:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:53:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 276])
[03/11 13:53:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:53:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:53:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 632])
[03/11 13:53:55 d2.evaluation.evaluator]: Inference done 4339/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:02:28
[03/11 13:53:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 524])
[03/11 13:53:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:53:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:53:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:53:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 356])
[03/11 13:53:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:53:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:53:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 576, 640])
[03/11 13:53:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:53:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:53:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:53:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:53:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:53:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 504, 640])
[03/11 13:53:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:53:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:54:00 d2.evaluation.evaluator]: Inference done 4362/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:02:23
[03/11 13:54:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 532, 640])
[03/11 13:54:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 384])
[03/11 13:54:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 304, 640])
[03/11 13:54:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:54:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:54:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 388])
[03/11 13:54:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 640])
[03/11 13:54:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:05 d2.evaluation.evaluator]: Inference done 4382/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:02:19
[03/11 13:54:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:54:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:54:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 524, 640])
[03/11 13:54:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:54:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 560, 640])
[03/11 13:54:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:54:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 568, 640])
[03/11 13:54:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:54:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:54:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:54:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:10 d2.evaluation.evaluator]: Inference done 4407/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:02:13
[03/11 13:54:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:54:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 540, 640])
[03/11 13:54:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 560, 640])
[03/11 13:54:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:54:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:54:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 500])
[03/11 13:54:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 444, 640])
[03/11 13:54:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:54:15 d2.evaluation.evaluator]: Inference done 4428/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:02:08
[03/11 13:54:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:54:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:54:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:54:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:54:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:54:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:20 d2.evaluation.evaluator]: Inference done 4452/5000. Dataloading: 0.0040 s/iter. Inference: 0.1773 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:02:03
[03/11 13:54:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:54:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:54:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 456])
[03/11 13:54:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 388, 640])
[03/11 13:54:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:54:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:54:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:25 d2.evaluation.evaluator]: Inference done 4472/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:01:58
[03/11 13:54:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:54:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 472, 640])
[03/11 13:54:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:54:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:54:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:54:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 636, 640])
[03/11 13:54:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:54:30 d2.evaluation.evaluator]: Inference done 4496/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:01:53
[03/11 13:54:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 636])
[03/11 13:54:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:54:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 500])
[03/11 13:54:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 468])
[03/11 13:54:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:35 d2.evaluation.evaluator]: Inference done 4519/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:01:48
[03/11 13:54:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 640])
[03/11 13:54:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:54:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:54:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 184, 640])
[03/11 13:54:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 356, 500])
[03/11 13:54:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:54:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:54:41 d2.evaluation.evaluator]: Inference done 4543/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:01:42
[03/11 13:54:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:54:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:54:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 300])
[03/11 13:54:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:54:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:54:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 424])
[03/11 13:54:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:46 d2.evaluation.evaluator]: Inference done 4567/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2247 s/iter. ETA=0:01:37
[03/11 13:54:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:54:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:54:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:54:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:54:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:54:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 640])
[03/11 13:54:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:54:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:54:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:54:51 d2.evaluation.evaluator]: Inference done 4587/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:01:32
[03/11 13:54:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:54:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:54:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 476])
[03/11 13:54:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 604])
[03/11 13:54:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:54:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:54:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:54:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 384, 500])
[03/11 13:54:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:56 d2.evaluation.evaluator]: Inference done 4611/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2248 s/iter. ETA=0:01:27
[03/11 13:54:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 552, 640])
[03/11 13:54:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 588, 640])
[03/11 13:54:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 452])
[03/11 13:54:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 328, 640])
[03/11 13:54:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 392, 640])
[03/11 13:54:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:54:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:54:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:54:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 364])
[03/11 13:54:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:54:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:55:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 512, 640])
[03/11 13:55:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:55:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:01 d2.evaluation.evaluator]: Inference done 4633/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:01:22
[03/11 13:55:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:55:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:55:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:55:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:55:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 508, 640])
[03/11 13:55:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:55:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:55:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 552])
[03/11 13:55:06 d2.evaluation.evaluator]: Inference done 4655/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0433 s/iter. Total: 0.2249 s/iter. ETA=0:01:17
[03/11 13:55:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:55:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:55:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:55:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 412, 640])
[03/11 13:55:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 380])
[03/11 13:55:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:11 d2.evaluation.evaluator]: Inference done 4676/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0433 s/iter. Total: 0.2250 s/iter. ETA=0:01:12
[03/11 13:55:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 484])
[03/11 13:55:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 332, 500])
[03/11 13:55:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:55:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 400])
[03/11 13:55:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:55:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:55:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:16 d2.evaluation.evaluator]: Inference done 4698/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:01:07
[03/11 13:55:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:55:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 640])
[03/11 13:55:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 388])
[03/11 13:55:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:55:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 344])
[03/11 13:55:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:55:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 556])
[03/11 13:55:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:55:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 448, 640])
[03/11 13:55:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:21 d2.evaluation.evaluator]: Inference done 4718/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0433 s/iter. Total: 0.2251 s/iter. ETA=0:01:03
[03/11 13:55:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 640])
[03/11 13:55:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 424])
[03/11 13:55:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:55:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 292, 640])
[03/11 13:55:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:25 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 500])
[03/11 13:55:26 d2.evaluation.evaluator]: Inference done 4739/5000. Dataloading: 0.0040 s/iter. Inference: 0.1777 s/iter. Eval: 0.0434 s/iter. Total: 0.2252 s/iter. ETA=0:00:58
[03/11 13:55:26 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:55:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:27 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 548])
[03/11 13:55:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 512])
[03/11 13:55:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 496, 640])
[03/11 13:55:28 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:55:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:29 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:30 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:31 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:32 d2.evaluation.evaluator]: Inference done 4765/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0433 s/iter. Total: 0.2251 s/iter. ETA=0:00:52
[03/11 13:55:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:55:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:32 mask2former.HRNetv2_model]: torch.Size([1, 3, 588, 640])
[03/11 13:55:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 336])
[03/11 13:55:33 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:55:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 500])
[03/11 13:55:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:34 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:55:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:55:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:35 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:55:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 404, 640])
[03/11 13:55:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 284, 500])
[03/11 13:55:36 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 576])
[03/11 13:55:37 d2.evaluation.evaluator]: Inference done 4789/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:00:47
[03/11 13:55:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:37 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:55:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 452, 640])
[03/11 13:55:38 mask2former.HRNetv2_model]: torch.Size([1, 3, 492, 640])
[03/11 13:55:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:55:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 312, 500])
[03/11 13:55:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:39 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:55:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:40 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 436, 640])
[03/11 13:55:41 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 380, 640])
[03/11 13:55:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:42 d2.evaluation.evaluator]: Inference done 4811/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0434 s/iter. Total: 0.2251 s/iter. ETA=0:00:42
[03/11 13:55:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 496])
[03/11 13:55:42 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 520])
[03/11 13:55:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 332])
[03/11 13:55:43 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 640])
[03/11 13:55:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:55:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:44 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 444])
[03/11 13:55:45 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:55:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 444])
[03/11 13:55:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:46 mask2former.HRNetv2_model]: torch.Size([1, 3, 432, 640])
[03/11 13:55:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:47 d2.evaluation.evaluator]: Inference done 4835/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:00:37
[03/11 13:55:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:47 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:55:48 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:55:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:49 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 640])
[03/11 13:55:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 416, 640])
[03/11 13:55:50 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:55:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:51 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:55:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:55:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 372, 640])
[03/11 13:55:52 d2.evaluation.evaluator]: Inference done 4858/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:00:31
[03/11 13:55:52 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:55:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:53 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 484, 640])
[03/11 13:55:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:55:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:54 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:55:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:55 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 216, 320])
[03/11 13:55:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:55:56 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 320, 640])
[03/11 13:55:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 272, 500])
[03/11 13:55:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 360])
[03/11 13:55:57 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:58 d2.evaluation.evaluator]: Inference done 4880/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0434 s/iter. Total: 0.2251 s/iter. ETA=0:00:27
[03/11 13:55:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:55:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 408, 640])
[03/11 13:55:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 536])
[03/11 13:55:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:55:58 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:55:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:55:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:55:59 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 316, 500])
[03/11 13:56:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:56:00 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:01 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:56:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:56:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:02 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:56:03 d2.evaluation.evaluator]: Inference done 4903/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2251 s/iter. ETA=0:00:21
[03/11 13:56:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:56:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:03 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 476])
[03/11 13:56:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:04 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:56:05 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:06 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:56:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 424, 640])
[03/11 13:56:07 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 528, 640])
[03/11 13:56:08 d2.evaluation.evaluator]: Inference done 4927/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:00:16
[03/11 13:56:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:08 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:56:09 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:56:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 640])
[03/11 13:56:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:56:10 mask2former.HRNetv2_model]: torch.Size([1, 3, 340, 640])
[03/11 13:56:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 536])
[03/11 13:56:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:11 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 436])
[03/11 13:56:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 500])
[03/11 13:56:12 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:56:13 d2.evaluation.evaluator]: Inference done 4950/5000. Dataloading: 0.0040 s/iter. Inference: 0.1775 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:00:11
[03/11 13:56:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 480])
[03/11 13:56:13 mask2former.HRNetv2_model]: torch.Size([1, 3, 396, 640])
[03/11 13:56:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:56:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 472])
[03/11 13:56:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:56:14 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 500, 376])
[03/11 13:56:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:15 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 432])
[03/11 13:56:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 240, 320])
[03/11 13:56:16 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 360, 640])
[03/11 13:56:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:17 mask2former.HRNetv2_model]: torch.Size([1, 3, 536, 640])
[03/11 13:56:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 440, 500])
[03/11 13:56:18 d2.evaluation.evaluator]: Inference done 4975/5000. Dataloading: 0.0040 s/iter. Inference: 0.1774 s/iter. Eval: 0.0434 s/iter. Total: 0.2249 s/iter. ETA=0:00:05
[03/11 13:56:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 420, 640])
[03/11 13:56:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 640])
[03/11 13:56:18 mask2former.HRNetv2_model]: torch.Size([1, 3, 344, 500])
[03/11 13:56:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:19 mask2former.HRNetv2_model]: torch.Size([1, 3, 468, 640])
[03/11 13:56:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:20 mask2former.HRNetv2_model]: torch.Size([1, 3, 428, 640])
[03/11 13:56:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:56:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 428])
[03/11 13:56:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 612, 612])
[03/11 13:56:21 mask2former.HRNetv2_model]: torch.Size([1, 3, 376, 500])
[03/11 13:56:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 400, 600])
[03/11 13:56:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 588])
[03/11 13:56:22 mask2former.HRNetv2_model]: torch.Size([1, 3, 480, 640])
[03/11 13:56:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 640, 640])
[03/11 13:56:23 d2.evaluation.evaluator]: Inference done 4995/5000. Dataloading: 0.0040 s/iter. Inference: 0.1776 s/iter. Eval: 0.0434 s/iter. Total: 0.2250 s/iter. ETA=0:00:01
[03/11 13:56:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:56:23 mask2former.HRNetv2_model]: torch.Size([1, 3, 460, 640])
[03/11 13:56:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 336, 500])
[03/11 13:56:24 mask2former.HRNetv2_model]: torch.Size([1, 3, 464, 640])
[03/11 13:56:24 d2.evaluation.evaluator]: Total inference time: 0:18:44.147412 (0.225055 s / iter per device, on 1 devices)
[03/11 13:56:24 d2.evaluation.evaluator]: Total inference pure compute time: 0:14:47 (0.177603 s / iter per device, on 1 devices)
[03/11 13:56:27 d2.evaluation.sem_seg_evaluation]: OrderedDict([('sem_seg', {'mIoU': 2.1714810254043138, 'fwIoU': 16.33139607739237, 'IoU-rug-merged': 20.23732052944588, 'BoundaryIoU-rug-merged': 60.97247245567651, 'min(IoU, B-Iou)-rug-merged': 20.23732052944588, 'IoU-person': 4.326086561531227e-05, 'BoundaryIoU-person': 0.1282825794502337, 'min(IoU, B-Iou)-person': 4.326086561531227e-05, 'IoU-bicycle': 3.7825364327604975e-05, 'BoundaryIoU-bicycle': 0.0, 'min(IoU, B-Iou)-bicycle': 0.0, 'IoU-car': 2.034181448117577, 'BoundaryIoU-car': 0.0, 'min(IoU, B-Iou)-car': 0.0, 'IoU-motorcycle': 0.0017969711660350573, 'BoundaryIoU-motorcycle': 0.0, 'min(IoU, B-Iou)-motorcycle': 0.0, 'IoU-airplane': 0.9788752788852905, 'BoundaryIoU-airplane': 0.0, 'min(IoU, B-Iou)-airplane': 0.0, 'IoU-bus': 0.7714741020326623, 'BoundaryIoU-bus': 0.0, 'min(IoU, B-Iou)-bus': 0.0, 'IoU-train': 0.00010155424418398844, 'BoundaryIoU-train': 0.0, 'min(IoU, B-Iou)-train': 0.0, 'IoU-truck': 0.0004030758350540396, 'BoundaryIoU-truck': 0.0, 'min(IoU, B-Iou)-truck': 0.0, 'IoU-boat': 0.0, 'BoundaryIoU-boat': 0.0, 'min(IoU, B-Iou)-boat': 0.0, 'IoU-traffic light': 0.007119194297050755, 'BoundaryIoU-traffic light': 0.0, 'min(IoU, B-Iou)-traffic light': 0.0, 'IoU-fire hydrant': 0.0, 'BoundaryIoU-fire hydrant': 0.0, 'min(IoU, B-Iou)-fire hydrant': 0.0, 'IoU-stop sign': 0.0, 'BoundaryIoU-stop sign': 0.0, 'min(IoU, B-Iou)-stop sign': 0.0, 'IoU-parking meter': 0.0009673771605957233, 'BoundaryIoU-parking meter': 0.0, 'min(IoU, B-Iou)-parking meter': 0.0, 'IoU-bench': 0.0, 'BoundaryIoU-bench': 0.0, 'min(IoU, B-Iou)-bench': 0.0, 'IoU-bird': 0.021798958517927028, 'BoundaryIoU-bird': 0.0, 'min(IoU, B-Iou)-bird': 0.0, 'IoU-cat': 0.05957314650138841, 'BoundaryIoU-cat': 0.0, 'min(IoU, B-Iou)-cat': 0.0, 'IoU-dog': 0.001272086280015194, 'BoundaryIoU-dog': 0.0, 'min(IoU, B-Iou)-dog': 0.0, 'IoU-horse': 0.0011519604625737422, 'BoundaryIoU-horse': 0.0, 'min(IoU, B-Iou)-horse': 0.0, 'IoU-sheep': 0.0005772779387462929, 'BoundaryIoU-sheep': 0.0, 'min(IoU, B-Iou)-sheep': 0.0, 'IoU-cow': 0.07458115346478364, 'BoundaryIoU-cow': 0.0, 'min(IoU, B-Iou)-cow': 0.0, 'IoU-elephant': 0.0, 'BoundaryIoU-elephant': 0.0, 'min(IoU, B-Iou)-elephant': 0.0, 'IoU-bear': 0.7905469584417566, 'BoundaryIoU-bear': 0.0, 'min(IoU, B-Iou)-bear': 0.0, 'IoU-zebra': 0.013287249437568947, 'BoundaryIoU-zebra': 0.0, 'min(IoU, B-Iou)-zebra': 0.0, 'IoU-giraffe': 0.0, 'BoundaryIoU-giraffe': 0.0, 'min(IoU, B-Iou)-giraffe': 0.0, 'IoU-backpack': 0.0, 'BoundaryIoU-backpack': 0.0, 'min(IoU, B-Iou)-backpack': 0.0, 'IoU-umbrella': 0.0, 'BoundaryIoU-umbrella': 0.0, 'min(IoU, B-Iou)-umbrella': 0.0, 'IoU-handbag': 0.0, 'BoundaryIoU-handbag': 0.0, 'min(IoU, B-Iou)-handbag': 0.0, 'IoU-tie': 0.00027021593495794356, 'BoundaryIoU-tie': 0.0, 'min(IoU, B-Iou)-tie': 0.0, 'IoU-suitcase': 0.0, 'BoundaryIoU-suitcase': 0.0, 'min(IoU, B-Iou)-suitcase': 0.0, 'IoU-frisbee': 0.0, 'BoundaryIoU-frisbee': 0.0, 'min(IoU, B-Iou)-frisbee': 0.0, 'IoU-skis': 0.0, 'BoundaryIoU-skis': 0.0, 'min(IoU, B-Iou)-skis': 0.0, 'IoU-snowboard': 0.0, 'BoundaryIoU-snowboard': 0.0, 'min(IoU, B-Iou)-snowboard': 0.0, 'IoU-sports ball': 0.0, 'BoundaryIoU-sports ball': 0.0, 'min(IoU, B-Iou)-sports ball': 0.0, 'IoU-kite': 0.0, 'BoundaryIoU-kite': 0.0, 'min(IoU, B-Iou)-kite': 0.0, 'IoU-baseball bat': 0.0, 'BoundaryIoU-baseball bat': 0.0, 'min(IoU, B-Iou)-baseball bat': 0.0, 'IoU-baseball glove': 0.0, 'BoundaryIoU-baseball glove': 0.0, 'min(IoU, B-Iou)-baseball glove': 0.0, 'IoU-skateboard': 0.023419641355598604, 'BoundaryIoU-skateboard': 0.0, 'min(IoU, B-Iou)-skateboard': 0.0, 'IoU-surfboard': 0.00020076854197869444, 'BoundaryIoU-surfboard': 0.0, 'min(IoU, B-Iou)-surfboard': 0.0, 'IoU-tennis racket': 0.00014008476529147788, 'BoundaryIoU-tennis racket': 0.0, 'min(IoU, B-Iou)-tennis racket': 0.0, 'IoU-bottle': 0.0, 'BoundaryIoU-bottle': 0.0, 'min(IoU, B-Iou)-bottle': 0.0, 'IoU-wine glass': 0.0, 'BoundaryIoU-wine glass': 0.0, 'min(IoU, B-Iou)-wine glass': 0.0, 'IoU-cup': 0.0, 'BoundaryIoU-cup': 0.0, 'min(IoU, B-Iou)-cup': 0.0, 'IoU-fork': 0.0, 'BoundaryIoU-fork': 0.0, 'min(IoU, B-Iou)-fork': 0.0, 'IoU-knife': 0.0, 'BoundaryIoU-knife': 0.0, 'min(IoU, B-Iou)-knife': 0.0, 'IoU-spoon': 0.03653894027609075, 'BoundaryIoU-spoon': 0.0, 'min(IoU, B-Iou)-spoon': 0.0, 'IoU-bowl': 0.6343052820353292, 'BoundaryIoU-bowl': 0.0, 'min(IoU, B-Iou)-bowl': 0.0, 'IoU-banana': 0.0, 'BoundaryIoU-banana': 0.0, 'min(IoU, B-Iou)-banana': 0.0, 'IoU-apple': 0.02511279714471705, 'BoundaryIoU-apple': 0.0, 'min(IoU, B-Iou)-apple': 0.0, 'IoU-sandwich': 0.002942243359800089, 'BoundaryIoU-sandwich': 0.0, 'min(IoU, B-Iou)-sandwich': 0.0, 'IoU-orange': 0.18213087354765334, 'BoundaryIoU-orange': 0.0, 'min(IoU, B-Iou)-orange': 0.0, 'IoU-broccoli': 0.0, 'BoundaryIoU-broccoli': 0.0, 'min(IoU, B-Iou)-broccoli': 0.0, 'IoU-carrot': 0.0, 'BoundaryIoU-carrot': 0.0, 'min(IoU, B-Iou)-carrot': 0.0, 'IoU-hot dog': 9.980470610402731, 'BoundaryIoU-hot dog': 0.0, 'min(IoU, B-Iou)-hot dog': 0.0, 'IoU-pizza': 0.0011691230822610088, 'BoundaryIoU-pizza': 0.0, 'min(IoU, B-Iou)-pizza': 0.0, 'IoU-donut': 0.02822740077702716, 'BoundaryIoU-donut': 0.0, 'min(IoU, B-Iou)-donut': 0.0, 'IoU-cake': 0.003484546205642903, 'BoundaryIoU-cake': 0.0, 'min(IoU, B-Iou)-cake': 0.0, 'IoU-chair': 0.0835085099382761, 'BoundaryIoU-chair': 0.0, 'min(IoU, B-Iou)-chair': 0.0, 'IoU-couch': 0.0, 'BoundaryIoU-couch': 0.0, 'min(IoU, B-Iou)-couch': 0.0, 'IoU-potted plant': 0.011961723444474217, 'BoundaryIoU-potted plant': 0.0, 'min(IoU, B-Iou)-potted plant': 0.0, 'IoU-bed': 1.245614083046075, 'BoundaryIoU-bed': 0.0, 'min(IoU, B-Iou)-bed': 0.0, 'IoU-dining table': 0.007659276140800111, 'BoundaryIoU-dining table': 0.0, 'min(IoU, B-Iou)-dining table': 0.0, 'IoU-toilet': 0.015227063398358266, 'BoundaryIoU-toilet': 0.0, 'min(IoU, B-Iou)-toilet': 0.0, 'IoU-tv': 0.0, 'BoundaryIoU-tv': 0.0, 'min(IoU, B-Iou)-tv': 0.0, 'IoU-laptop': 0.0, 'BoundaryIoU-laptop': 0.0, 'min(IoU, B-Iou)-laptop': 0.0, 'IoU-mouse': 0.0, 'BoundaryIoU-mouse': 0.0, 'min(IoU, B-Iou)-mouse': 0.0, 'IoU-remote': 0.0, 'BoundaryIoU-remote': 0.0, 'min(IoU, B-Iou)-remote': 0.0, 'IoU-keyboard': 0.001736088062556359, 'BoundaryIoU-keyboard': 0.0, 'min(IoU, B-Iou)-keyboard': 0.0, 'IoU-cell phone': 0.0, 'BoundaryIoU-cell phone': 0.0, 'min(IoU, B-Iou)-cell phone': 0.0, 'IoU-microwave': 0.01718740018064958, 'BoundaryIoU-microwave': 0.0, 'min(IoU, B-Iou)-microwave': 0.0, 'IoU-oven': 0.0, 'BoundaryIoU-oven': 0.0, 'min(IoU, B-Iou)-oven': 0.0, 'IoU-toaster': 0.0, 'BoundaryIoU-toaster': 0.0, 'min(IoU, B-Iou)-toaster': 0.0, 'IoU-sink': 0.0, 'BoundaryIoU-sink': 0.0, 'min(IoU, B-Iou)-sink': 0.0, 'IoU-refrigerator': 0.0, 'BoundaryIoU-refrigerator': 0.0, 'min(IoU, B-Iou)-refrigerator': 0.0, 'IoU-book': 0.00034141744818746354, 'BoundaryIoU-book': 0.0, 'min(IoU, B-Iou)-book': 0.0, 'IoU-clock': 0.0, 'BoundaryIoU-clock': 0.0, 'min(IoU, B-Iou)-clock': 0.0, 'IoU-vase': 0.0, 'BoundaryIoU-vase': 0.0, 'min(IoU, B-Iou)-vase': 0.0, 'IoU-scissors': 0.0, 'BoundaryIoU-scissors': 0.0, 'min(IoU, B-Iou)-scissors': 0.0, 'IoU-teddy bear': 0.0, 'BoundaryIoU-teddy bear': 0.0, 'min(IoU, B-Iou)-teddy bear': 0.0, 'IoU-hair drier': 0.0, 'BoundaryIoU-hair drier': 0.0, 'min(IoU, B-Iou)-hair drier': 0.0, 'IoU-toothbrush': 0.0, 'BoundaryIoU-toothbrush': 0.0, 'min(IoU, B-Iou)-toothbrush': 0.0, 'IoU-banner': 0.0, 'BoundaryIoU-banner': 0.0, 'min(IoU, B-Iou)-banner': 0.0, 'IoU-blanket': 0.0, 'BoundaryIoU-blanket': 0.0, 'min(IoU, B-Iou)-blanket': 0.0, 'IoU-bridge': 0.008747066373781615, 'BoundaryIoU-bridge': 0.0, 'min(IoU, B-Iou)-bridge': 0.0, 'IoU-cardboard': 0.0, 'BoundaryIoU-cardboard': 0.0, 'min(IoU, B-Iou)-cardboard': 0.0, 'IoU-counter': 0.0, 'BoundaryIoU-counter': 0.0, 'min(IoU, B-Iou)-counter': 0.0, 'IoU-curtain': 0.0009214273180164108, 'BoundaryIoU-curtain': 0.0, 'min(IoU, B-Iou)-curtain': 0.0, 'IoU-door-stuff': 0.00010258573199536137, 'BoundaryIoU-door-stuff': 0.0, 'min(IoU, B-Iou)-door-stuff': 0.0, 'IoU-floor-wood': 5.0141398744459373e-05, 'BoundaryIoU-floor-wood': 0.0, 'min(IoU, B-Iou)-floor-wood': 0.0, 'IoU-flower': 0.0044490334330417585, 'BoundaryIoU-flower': 0.0, 'min(IoU, B-Iou)-flower': 0.0, 'IoU-fruit': 0.010812512316027343, 'BoundaryIoU-fruit': 0.0, 'min(IoU, B-Iou)-fruit': 0.0, 'IoU-gravel': 0.00016511137646868043, 'BoundaryIoU-gravel': 0.0, 'min(IoU, B-Iou)-gravel': 0.0, 'IoU-house': 0.0, 'BoundaryIoU-house': 0.0, 'min(IoU, B-Iou)-house': 0.0, 'IoU-light': 0.0, 'BoundaryIoU-light': 0.0, 'min(IoU, B-Iou)-light': 0.0, 'IoU-mirror-stuff': 0.0, 'BoundaryIoU-mirror-stuff': 0.0, 'min(IoU, B-Iou)-mirror-stuff': 0.0, 'IoU-net': 0.0, 'BoundaryIoU-net': 0.0, 'min(IoU, B-Iou)-net': 0.0, 'IoU-pillow': 0.0, 'BoundaryIoU-pillow': 0.0, 'min(IoU, B-Iou)-pillow': 0.0, 'IoU-platform': 4.945978361886184, 'BoundaryIoU-platform': 0.0, 'min(IoU, B-Iou)-platform': 0.0, 'IoU-playingfield': 0.0, 'BoundaryIoU-playingfield': 0.0, 'min(IoU, B-Iou)-playingfield': 0.0, 'IoU-railroad': 1.5099542982132561e-05, 'BoundaryIoU-railroad': 0.0, 'min(IoU, B-Iou)-railroad': 0.0, 'IoU-river': 12.480116726827573, 'BoundaryIoU-river': 0.0, 'min(IoU, B-Iou)-river': 0.0, 'IoU-road': 0.038605371584493536, 'BoundaryIoU-road': 0.0, 'min(IoU, B-Iou)-road': 0.0, 'IoU-roof': 3.113697877419573, 'BoundaryIoU-roof': 0.0, 'min(IoU, B-Iou)-roof': 0.0, 'IoU-sand': 25.50258475515321, 'BoundaryIoU-sand': 0.0, 'min(IoU, B-Iou)-sand': 0.0, 'IoU-sea': 0.010300580165620478, 'BoundaryIoU-sea': 0.0, 'min(IoU, B-Iou)-sea': 0.0, 'IoU-shelf': 20.243299631709945, 'BoundaryIoU-shelf': 0.0, 'min(IoU, B-Iou)-shelf': 0.0, 'IoU-snow': 0.0, 'BoundaryIoU-snow': 0.0, 'min(IoU, B-Iou)-snow': 0.0, 'IoU-stairs': 0.0, 'BoundaryIoU-stairs': 0.0, 'min(IoU, B-Iou)-stairs': 0.0, 'IoU-tent': 0.0, 'BoundaryIoU-tent': 0.0, 'min(IoU, B-Iou)-tent': 0.0, 'IoU-towel': 0.0, 'BoundaryIoU-towel': 0.0, 'min(IoU, B-Iou)-towel': 0.0, 'IoU-wall-brick': 0.0, 'BoundaryIoU-wall-brick': 0.0, 'min(IoU, B-Iou)-wall-brick': 0.0, 'IoU-wall-stone': 0.01033810665908373, 'BoundaryIoU-wall-stone': 0.0, 'min(IoU, B-Iou)-wall-stone': 0.0, 'IoU-wall-tile': 0.002673701296459013, 'BoundaryIoU-wall-tile': 0.0, 'min(IoU, B-Iou)-wall-tile': 0.0, 'IoU-wall-wood': 0.001572427484066887, 'BoundaryIoU-wall-wood': 0.0, 'min(IoU, B-Iou)-wall-wood': 0.0, 'IoU-water-other': 0.0, 'BoundaryIoU-water-other': 0.0, 'min(IoU, B-Iou)-water-other': 0.0, 'IoU-window-blind': 0.3158138029097275, 'BoundaryIoU-window-blind': 0.0, 'min(IoU, B-Iou)-window-blind': 0.0, 'IoU-window-other': 36.69255384846339, 'BoundaryIoU-window-other': 0.0, 'min(IoU, B-Iou)-window-other': 0.0, 'IoU-tree-merged': 0.025868158984948573, 'BoundaryIoU-tree-merged': 0.0, 'min(IoU, B-Iou)-tree-merged': 0.0, 'IoU-fence-merged': 0.023368626345667765, 'BoundaryIoU-fence-merged': 0.0, 'min(IoU, B-Iou)-fence-merged': 0.0, 'IoU-ceiling-merged': 64.87103220237313, 'BoundaryIoU-ceiling-merged': 0.0, 'min(IoU, B-Iou)-ceiling-merged': 0.0, 'IoU-sky-other-merged': 0.01195144924473301, 'BoundaryIoU-sky-other-merged': 0.0, 'min(IoU, B-Iou)-sky-other-merged': 0.0, 'IoU-cabinet-merged': 0.02727760167653537, 'BoundaryIoU-cabinet-merged': 0.0, 'min(IoU, B-Iou)-cabinet-merged': 0.0, 'IoU-table-merged': 0.08293763801759964, 'BoundaryIoU-table-merged': 0.0, 'min(IoU, B-Iou)-table-merged': 0.0, 'IoU-floor-other-merged': 6.202784998619252, 'BoundaryIoU-floor-other-merged': 0.0, 'min(IoU, B-Iou)-floor-other-merged': 0.0, 'IoU-pavement-merged': 2.267376676426817, 'BoundaryIoU-pavement-merged': 0.0, 'min(IoU, B-Iou)-pavement-merged': 0.0, 'IoU-mountain-merged': 29.639615140235286, 'BoundaryIoU-mountain-merged': 0.0, 'min(IoU, B-Iou)-mountain-merged': 0.0, 'IoU-grass-merged': 0.5470424775841052, 'BoundaryIoU-grass-merged': 0.0, 'min(IoU, B-Iou)-grass-merged': 0.0, 'IoU-dirt-merged': 0.0, 'BoundaryIoU-dirt-merged': 0.0, 'min(IoU, B-Iou)-dirt-merged': 0.0, 'IoU-paper-merged': 0.0030439334847510223, 'BoundaryIoU-paper-merged': 0.0, 'min(IoU, B-Iou)-paper-merged': 0.0, 'IoU-food-other-merged': 19.213482471892572, 'BoundaryIoU-food-other-merged': 0.0, 'min(IoU, B-Iou)-food-other-merged': 0.0, 'IoU-building-other-merged': 0.0, 'BoundaryIoU-building-other-merged': 0.0, 'min(IoU, B-Iou)-building-other-merged': 0.0, 'IoU-rock-merged': 25.211639337290393, 'BoundaryIoU-rock-merged': 0.0, 'min(IoU, B-Iou)-rock-merged': 0.0, 'IoU-wall-other-merged': 0.0, 'BoundaryIoU-wall-other-merged': 0.0, 'min(IoU, B-Iou)-wall-other-merged': 0.0, 'mACC': 4.0117144281496655, 'pACC': 30.98445487345028, 'ACC-rug-merged': 78.47184653644807, 'ACC-person': 4.3263448442948495e-05, 'ACC-bicycle': 3.782567909702539e-05, 'ACC-car': 15.720159401972477, 'ACC-motorcycle': 0.0018288353261012174, 'ACC-airplane': 1.0349506046302335, 'ACC-bus': 0.818404873593813, 'ACC-train': 0.00010156802162760433, 'ACC-truck': 0.0004046975823734336, 'ACC-boat': 0.0, 'ACC-traffic light': 0.0072057799963277215, 'ACC-fire hydrant': 0.0, 'ACC-stop sign': 0.0, 'ACC-parking meter': 0.0009682516465428267, 'ACC-bench': 0.0, 'ACC-bird': 0.02187099391028844, 'ACC-cat': 0.06042677256049291, 'ACC-dog': 0.0012726771986644016, 'ACC-horse': 0.001152034841820258, 'ACC-sheep': 0.0005775654011204266, 'ACC-cow': 0.0758926405289095, 'ACC-elephant': 0.0, 'ACC-bear': 0.7952183822743091, 'ACC-zebra': 0.013301320772881825, 'ACC-giraffe': 0.0, 'ACC-backpack': 0.0, 'ACC-umbrella': 0.0, 'ACC-handbag': 0.0, 'ACC-tie': 0.0002702762601765769, 'ACC-suitcase': 0.0, 'ACC-frisbee': 0.0, 'ACC-skis': 0.0, 'ACC-snowboard': 0.0, 'ACC-sports ball': 0.0, 'ACC-kite': 0.0, 'ACC-baseball bat': 0.0, 'ACC-baseball glove': 0.0, 'ACC-skateboard': 0.02540289944370353, 'ACC-surfboard': 0.0002007739837071912, 'ACC-tennis racket': 0.0001404607322709586, 'ACC-bottle': 0.0, 'ACC-wine glass': 0.0, 'ACC-cup': 0.0, 'ACC-fork': 0.0, 'ACC-knife': 0.0, 'ACC-spoon': 0.03741015696211286, 'ACC-bowl': 0.7049782927844549, 'ACC-banana': 0.0, 'ACC-apple': 0.025643652085838898, 'ACC-sandwich': 0.002945288244870458, 'ACC-orange': 0.18693078746517985, 'ACC-broccoli': 0.0, 'ACC-carrot': 0.0, 'ACC-hot dog': 18.871893888945426, 'ACC-pizza': 0.0011728860526065879, 'ACC-donut': 0.02892922646891362, 'ACC-cake': 0.0034985153808122743, 'ACC-chair': 0.08826042629968098, 'ACC-couch': 0.0, 'ACC-potted plant': 0.012202036027163885, 'ACC-bed': 1.45225738494902, 'ACC-dining table': 0.007705344203520677, 'ACC-toilet': 0.015264357434985361, 'ACC-tv': 0.0, 'ACC-laptop': 0.0, 'ACC-mouse': 0.0, 'ACC-remote': 0.0, 'ACC-keyboard': 0.0017366822014592217, 'ACC-cell phone': 0.0, 'ACC-microwave': 0.017269981437054344, 'ACC-oven': 0.0, 'ACC-toaster': 0.0, 'ACC-sink': 0.0, 'ACC-refrigerator': 0.0, 'ACC-book': 0.00034280268620184905, 'ACC-clock': 0.0, 'ACC-vase': 0.0, 'ACC-scissors': 0.0, 'ACC-teddy bear': 0.0, 'ACC-hair drier': 0.0, 'ACC-toothbrush': 0.0, 'ACC-banner': 0.0, 'ACC-blanket': 0.0, 'ACC-bridge': 0.009277301148756726, 'ACC-cardboard': 0.0, 'ACC-counter': 0.0, 'ACC-curtain': 0.0009217491871663234, 'ACC-door-stuff': 0.00010260272328148134, 'ACC-floor-wood': 5.021000333896522e-05, 'ACC-flower': 0.004451734239559961, 'ACC-fruit': 0.010870872686642913, 'ACC-gravel': 0.00016511608899426965, 'ACC-house': 0.0, 'ACC-light': 0.0, 'ACC-mirror-stuff': 0.0, 'ACC-net': 0.0, 'ACC-pillow': 0.0, 'ACC-platform': 5.453161462190095, 'ACC-playingfield': 0.0, 'ACC-railroad': 1.510733078694237e-05, 'ACC-river': 25.85377899307532, 'ACC-road': 0.9487953648131623, 'ACC-roof': 3.6480660655307404, 'ACC-sand': 32.915148622830145, 'ACC-sea': 0.011519428313003302, 'ACC-shelf': 25.38149483595807, 'ACC-snow': 0.0, 'ACC-stairs': 0.0, 'ACC-tent': 0.0, 'ACC-towel': 0.0, 'ACC-wall-brick': 0.0, 'ACC-wall-stone': 0.01039883146154367, 'ACC-wall-tile': 0.0026745792102293277, 'ACC-wall-wood': 0.0015731553622672, 'ACC-water-other': 0.0, 'ACC-window-blind': 0.3206819136190017, 'ACC-window-other': 72.10590496421584, 'ACC-tree-merged': 0.025965016565038013, 'ACC-fence-merged': 0.02480342651537747, 'ACC-ceiling-merged': 82.56615809049454, 'ACC-sky-other-merged': 0.012255558392577996, 'ACC-cabinet-merged': 0.027294775315792514, 'ACC-table-merged': 0.08540286549536008, 'ACC-floor-other-merged': 9.202631378718332, 'ACC-pavement-merged': 2.396094120849306, 'ACC-mountain-merged': 63.23475385446676, 'ACC-grass-merged': 0.5571390398851063, 'ACC-dirt-merged': 0.0, 'ACC-paper-merged': 0.0030454887960396854, 'ACC-food-other-merged': 43.6470773873859, 'ACC-building-other-merged': 0.0, 'ACC-rock-merged': 46.58622488515466, 'ACC-wall-other-merged': 0.0})])
[03/11 13:56:27 d2.engine.defaults]: Evaluation results for coco_sem_seg_val in csv format:
[03/11 13:56:27 d2.evaluation.testing]: copypaste: Task: sem_seg
[03/11 13:56:27 d2.evaluation.testing]: copypaste: mIoU,fwIoU,mACC,pACC
[03/11 13:56:27 d2.evaluation.testing]: copypaste: 2.1715,16.3314,4.0117,30.9845
